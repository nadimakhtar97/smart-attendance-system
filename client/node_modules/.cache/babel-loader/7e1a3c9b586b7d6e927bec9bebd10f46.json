{"ast":null,"code":"/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { backend_util, sumOutType, util } from '@tensorflow/tfjs-core';\nimport { reduce } from '../kernel_utils/reduce';\nimport { reshape } from './Reshape';\nimport { transposeImpl } from './Transpose_impl';\nexport function sumImpl(x, axis, keepDims, backend) {\n  const reductionIndices = axis;\n  const xRank = x.shape.length;\n  const origAxes = util.parseAxisParam(reductionIndices, x.shape);\n  let axes = origAxes;\n  const permutedAxes = backend_util.getAxesPermutation(axes, xRank);\n  const sumInputIsTransposed = permutedAxes != null;\n  let sumInput = x;\n\n  if (sumInputIsTransposed) {\n    sumInput = transposeImpl(x, permutedAxes, backend);\n    axes = backend_util.getInnerMostAxes(axes.length, xRank);\n  }\n\n  backend_util.assertAxesAreInnerMostDims('sum', axes, xRank);\n  const [sumOutShape, reduceShape] = backend_util.computeOutAndReduceShapes(sumInput.shape, axes);\n  let outShape = sumOutShape;\n\n  if (keepDims) {\n    // rather than reshape at the end, set the target shape here.\n    outShape = backend_util.expandShapeToKeepDim(sumOutShape, origAxes);\n  }\n\n  const inSize = util.sizeFromShape(reduceShape);\n  const xSize = util.sizeFromShape(x.shape);\n  const batchSize = xSize / inSize;\n  const reshapedInput = reshape({\n    inputs: {\n      x: sumInput\n    },\n    attrs: {\n      shape: [batchSize, inSize]\n    },\n    backend\n  });\n  const outType = sumOutType(x.dtype);\n  const reduced = reduce(reshapedInput, outType, 'sum', backend);\n  const out = reshape({\n    inputs: {\n      x: reduced\n    },\n    attrs: {\n      shape: outShape\n    },\n    backend\n  });\n  backend.disposeIntermediateTensorInfo(reshapedInput);\n  backend.disposeIntermediateTensorInfo(reduced);\n\n  if (sumInputIsTransposed) {\n    backend.disposeIntermediateTensorInfo(sumInput);\n  }\n\n  return out;\n}","map":{"version":3,"mappings":"AAAA;;;;;;;;;;;;;;;;AAiBA,SAAQA,YAAR,EAAsBC,UAAtB,EAA8CC,IAA9C,QAAyD,uBAAzD;AAGA,SAAQC,MAAR,QAAqB,wBAArB;AACA,SAAQC,OAAR,QAAsB,WAAtB;AAEA,SAAQC,aAAR,QAA4B,kBAA5B;AAEA,OAAM,SAAUC,OAAV,CACFC,CADE,EACaC,IADb,EACoCC,QADpC,EAEFC,OAFE,EAEuB;AAC3B,QAAMC,gBAAgB,GAAGH,IAAzB;AAEA,QAAMI,KAAK,GAAGL,CAAC,CAACM,KAAF,CAAQC,MAAtB;AAEA,QAAMC,QAAQ,GAAGb,IAAI,CAACc,cAAL,CAAoBL,gBAApB,EAAsCJ,CAAC,CAACM,KAAxC,CAAjB;AACA,MAAII,IAAI,GAAGF,QAAX;AACA,QAAMG,YAAY,GAAGlB,YAAY,CAACmB,kBAAb,CAAgCF,IAAhC,EAAsCL,KAAtC,CAArB;AACA,QAAMQ,oBAAoB,GAAGF,YAAY,IAAI,IAA7C;AAEA,MAAIG,QAAQ,GAAGd,CAAf;;AACA,MAAIa,oBAAJ,EAA0B;AACxBC,YAAQ,GAAGhB,aAAa,CAACE,CAAD,EAAIW,YAAJ,EAAkBR,OAAlB,CAAxB;AAEAO,QAAI,GAAGjB,YAAY,CAACsB,gBAAb,CAA8BL,IAAI,CAACH,MAAnC,EAA2CF,KAA3C,CAAP;AACD;;AAEDZ,cAAY,CAACuB,0BAAb,CAAwC,KAAxC,EAA+CN,IAA/C,EAAqDL,KAArD;AACA,QAAM,CAACY,WAAD,EAAcC,WAAd,IACFzB,YAAY,CAAC0B,yBAAb,CAAuCL,QAAQ,CAACR,KAAhD,EAAuDI,IAAvD,CADJ;AAGA,MAAIU,QAAQ,GAAGH,WAAf;;AACA,MAAIf,QAAJ,EAAc;AACZ;AACAkB,YAAQ,GAAG3B,YAAY,CAAC4B,oBAAb,CAAkCJ,WAAlC,EAA+CT,QAA/C,CAAX;AACD;;AAED,QAAMc,MAAM,GAAG3B,IAAI,CAAC4B,aAAL,CAAmBL,WAAnB,CAAf;AACA,QAAMM,KAAK,GAAG7B,IAAI,CAAC4B,aAAL,CAAmBvB,CAAC,CAACM,KAArB,CAAd;AACA,QAAMmB,SAAS,GAAGD,KAAK,GAAGF,MAA1B;AACA,QAAMI,aAAa,GAAG7B,OAAO,CACzB;AAAC8B,UAAM,EAAE;AAAC3B,OAAC,EAAEc;AAAJ,KAAT;AAAwBc,SAAK,EAAE;AAACtB,WAAK,EAAE,CAACmB,SAAD,EAAYH,MAAZ;AAAR,KAA/B;AAA6DnB;AAA7D,GADyB,CAA7B;AAGA,QAAM0B,OAAO,GAAGnC,UAAU,CAACM,CAAC,CAAC8B,KAAH,CAA1B;AAEA,QAAMC,OAAO,GAAGnC,MAAM,CAAC8B,aAAD,EAAgBG,OAAhB,EAAyB,KAAzB,EAAgC1B,OAAhC,CAAtB;AACA,QAAM6B,GAAG,GACLnC,OAAO,CAAC;AAAC8B,UAAM,EAAE;AAAC3B,OAAC,EAAE+B;AAAJ,KAAT;AAAuBH,SAAK,EAAE;AAACtB,WAAK,EAAEc;AAAR,KAA9B;AAAiDjB;AAAjD,GAAD,CADX;AAGAA,SAAO,CAAC8B,6BAAR,CAAsCP,aAAtC;AACAvB,SAAO,CAAC8B,6BAAR,CAAsCF,OAAtC;;AACA,MAAIlB,oBAAJ,EAA0B;AACxBV,WAAO,CAAC8B,6BAAR,CAAsCnB,QAAtC;AACD;;AAED,SAAOkB,GAAP;AACD","names":["backend_util","sumOutType","util","reduce","reshape","transposeImpl","sumImpl","x","axis","keepDims","backend","reductionIndices","xRank","shape","length","origAxes","parseAxisParam","axes","permutedAxes","getAxesPermutation","sumInputIsTransposed","sumInput","getInnerMostAxes","assertAxesAreInnerMostDims","sumOutShape","reduceShape","computeOutAndReduceShapes","outShape","expandShapeToKeepDim","inSize","sizeFromShape","xSize","batchSize","reshapedInput","inputs","attrs","outType","dtype","reduced","out","disposeIntermediateTensorInfo"],"sources":["/home/nadimakhtar97/smart-attendance-system/tfjs-backend-webgl/src/kernels/Sum_impl.ts"],"sourcesContent":["/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, sumOutType, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendWebGL} from '../backend_webgl';\nimport {reduce} from '../kernel_utils/reduce';\nimport {reshape} from './Reshape';\n\nimport {transposeImpl} from './Transpose_impl';\n\nexport function sumImpl(\n    x: TensorInfo, axis: number|number[], keepDims: boolean,\n    backend: MathBackendWebGL): TensorInfo {\n  const reductionIndices = axis;\n\n  const xRank = x.shape.length;\n\n  const origAxes = util.parseAxisParam(reductionIndices, x.shape);\n  let axes = origAxes;\n  const permutedAxes = backend_util.getAxesPermutation(axes, xRank);\n  const sumInputIsTransposed = permutedAxes != null;\n\n  let sumInput = x;\n  if (sumInputIsTransposed) {\n    sumInput = transposeImpl(x, permutedAxes, backend);\n\n    axes = backend_util.getInnerMostAxes(axes.length, xRank);\n  }\n\n  backend_util.assertAxesAreInnerMostDims('sum', axes, xRank);\n  const [sumOutShape, reduceShape] =\n      backend_util.computeOutAndReduceShapes(sumInput.shape, axes);\n\n  let outShape = sumOutShape;\n  if (keepDims) {\n    // rather than reshape at the end, set the target shape here.\n    outShape = backend_util.expandShapeToKeepDim(sumOutShape, origAxes);\n  }\n\n  const inSize = util.sizeFromShape(reduceShape);\n  const xSize = util.sizeFromShape(x.shape);\n  const batchSize = xSize / inSize;\n  const reshapedInput = reshape(\n      {inputs: {x: sumInput}, attrs: {shape: [batchSize, inSize]}, backend});\n\n  const outType = sumOutType(x.dtype);\n\n  const reduced = reduce(reshapedInput, outType, 'sum', backend);\n  const out =\n      reshape({inputs: {x: reduced}, attrs: {shape: outShape}, backend});\n\n  backend.disposeIntermediateTensorInfo(reshapedInput);\n  backend.disposeIntermediateTensorInfo(reduced);\n  if (sumInputIsTransposed) {\n    backend.disposeIntermediateTensorInfo(sumInput);\n  }\n\n  return out;\n}\n"]},"metadata":{},"sourceType":"module"}