{"ast":null,"code":"/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { DepthwiseConv2dNative } from '../kernel_names';\nimport * as conv_util from '../ops/conv_util';\nimport { depthwiseConv2dNativeBackpropFilter } from '../ops/depthwise_conv2d_native_backprop_filter';\nimport { depthwiseConv2dNativeBackpropInput } from '../ops/depthwise_conv2d_native_backprop_input';\nimport * as util from '../util';\nexport const depthwiseConv2dNativeGradConfig = {\n  kernelName: DepthwiseConv2dNative,\n  inputsToSave: ['x', 'filter'],\n  gradFunc: (dy, saved, attrs) => {\n    const {\n      dilations,\n      strides,\n      pad,\n      dimRoundingMode\n    } = attrs;\n    const $dilations = dilations == null ? [1, 1] : dilations;\n    util.assert(conv_util.tupleValuesAreOne($dilations), () => 'Error in gradient of depthwiseConv2dNative: dilation rates ' + `greater than 1 are not yet supported. Got dilations ` + `'${$dilations}'`);\n    const [x, filter] = saved;\n    util.assert(x.rank === 4, () => `Error in gradient of depthwiseConv2dNative: input must be ` + `rank 4, but got rank ${x.rank}.`);\n    util.assert(filter.rank === 4, () => `Error in gradient of depthwiseConv2dNative: filter must be ` + `rank 4, but got rank ${filter.rank}.`);\n    util.assert(x.shape[3] === filter.shape[2], () => `Error in gradient of depthwiseConv2d: number of input ` + `channels (${x.shape[3]}) must match the inChannels dimension ` + `in filter ${filter.shape[2]}.`);\n    util.assert(conv_util.eitherStridesOrDilationsAreOne(strides, $dilations), () => 'Error in gradient of depthwiseConv2d: Either strides or ' + `dilations must be  1. Got strides ${strides} and dilations ` + `'${$dilations}'.`);\n    conv_util.checkPadOnDimRoundingMode('depthwiseConv2d', pad, dimRoundingMode);\n    return {\n      x: () => depthwiseConv2dNativeBackpropInput(x.shape, dy, filter, strides, pad, $dilations, dimRoundingMode),\n      filter: () => depthwiseConv2dNativeBackpropFilter(x, dy, filter.shape, strides, pad, $dilations, dimRoundingMode)\n    };\n  }\n};","map":{"version":3,"mappings":"AAAA;;;;;;;;;;;;;;;;AAgBA,SAAQA,qBAAR,QAAgE,iBAAhE;AAEA,OAAO,KAAKC,SAAZ,MAA2B,kBAA3B;AACA,SAAQC,mCAAR,QAAkD,gDAAlD;AACA,SAAQC,kCAAR,QAAiD,+CAAjD;AAEA,OAAO,KAAKC,IAAZ,MAAsB,SAAtB;AAEA,OAAO,MAAMC,+BAA+B,GAAe;AACzDC,YAAU,EAAEN,qBAD6C;AAEzDO,cAAY,EAAE,CAAC,GAAD,EAAM,QAAN,CAF2C;AAGzDC,UAAQ,EAAE,CAACC,EAAD,EAAeC,KAAf,EAAgCC,KAAhC,KAAuD;AAC/D,UAAM;AAACC,eAAD;AAAYC,aAAZ;AAAqBC,SAArB;AAA0BC;AAA1B,QACFJ,KADJ;AAEA,UAAMK,UAAU,GAAGJ,SAAS,IAAI,IAAb,GAAoB,CAAC,CAAD,EAAI,CAAJ,CAApB,GAA+CA,SAAlE;AAEAR,QAAI,CAACa,MAAL,CACIhB,SAAS,CAACiB,iBAAV,CAA4BF,UAA5B,CADJ,EAEI,MAAM,gEACF,sDADE,GAEF,IAAIA,UAAU,GAJtB;AAMA,UAAM,CAACG,CAAD,EAAIC,MAAJ,IAAcV,KAApB;AAEAN,QAAI,CAACa,MAAL,CACIE,CAAC,CAACE,IAAF,KAAW,CADf,EAEI,MAAM,+DACF,wBAAwBF,CAAC,CAACE,IAAI,GAHtC;AAIAjB,QAAI,CAACa,MAAL,CACIG,MAAM,CAACC,IAAP,KAAgB,CADpB,EAEI,MAAM,gEACF,wBAAwBD,MAAM,CAACC,IAAI,GAH3C;AAIAjB,QAAI,CAACa,MAAL,CACIE,CAAC,CAACG,KAAF,CAAQ,CAAR,MAAeF,MAAM,CAACE,KAAP,CAAa,CAAb,CADnB,EAEI,MAAM,2DACF,aAAaH,CAAC,CAACG,KAAF,CAAQ,CAAR,CAAU,wCADrB,GAEF,aAAaF,MAAM,CAACE,KAAP,CAAa,CAAb,CAAe,GAJpC;AAMAlB,QAAI,CAACa,MAAL,CACIhB,SAAS,CAACsB,8BAAV,CAAyCV,OAAzC,EAAkDG,UAAlD,CADJ,EAEI,MAAM,6DACF,qCAAqCH,OAAO,iBAD1C,GAEF,IAAIG,UAAU,IAJtB;AAMAf,aAAS,CAACuB,yBAAV,CACI,iBADJ,EACuBV,GADvB,EAC4BC,eAD5B;AAGA,WAAO;AACLI,OAAC,EAAE,MAAMhB,kCAAkC,CACvCgB,CAAC,CAACG,KADqC,EAC9Bb,EAD8B,EAC1BW,MAD0B,EAClBP,OADkB,EACTC,GADS,EACJE,UADI,EACQD,eADR,CADtC;AAGLK,YAAM,EAAE,MAAMlB,mCAAmC,CAC7CiB,CAD6C,EAC1CV,EAD0C,EACtCW,MAAM,CAACE,KAD+B,EACxBT,OADwB,EACfC,GADe,EACVE,UADU,EACED,eADF;AAH5C,KAAP;AAMD;AA7CwD,CAApD","names":["DepthwiseConv2dNative","conv_util","depthwiseConv2dNativeBackpropFilter","depthwiseConv2dNativeBackpropInput","util","depthwiseConv2dNativeGradConfig","kernelName","inputsToSave","gradFunc","dy","saved","attrs","dilations","strides","pad","dimRoundingMode","$dilations","assert","tupleValuesAreOne","x","filter","rank","shape","eitherStridesOrDilationsAreOne","checkPadOnDimRoundingMode"],"sources":["/home/nadimakhtar97/smart-attendance-system/tfjs-core/src/gradients/DepthwiseConv2dNative_grad.ts"],"sourcesContent":["/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {DepthwiseConv2dNative, DepthwiseConv2dNativeAttrs} from '../kernel_names';\nimport {GradConfig, NamedAttrMap} from '../kernel_registry';\nimport * as conv_util from '../ops/conv_util';\nimport {depthwiseConv2dNativeBackpropFilter} from '../ops/depthwise_conv2d_native_backprop_filter';\nimport {depthwiseConv2dNativeBackpropInput} from '../ops/depthwise_conv2d_native_backprop_input';\nimport {Tensor, Tensor4D} from '../tensor';\nimport * as util from '../util';\n\nexport const depthwiseConv2dNativeGradConfig: GradConfig = {\n  kernelName: DepthwiseConv2dNative,\n  inputsToSave: ['x', 'filter'],\n  gradFunc: (dy: Tensor4D, saved: Tensor[], attrs: NamedAttrMap) => {\n    const {dilations, strides, pad, dimRoundingMode} =\n        attrs as {} as DepthwiseConv2dNativeAttrs;\n    const $dilations = dilations == null ? [1, 1] as[number,number] : dilations;\n\n    util.assert(\n        conv_util.tupleValuesAreOne($dilations),\n        () => 'Error in gradient of depthwiseConv2dNative: dilation rates ' +\n            `greater than 1 are not yet supported. Got dilations ` +\n            `'${$dilations}'`);\n\n    const [x, filter] = saved as [Tensor4D, Tensor4D];\n\n    util.assert(\n        x.rank === 4,\n        () => `Error in gradient of depthwiseConv2dNative: input must be ` +\n            `rank 4, but got rank ${x.rank}.`);\n    util.assert(\n        filter.rank === 4,\n        () => `Error in gradient of depthwiseConv2dNative: filter must be ` +\n            `rank 4, but got rank ${filter.rank}.`);\n    util.assert(\n        x.shape[3] === filter.shape[2],\n        () => `Error in gradient of depthwiseConv2d: number of input ` +\n            `channels (${x.shape[3]}) must match the inChannels dimension ` +\n            `in filter ${filter.shape[2]}.`);\n\n    util.assert(\n        conv_util.eitherStridesOrDilationsAreOne(strides, $dilations),\n        () => 'Error in gradient of depthwiseConv2d: Either strides or ' +\n            `dilations must be  1. Got strides ${strides} and dilations ` +\n            `'${$dilations}'.`);\n\n    conv_util.checkPadOnDimRoundingMode(\n        'depthwiseConv2d', pad, dimRoundingMode);\n\n    return {\n      x: () => depthwiseConv2dNativeBackpropInput(\n          x.shape, dy, filter, strides, pad, $dilations, dimRoundingMode),\n      filter: () => depthwiseConv2dNativeBackpropFilter(\n          x, dy, filter.shape, strides, pad, $dilations, dimRoundingMode),\n    };\n  }\n};\n"]},"metadata":{},"sourceType":"module"}