{"ast":null,"code":"/**\n * @license\n * Copyright 2018 Google LLC\n *\n * Use of this source code is governed by an MIT-style\n * license that can be found in the LICENSE file or at\n * https://opensource.org/licenses/MIT.\n * =============================================================================\n */\n\n/**\n * TensorFlow.js Layers: Basic Layers.\n */\nimport { any, cast, mul, notEqual, reshape, serialization, tidy, transpose, util } from '@tensorflow/tfjs-core';\nimport { getActivation, serializeActivation } from '../activations';\nimport * as K from '../backend/tfjs_backend';\nimport { getConstraint, serializeConstraint } from '../constraints';\nimport { InputSpec, Layer } from '../engine/topology';\nimport { ValueError } from '../errors';\nimport { getInitializer, serializeInitializer } from '../initializers';\nimport { getRegularizer, serializeRegularizer } from '../regularizers';\nimport { assertPositiveInteger, mapActivationToFusedKernel } from '../utils/generic_utils';\nimport { arrayProd, range } from '../utils/math_utils';\nimport { getExactlyOneShape, getExactlyOneTensor } from '../utils/types_utils';\nexport class Dropout extends Layer {\n  constructor(args) {\n    super(args);\n    this.rate = Math.max(Math.min(args.rate, 1), 0); // So that the scalar doesn't get tidied up between executions.\n\n    this.noiseShape = args.noiseShape;\n    this.seed = args.seed;\n    this.supportsMasking = true;\n  }\n\n  getNoiseShape(input) {\n    if (this.noiseShape == null) {\n      return this.noiseShape;\n    }\n\n    const inputShape = input.shape;\n    const noiseShape = [];\n\n    for (let i = 0; i < this.noiseShape.length; ++i) {\n      noiseShape.push(this.noiseShape[i] == null ? inputShape[i] : this.noiseShape[i]);\n    }\n\n    return noiseShape;\n  }\n\n  call(inputs, kwargs) {\n    return tidy(() => {\n      this.invokeCallHook(inputs, kwargs);\n      const input = getExactlyOneTensor(inputs);\n\n      if (0 < this.rate && this.rate < 1) {\n        const training = kwargs['training'] == null ? false : kwargs['training'];\n        const noiseShape = this.getNoiseShape(input);\n        const output = K.inTrainPhase(() => K.dropout(input, this.rate, noiseShape, this.seed), () => input, training);\n        return output;\n      }\n\n      return inputs;\n    });\n  }\n\n  getConfig() {\n    const config = {\n      rate: this.rate,\n      noiseShape: this.noiseShape,\n      seed: this.seed\n    };\n    const baseConfig = super.getConfig();\n    Object.assign(config, baseConfig);\n    return config;\n  }\n\n  dispose() {\n    return super.dispose();\n  }\n\n}\n/** @nocollapse */\n\nDropout.className = 'Dropout';\nserialization.registerClass(Dropout);\nexport class SpatialDropout1D extends Dropout {\n  constructor(args) {\n    super(args);\n    this.inputSpec = [{\n      ndim: 3\n    }];\n  }\n\n  getNoiseShape(input) {\n    const inputShape = input.shape;\n    return [inputShape[0], 1, inputShape[2]];\n  }\n\n}\n/** @nocollapse */\n\nSpatialDropout1D.className = 'SpatialDropout1D';\nserialization.registerClass(SpatialDropout1D);\nexport class Dense extends Layer {\n  constructor(args) {\n    super(args); // Default activation: Linear (none).\n\n    this.activation = null;\n    this.useBias = true;\n    this.kernel = null;\n    this.bias = null;\n    this.DEFAULT_KERNEL_INITIALIZER = 'glorotNormal';\n    this.DEFAULT_BIAS_INITIALIZER = 'zeros';\n\n    if (args.batchInputShape == null && args.inputShape == null && args.inputDim != null) {\n      // This logic is copied from Layer's constructor, since we can't\n      // do exactly what the Python constructor does for Dense().\n      let batchSize = null;\n\n      if (args.batchSize != null) {\n        batchSize = args.batchSize;\n      }\n\n      this.batchInputShape = [batchSize, args.inputDim];\n    }\n\n    this.units = args.units;\n    assertPositiveInteger(this.units, 'units');\n    this.activation = getActivation(args.activation);\n\n    if (args.useBias != null) {\n      this.useBias = args.useBias;\n    }\n\n    this.kernelInitializer = getInitializer(args.kernelInitializer || this.DEFAULT_KERNEL_INITIALIZER);\n    this.biasInitializer = getInitializer(args.biasInitializer || this.DEFAULT_BIAS_INITIALIZER);\n    this.kernelConstraint = getConstraint(args.kernelConstraint);\n    this.biasConstraint = getConstraint(args.biasConstraint);\n    this.kernelRegularizer = getRegularizer(args.kernelRegularizer);\n    this.biasRegularizer = getRegularizer(args.biasRegularizer);\n    this.activityRegularizer = getRegularizer(args.activityRegularizer);\n    this.supportsMasking = true;\n    this.inputSpec = [{\n      minNDim: 2\n    }];\n  }\n\n  build(inputShape) {\n    inputShape = getExactlyOneShape(inputShape);\n    const inputLastDim = inputShape[inputShape.length - 1];\n\n    if (this.kernel == null) {\n      this.kernel = this.addWeight('kernel', [inputLastDim, this.units], null, this.kernelInitializer, this.kernelRegularizer, true, this.kernelConstraint);\n\n      if (this.useBias) {\n        this.bias = this.addWeight('bias', [this.units], null, this.biasInitializer, this.biasRegularizer, true, this.biasConstraint);\n      }\n    }\n\n    this.inputSpec = [{\n      minNDim: 2,\n      axes: {\n        [-1]: inputLastDim\n      }\n    }];\n    this.built = true;\n  }\n\n  computeOutputShape(inputShape) {\n    inputShape = getExactlyOneShape(inputShape);\n    const outputShape = inputShape.slice();\n    outputShape[outputShape.length - 1] = this.units;\n    return outputShape;\n  }\n\n  call(inputs, kwargs) {\n    return tidy(() => {\n      this.invokeCallHook(inputs, kwargs); // Dense layer accepts only a single input.\n\n      const input = getExactlyOneTensor(inputs);\n      const fusedActivationName = mapActivationToFusedKernel(this.activation.getClassName());\n      let output;\n\n      if (fusedActivationName != null) {\n        output = K.dot(input, this.kernel.read(), fusedActivationName, this.bias ? this.bias.read() : null);\n      } else {\n        output = K.dot(input, this.kernel.read());\n\n        if (this.bias != null) {\n          output = K.biasAdd(output, this.bias.read());\n        }\n\n        if (this.activation != null) {\n          output = this.activation.apply(output);\n        }\n      }\n\n      return output;\n    });\n  }\n\n  getConfig() {\n    const config = {\n      units: this.units,\n      activation: serializeActivation(this.activation),\n      useBias: this.useBias,\n      kernelInitializer: serializeInitializer(this.kernelInitializer),\n      biasInitializer: serializeInitializer(this.biasInitializer),\n      kernelRegularizer: serializeRegularizer(this.kernelRegularizer),\n      biasRegularizer: serializeRegularizer(this.biasRegularizer),\n      activityRegularizer: serializeRegularizer(this.activityRegularizer),\n      kernelConstraint: serializeConstraint(this.kernelConstraint),\n      biasConstraint: serializeConstraint(this.biasConstraint)\n    };\n    const baseConfig = super.getConfig();\n    Object.assign(config, baseConfig);\n    return config;\n  }\n\n}\n/** @nocollapse */\n\nDense.className = 'Dense';\nserialization.registerClass(Dense);\nexport class Flatten extends Layer {\n  constructor(args) {\n    args = args || {};\n    super(args);\n    this.inputSpec = [{\n      minNDim: 3\n    }];\n    this.dataFormat = args.dataFormat;\n  }\n\n  computeOutputShape(inputShape) {\n    inputShape = getExactlyOneShape(inputShape);\n\n    for (const dim of inputShape.slice(1)) {\n      if (dim == null) {\n        throw new ValueError(`The shape of the input to \"Flatten\" is not fully defined ` + `(got ${inputShape.slice(1)}). Make sure to pass a complete ` + `\"input_shape\" or \"batch_input_shape\" argument to the first ` + `layer in your model.`);\n      }\n    }\n\n    return [inputShape[0], arrayProd(inputShape, 1)];\n  }\n\n  call(inputs, kwargs) {\n    return tidy(() => {\n      this.invokeCallHook(inputs, kwargs);\n      let input = getExactlyOneTensor(inputs);\n\n      if (this.dataFormat === 'channelsFirst' && input.rank > 1) {\n        const permutation = [0];\n\n        for (let i = 2; i < input.rank; ++i) {\n          permutation.push(i);\n        }\n\n        permutation.push(1);\n        input = transpose(input, permutation);\n      }\n\n      return K.batchFlatten(input);\n    });\n  }\n\n  getConfig() {\n    const config = {};\n\n    if (this.dataFormat != null) {\n      config['dataFormat'] = this.dataFormat;\n    }\n\n    const baseConfig = super.getConfig();\n    Object.assign(config, baseConfig);\n    return config;\n  }\n\n}\n/** @nocollapse */\n\nFlatten.className = 'Flatten';\nserialization.registerClass(Flatten);\nexport class Activation extends Layer {\n  constructor(args) {\n    super(args);\n    this.supportsMasking = true;\n    this.activation = getActivation(args.activation);\n  }\n\n  call(inputs, kwargs) {\n    return tidy(() => {\n      this.invokeCallHook(inputs, kwargs);\n      const input = getExactlyOneTensor(inputs);\n      return this.activation.apply(input);\n    });\n  }\n\n  getConfig() {\n    const config = {\n      activation: serializeActivation(this.activation)\n    };\n    const baseConfig = super.getConfig();\n    Object.assign(config, baseConfig);\n    return config;\n  }\n\n}\n/** @nocollapse */\n\nActivation.className = 'Activation';\nserialization.registerClass(Activation);\nexport class RepeatVector extends Layer {\n  constructor(args) {\n    super(args);\n    this.n = args.n;\n    this.inputSpec = [{\n      ndim: 2\n    }];\n  }\n\n  computeOutputShape(inputShape) {\n    return [inputShape[0], this.n, inputShape[1]];\n  }\n\n  call(inputs, kwargs) {\n    return tidy(() => {\n      inputs = getExactlyOneTensor(inputs);\n      return K.repeat(inputs, this.n);\n    });\n  }\n\n  getConfig() {\n    const config = {\n      n: this.n\n    };\n    const baseConfig = super.getConfig();\n    Object.assign(config, baseConfig);\n    return config;\n  }\n\n}\n/** @nocollapse */\n\nRepeatVector.className = 'RepeatVector';\nserialization.registerClass(RepeatVector);\nexport class Reshape extends Layer {\n  constructor(args) {\n    super(args);\n    this.targetShape = args.targetShape; // Make sure that all unknown dimensions are represented as `null`.\n\n    for (let i = 0; i < this.targetShape.length; ++i) {\n      if (this.isUnknown(this.targetShape[i])) {\n        this.targetShape[i] = null;\n      }\n    }\n  }\n\n  isUnknown(dim) {\n    return dim < 0 || dim == null;\n  }\n  /**\n   * Finds and replaces a missing dimension in output shape.\n   *\n   * This is a near direct port of the internal Numpy function\n   * `_fix_unknown_dimension` in `numpy/core/src/multiarray/shape.c`.\n   *\n   * @param inputShape: Original shape of array begin reshape.\n   * @param outputShape: Target shape of the array, with at most a single\n   * `null` or negative number, which indicates an underdetermined dimension\n   * that should be derived from `inputShape` and the known dimensions of\n   *   `outputShape`.\n   * @returns: The output shape with `null` replaced with its computed value.\n   * @throws: ValueError: If `inputShape` and `outputShape` do not match.\n   */\n\n\n  fixUnknownDimension(inputShape, outputShape) {\n    const errorMsg = 'Total size of new array must be unchanged.';\n    const finalShape = outputShape.slice();\n    let known = 1;\n    let unknown = null;\n\n    for (let i = 0; i < finalShape.length; ++i) {\n      const dim = finalShape[i];\n\n      if (this.isUnknown(dim)) {\n        if (unknown === null) {\n          unknown = i;\n        } else {\n          throw new ValueError('Can only specifiy one unknown dimension.');\n        }\n      } else {\n        known *= dim;\n      }\n    }\n\n    const originalSize = arrayProd(inputShape);\n\n    if (unknown !== null) {\n      if (known === 0 || originalSize % known !== 0) {\n        throw new ValueError(errorMsg);\n      }\n\n      finalShape[unknown] = originalSize / known;\n    } else if (originalSize !== known) {\n      throw new ValueError(errorMsg);\n    }\n\n    return finalShape;\n  }\n\n  computeOutputShape(inputShape) {\n    let anyUnknownDims = false;\n\n    for (let i = 0; i < inputShape.length; ++i) {\n      if (this.isUnknown(inputShape[i])) {\n        anyUnknownDims = true;\n        break;\n      }\n    }\n\n    if (anyUnknownDims) {\n      return inputShape.slice(0, 1).concat(this.targetShape);\n    } else {\n      return inputShape.slice(0, 1).concat(this.fixUnknownDimension(inputShape.slice(1), this.targetShape));\n    }\n  }\n\n  call(inputs, kwargs) {\n    return tidy(() => {\n      this.invokeCallHook(inputs, kwargs);\n      const input = getExactlyOneTensor(inputs);\n      const inputShape = input.shape;\n      const outputShape = inputShape.slice(0, 1).concat(this.fixUnknownDimension(inputShape.slice(1), this.targetShape));\n      return reshape(input, outputShape);\n    });\n  }\n\n  getConfig() {\n    const config = {\n      targetShape: this.targetShape\n    };\n    const baseConfig = super.getConfig();\n    Object.assign(config, baseConfig);\n    return config;\n  }\n\n}\n/** @nocollapse */\n\nReshape.className = 'Reshape';\nserialization.registerClass(Reshape);\nexport class Permute extends Layer {\n  constructor(args) {\n    super(args);\n\n    if (args.dims == null) {\n      throw new Error('Required configuration field `dims` is missing during Permute ' + 'constructor call.');\n    }\n\n    if (!Array.isArray(args.dims)) {\n      throw new Error('Permute constructor requires `dims` to be an Array, but received ' + `${args.dims} instead.`);\n    } // Check the validity of the permutation indices.\n\n\n    const expectedSortedIndices = range(1, args.dims.length + 1);\n\n    if (!util.arraysEqual(args.dims.slice().sort(), expectedSortedIndices)) {\n      throw new Error('Invalid permutation `dims`: ' + JSON.stringify(args.dims) + ' `dims` must contain consecutive integers starting from 1.');\n    }\n\n    this.dims = args.dims;\n    this.dimsIncludingBatch = [0].concat(this.dims);\n    this.inputSpec = [new InputSpec({\n      ndim: this.dims.length + 1\n    })];\n  }\n\n  computeOutputShape(inputShape) {\n    inputShape = getExactlyOneShape(inputShape);\n    const outputShape = inputShape.slice();\n    this.dims.forEach((dim, i) => {\n      outputShape[i + 1] = inputShape[dim];\n    });\n    return outputShape;\n  }\n\n  call(inputs, kwargs) {\n    return transpose(getExactlyOneTensor(inputs), this.dimsIncludingBatch);\n  }\n\n  getConfig() {\n    const config = {\n      dims: this.dims\n    };\n    const baseConfig = super.getConfig();\n    Object.assign(config, baseConfig);\n    return config;\n  }\n\n}\n/** @nocollapse */\n\nPermute.className = 'Permute';\nserialization.registerClass(Permute);\nexport class Masking extends Layer {\n  constructor(args) {\n    super(args == null ? {} : args);\n    this.supportsMasking = true;\n\n    if (args != null) {\n      this.maskValue = args.maskValue == null ? 0 : args.maskValue;\n    } else {\n      this.maskValue = 0;\n    }\n  }\n\n  computeOutputShape(inputShape) {\n    return inputShape;\n  }\n\n  getConfig() {\n    const baseConfig = super.getConfig();\n    const config = {\n      maskValue: this.maskValue\n    };\n    Object.assign(config, baseConfig);\n    return config;\n  }\n\n  computeMask(inputs, mask) {\n    const input = getExactlyOneTensor(inputs);\n    const axis = -1;\n    return any(notEqual(input, this.maskValue), axis);\n  }\n\n  call(inputs, kwargs) {\n    return tidy(() => {\n      this.invokeCallHook(inputs, kwargs);\n      const input = getExactlyOneTensor(inputs);\n      const axis = -1;\n      const keepDims = true;\n      const booleanMask = any(notEqual(input, this.maskValue), axis, keepDims);\n      const output = mul(input, cast(booleanMask, input.dtype));\n      return output;\n    });\n  }\n\n}\n/** @nocollapse */\n\nMasking.className = 'Masking';\nserialization.registerClass(Masking);","map":{"version":3,"mappings":"AAAA;;;;;;;;;;AAUA;;;AAIA,SAAQA,GAAR,EAAaC,IAAb,EAAmBC,GAAnB,EAAwBC,QAAxB,EAAkCC,OAAlC,EAA2CC,aAA3C,EAAkEC,IAAlE,EAAwEC,SAAxE,EAAmFC,IAAnF,QAA8F,uBAA9F;AAEA,SAAoCC,aAApC,EAAmDC,mBAAnD,QAA6E,gBAA7E;AACA,OAAO,KAAKC,CAAZ,MAAmB,yBAAnB;AACA,SAA0CC,aAA1C,EAAyDC,mBAAzD,QAAmF,gBAAnF;AACA,SAAuBC,SAAvB,EAAkCC,KAAlC,QAAyD,oBAAzD;AACA,SAAQC,UAAR,QAAyB,WAAzB;AACA,SAAQC,cAAR,EAA4DC,oBAA5D,QAAuF,iBAAvF;AAIA,SAAQC,cAAR,EAA4DC,oBAA5D,QAAuF,iBAAvF;AAEA,SAAQC,qBAAR,EAA+BC,0BAA/B,QAAgE,wBAAhE;AACA,SAAQC,SAAR,EAAmBC,KAAnB,QAA+B,qBAA/B;AACA,SAAQC,kBAAR,EAA4BC,mBAA5B,QAAsD,sBAAtD;AAqBA,OAAM,MAAOC,OAAP,SAAuBZ,KAAvB,CAA4B;AAOhCa,cAAYC,IAAZ,EAAkC;AAChC,UAAMA,IAAN;AACA,SAAKC,IAAL,GAAYC,IAAI,CAACC,GAAL,CAASD,IAAI,CAACE,GAAL,CAASJ,IAAI,CAACC,IAAd,EAAoB,CAApB,CAAT,EAAiC,CAAjC,CAAZ,CAFgC,CAGhC;;AACA,SAAKI,UAAL,GAAkBL,IAAI,CAACK,UAAvB;AACA,SAAKC,IAAL,GAAYN,IAAI,CAACM,IAAjB;AACA,SAAKC,eAAL,GAAuB,IAAvB;AACD;;AAESC,eAAa,CAACC,KAAD,EAAc;AACnC,QAAI,KAAKJ,UAAL,IAAmB,IAAvB,EAA6B;AAC3B,aAAO,KAAKA,UAAZ;AACD;;AACD,UAAMK,UAAU,GAAGD,KAAK,CAACE,KAAzB;AACA,UAAMN,UAAU,GAAU,EAA1B;;AACA,SAAK,IAAIO,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAG,KAAKP,UAAL,CAAgBQ,MAApC,EAA4C,EAAED,CAA9C,EAAiD;AAC/CP,gBAAU,CAACS,IAAX,CACI,KAAKT,UAAL,CAAgBO,CAAhB,KAAsB,IAAtB,GAA6BF,UAAU,CAACE,CAAD,CAAvC,GAA6C,KAAKP,UAAL,CAAgBO,CAAhB,CADjD;AAED;;AACD,WAAOP,UAAP;AACD;;AAEDU,MAAI,CAACC,MAAD,EAA0BC,MAA1B,EAAwC;AAC1C,WAAOxC,IAAI,CAAC,MAAK;AACf,WAAKyC,cAAL,CAAoBF,MAApB,EAA4BC,MAA5B;AACA,YAAMR,KAAK,GAAGZ,mBAAmB,CAACmB,MAAD,CAAjC;;AACA,UAAI,IAAI,KAAKf,IAAT,IAAiB,KAAKA,IAAL,GAAY,CAAjC,EAAoC;AAClC,cAAMkB,QAAQ,GACVF,MAAM,CAAC,UAAD,CAAN,IAAsB,IAAtB,GAA6B,KAA7B,GAAqCA,MAAM,CAAC,UAAD,CAD/C;AAEA,cAAMZ,UAAU,GAAG,KAAKG,aAAL,CAAmBC,KAAnB,CAAnB;AACA,cAAMW,MAAM,GAAGtC,CAAC,CAACuC,YAAF,CACX,MAAMvC,CAAC,CAACwC,OAAF,CAAUb,KAAV,EAAiB,KAAKR,IAAtB,EAA4BI,UAA5B,EAAwC,KAAKC,IAA7C,CADK,EAEX,MAAMG,KAFK,EAEEU,QAFF,CAAf;AAGA,eAAOC,MAAP;AACD;;AACD,aAAOJ,MAAP;AACD,KAbU,CAAX;AAcD;;AAEDO,WAAS;AACP,UAAMC,MAAM,GAAG;AACbvB,UAAI,EAAE,KAAKA,IADE;AAEbI,gBAAU,EAAE,KAAKA,UAFJ;AAGbC,UAAI,EAAE,KAAKA;AAHE,KAAf;AAKA,UAAMmB,UAAU,GAAG,MAAMF,SAAN,EAAnB;AACAG,UAAM,CAACC,MAAP,CAAcH,MAAd,EAAsBC,UAAtB;AACA,WAAOD,MAAP;AACD;;AAEDI,SAAO;AACL,WAAO,MAAMA,OAAN,EAAP;AACD;;AA3D+B;AAChC;;AACO9B,oBAAY,SAAZ;AA2DTtB,aAAa,CAACqD,aAAd,CAA4B/B,OAA5B;AA4DA,OAAM,MAAOgC,gBAAP,SAAgChC,OAAhC,CAAuC;AAI3CC,cAAYC,IAAZ,EAA6C;AAC3C,UAAMA,IAAN;AACA,SAAK+B,SAAL,GAAiB,CAAC;AAACC,UAAI,EAAE;AAAP,KAAD,CAAjB;AACD;;AAESxB,eAAa,CAACC,KAAD,EAAc;AACnC,UAAMC,UAAU,GAAGD,KAAK,CAACE,KAAzB;AACA,WAAO,CAACD,UAAU,CAAC,CAAD,CAAX,EAAgB,CAAhB,EAAmBA,UAAU,CAAC,CAAD,CAA7B,CAAP;AACD;;AAZ0C;AAC3C;;AACOoB,6BAAY,kBAAZ;AAYTtD,aAAa,CAACqD,aAAd,CAA4BC,gBAA5B;AAEA,OAAM,MAAOG,KAAP,SAAqB/C,KAArB,CAA0B;AAmB9Ba,cAAYC,IAAZ,EAAgC;AAC9B,UAAMA,IAAN,EAD8B,CAfhC;;AACQ,sBAA2B,IAA3B;AACA,mBAAU,IAAV;AAGA,kBAAwB,IAAxB;AACA,gBAAsB,IAAtB;AAEC,sCAAoD,cAApD;AACA,oCAAkD,OAAlD;;AAQP,QAAIA,IAAI,CAACkC,eAAL,IAAwB,IAAxB,IAAgClC,IAAI,CAACU,UAAL,IAAmB,IAAnD,IACAV,IAAI,CAACmC,QAAL,IAAiB,IADrB,EAC2B;AACzB;AACA;AACA,UAAIC,SAAS,GAAW,IAAxB;;AACA,UAAIpC,IAAI,CAACoC,SAAL,IAAkB,IAAtB,EAA4B;AAC1BA,iBAAS,GAAGpC,IAAI,CAACoC,SAAjB;AACD;;AACD,WAAKF,eAAL,GAAuB,CAACE,SAAD,EAAYpC,IAAI,CAACmC,QAAjB,CAAvB;AACD;;AAED,SAAKE,KAAL,GAAarC,IAAI,CAACqC,KAAlB;AACA7C,yBAAqB,CAAC,KAAK6C,KAAN,EAAa,OAAb,CAArB;AACA,SAAKC,UAAL,GAAkB1D,aAAa,CAACoB,IAAI,CAACsC,UAAN,CAA/B;;AACA,QAAItC,IAAI,CAACuC,OAAL,IAAgB,IAApB,EAA0B;AACxB,WAAKA,OAAL,GAAevC,IAAI,CAACuC,OAApB;AACD;;AACD,SAAKC,iBAAL,GAAyBpD,cAAc,CACnCY,IAAI,CAACwC,iBAAL,IAA0B,KAAKC,0BADI,CAAvC;AAEA,SAAKC,eAAL,GACItD,cAAc,CAACY,IAAI,CAAC0C,eAAL,IAAwB,KAAKC,wBAA9B,CADlB;AAEA,SAAKC,gBAAL,GAAwB7D,aAAa,CAACiB,IAAI,CAAC4C,gBAAN,CAArC;AACA,SAAKC,cAAL,GAAsB9D,aAAa,CAACiB,IAAI,CAAC6C,cAAN,CAAnC;AACA,SAAKC,iBAAL,GAAyBxD,cAAc,CAACU,IAAI,CAAC8C,iBAAN,CAAvC;AACA,SAAKC,eAAL,GAAuBzD,cAAc,CAACU,IAAI,CAAC+C,eAAN,CAArC;AACA,SAAKC,mBAAL,GAA2B1D,cAAc,CAACU,IAAI,CAACgD,mBAAN,CAAzC;AACA,SAAKzC,eAAL,GAAuB,IAAvB;AAEA,SAAKwB,SAAL,GAAiB,CAAC;AAACkB,aAAO,EAAE;AAAV,KAAD,CAAjB;AACD;;AAEMC,OAAK,CAACxC,UAAD,EAA0B;AACpCA,cAAU,GAAGd,kBAAkB,CAACc,UAAD,CAA/B;AACA,UAAMyC,YAAY,GAAGzC,UAAU,CAACA,UAAU,CAACG,MAAX,GAAoB,CAArB,CAA/B;;AACA,QAAI,KAAKuC,MAAL,IAAe,IAAnB,EAAyB;AACvB,WAAKA,MAAL,GAAc,KAAKC,SAAL,CACV,QADU,EACA,CAACF,YAAD,EAAe,KAAKd,KAApB,CADA,EAC4B,IAD5B,EACkC,KAAKG,iBADvC,EAEV,KAAKM,iBAFK,EAEc,IAFd,EAEoB,KAAKF,gBAFzB,CAAd;;AAGA,UAAI,KAAKL,OAAT,EAAkB;AAChB,aAAKe,IAAL,GAAY,KAAKD,SAAL,CACR,MADQ,EACA,CAAC,KAAKhB,KAAN,CADA,EACc,IADd,EACoB,KAAKK,eADzB,EAER,KAAKK,eAFG,EAEc,IAFd,EAEoB,KAAKF,cAFzB,CAAZ;AAGD;AACF;;AAED,SAAKd,SAAL,GAAiB,CAAC;AAACkB,aAAO,EAAE,CAAV;AAAaM,UAAI,EAAE;AAAC,SAAC,CAAC,CAAF,GAAMJ;AAAP;AAAnB,KAAD,CAAjB;AACA,SAAKK,KAAL,GAAa,IAAb;AACD;;AAEDC,oBAAkB,CAAC/C,UAAD,EAA0B;AAC1CA,cAAU,GAAGd,kBAAkB,CAACc,UAAD,CAA/B;AACA,UAAMgD,WAAW,GAAGhD,UAAU,CAACiD,KAAX,EAApB;AACAD,eAAW,CAACA,WAAW,CAAC7C,MAAZ,GAAqB,CAAtB,CAAX,GAAsC,KAAKwB,KAA3C;AACA,WAAOqB,WAAP;AACD;;AAED3C,MAAI,CAACC,MAAD,EAA0BC,MAA1B,EAAwC;AAC1C,WAAOxC,IAAI,CAAC,MAAK;AACf,WAAKyC,cAAL,CAAoBF,MAApB,EAA4BC,MAA5B,EADe,CAEf;;AACA,YAAMR,KAAK,GAAGZ,mBAAmB,CAACmB,MAAD,CAAjC;AACA,YAAM4C,mBAAmB,GACrBnE,0BAA0B,CAAC,KAAK6C,UAAL,CAAgBuB,YAAhB,EAAD,CAD9B;AAEA,UAAIzC,MAAJ;;AAEA,UAAIwC,mBAAmB,IAAI,IAA3B,EAAiC;AAC/BxC,cAAM,GAAGtC,CAAC,CAACgF,GAAF,CACLrD,KADK,EACE,KAAK2C,MAAL,CAAYW,IAAZ,EADF,EACsBH,mBADtB,EAEL,KAAKN,IAAL,GAAY,KAAKA,IAAL,CAAUS,IAAV,EAAZ,GAA+B,IAF1B,CAAT;AAGD,OAJD,MAIO;AACL3C,cAAM,GAAGtC,CAAC,CAACgF,GAAF,CAAMrD,KAAN,EAAa,KAAK2C,MAAL,CAAYW,IAAZ,EAAb,CAAT;;AACA,YAAI,KAAKT,IAAL,IAAa,IAAjB,EAAuB;AACrBlC,gBAAM,GAAGtC,CAAC,CAACkF,OAAF,CAAU5C,MAAV,EAAkB,KAAKkC,IAAL,CAAUS,IAAV,EAAlB,CAAT;AACD;;AACD,YAAI,KAAKzB,UAAL,IAAmB,IAAvB,EAA6B;AAC3BlB,gBAAM,GAAG,KAAKkB,UAAL,CAAgB2B,KAAhB,CAAsB7C,MAAtB,CAAT;AACD;AACF;;AAED,aAAOA,MAAP;AACD,KAvBU,CAAX;AAwBD;;AAEDG,WAAS;AACP,UAAMC,MAAM,GAA6B;AACvCa,WAAK,EAAE,KAAKA,KAD2B;AAEvCC,gBAAU,EAAEzD,mBAAmB,CAAC,KAAKyD,UAAN,CAFQ;AAGvCC,aAAO,EAAE,KAAKA,OAHyB;AAIvCC,uBAAiB,EAAEnD,oBAAoB,CAAC,KAAKmD,iBAAN,CAJA;AAKvCE,qBAAe,EAAErD,oBAAoB,CAAC,KAAKqD,eAAN,CALE;AAMvCI,uBAAiB,EAAEvD,oBAAoB,CAAC,KAAKuD,iBAAN,CANA;AAOvCC,qBAAe,EAAExD,oBAAoB,CAAC,KAAKwD,eAAN,CAPE;AAQvCC,yBAAmB,EAAEzD,oBAAoB,CAAC,KAAKyD,mBAAN,CARF;AASvCJ,sBAAgB,EAAE5D,mBAAmB,CAAC,KAAK4D,gBAAN,CATE;AAUvCC,oBAAc,EAAE7D,mBAAmB,CAAC,KAAK6D,cAAN;AAVI,KAAzC;AAYA,UAAMpB,UAAU,GAAG,MAAMF,SAAN,EAAnB;AACAG,UAAM,CAACC,MAAP,CAAcH,MAAd,EAAsBC,UAAtB;AACA,WAAOD,MAAP;AACD;;AAxH6B;AAC9B;;AACOS,kBAAY,OAAZ;AAwHTzD,aAAa,CAACqD,aAAd,CAA4BI,KAA5B;AAOA,OAAM,MAAOiC,OAAP,SAAuBhF,KAAvB,CAA4B;AAKhCa,cAAYC,IAAZ,EAAmC;AACjCA,QAAI,GAAGA,IAAI,IAAI,EAAf;AACA,UAAMA,IAAN;AACA,SAAK+B,SAAL,GAAiB,CAAC;AAACkB,aAAO,EAAE;AAAV,KAAD,CAAjB;AACA,SAAKkB,UAAL,GAAkBnE,IAAI,CAACmE,UAAvB;AACD;;AAEDV,oBAAkB,CAAC/C,UAAD,EAA0B;AAC1CA,cAAU,GAAGd,kBAAkB,CAACc,UAAD,CAA/B;;AACA,SAAK,MAAM0D,GAAX,IAAkB1D,UAAU,CAACiD,KAAX,CAAiB,CAAjB,CAAlB,EAAuC;AACrC,UAAIS,GAAG,IAAI,IAAX,EAAiB;AACf,cAAM,IAAIjF,UAAJ,CACF,8DACA,QAAQuB,UAAU,CAACiD,KAAX,CAAiB,CAAjB,CAAmB,kCAD3B,GAEA,6DAFA,GAGA,sBAJE,CAAN;AAKD;AACF;;AACD,WAAO,CAACjD,UAAU,CAAC,CAAD,CAAX,EAAgBhB,SAAS,CAACgB,UAAD,EAAa,CAAb,CAAzB,CAAP;AACD;;AAEDK,MAAI,CAACC,MAAD,EAA0BC,MAA1B,EAAwC;AAC1C,WAAOxC,IAAI,CAAC,MAAK;AACf,WAAKyC,cAAL,CAAoBF,MAApB,EAA4BC,MAA5B;AAEA,UAAIR,KAAK,GAAGZ,mBAAmB,CAACmB,MAAD,CAA/B;;AACA,UAAI,KAAKmD,UAAL,KAAoB,eAApB,IAAuC1D,KAAK,CAAC4D,IAAN,GAAa,CAAxD,EAA2D;AACzD,cAAMC,WAAW,GAAa,CAAC,CAAD,CAA9B;;AACA,aAAK,IAAI1D,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAGH,KAAK,CAAC4D,IAA1B,EAAgC,EAAEzD,CAAlC,EAAqC;AACnC0D,qBAAW,CAACxD,IAAZ,CAAiBF,CAAjB;AACD;;AACD0D,mBAAW,CAACxD,IAAZ,CAAiB,CAAjB;AACAL,aAAK,GAAG/B,SAAS,CAAC+B,KAAD,EAAQ6D,WAAR,CAAjB;AACD;;AAED,aAAOxF,CAAC,CAACyF,YAAF,CAAe9D,KAAf,CAAP;AACD,KAdU,CAAX;AAeD;;AAEDc,WAAS;AACP,UAAMC,MAAM,GAA6B,EAAzC;;AACA,QAAI,KAAK2C,UAAL,IAAmB,IAAvB,EAA6B;AAC3B3C,YAAM,CAAC,YAAD,CAAN,GAAuB,KAAK2C,UAA5B;AACD;;AACD,UAAM1C,UAAU,GAAG,MAAMF,SAAN,EAAnB;AACAG,UAAM,CAACC,MAAP,CAAcH,MAAd,EAAsBC,UAAtB;AACA,WAAOD,MAAP;AACD;;AApD+B;AAGhC;;AACO0C,oBAAY,SAAZ;AAkDT1F,aAAa,CAACqD,aAAd,CAA4BqC,OAA5B;AASA,OAAM,MAAOM,UAAP,SAA0BtF,KAA1B,CAA+B;AAKnCa,cAAYC,IAAZ,EAAqC;AACnC,UAAMA,IAAN;AACA,SAAKO,eAAL,GAAuB,IAAvB;AACA,SAAK+B,UAAL,GAAkB1D,aAAa,CAACoB,IAAI,CAACsC,UAAN,CAA/B;AACD;;AAEDvB,MAAI,CAACC,MAAD,EAA0BC,MAA1B,EAAwC;AAC1C,WAAOxC,IAAI,CAAC,MAAK;AACf,WAAKyC,cAAL,CAAoBF,MAApB,EAA4BC,MAA5B;AACA,YAAMR,KAAK,GAAGZ,mBAAmB,CAACmB,MAAD,CAAjC;AACA,aAAO,KAAKsB,UAAL,CAAgB2B,KAAhB,CAAsBxD,KAAtB,CAAP;AACD,KAJU,CAAX;AAKD;;AAEDc,WAAS;AACP,UAAMC,MAAM,GAAG;AAACc,gBAAU,EAAEzD,mBAAmB,CAAC,KAAKyD,UAAN;AAAhC,KAAf;AACA,UAAMb,UAAU,GAAG,MAAMF,SAAN,EAAnB;AACAG,UAAM,CAACC,MAAP,CAAcH,MAAd,EAAsBC,UAAtB;AACA,WAAOD,MAAP;AACD;;AAxBkC;AACnC;;AACOgD,uBAAY,YAAZ;AAwBThG,aAAa,CAACqD,aAAd,CAA4B2C,UAA5B;AAcA,OAAM,MAAOC,YAAP,SAA4BvF,KAA5B,CAAiC;AAKrCa,cAAYC,IAAZ,EAAuC;AACrC,UAAMA,IAAN;AACA,SAAK0E,CAAL,GAAS1E,IAAI,CAAC0E,CAAd;AACA,SAAK3C,SAAL,GAAiB,CAAC;AAACC,UAAI,EAAE;AAAP,KAAD,CAAjB;AACD;;AAEDyB,oBAAkB,CAAC/C,UAAD,EAAkB;AAClC,WAAO,CAACA,UAAU,CAAC,CAAD,CAAX,EAAgB,KAAKgE,CAArB,EAAwBhE,UAAU,CAAC,CAAD,CAAlC,CAAP;AACD;;AAEDK,MAAI,CAACC,MAAD,EAA0BC,MAA1B,EAAwC;AAC1C,WAAOxC,IAAI,CAAC,MAAK;AACfuC,YAAM,GAAGnB,mBAAmB,CAACmB,MAAD,CAA5B;AACA,aAAOlC,CAAC,CAAC6F,MAAF,CAAS3D,MAAT,EAAiB,KAAK0D,CAAtB,CAAP;AACD,KAHU,CAAX;AAID;;AAEDnD,WAAS;AACP,UAAMC,MAAM,GAAG;AACbkD,OAAC,EAAE,KAAKA;AADK,KAAf;AAGA,UAAMjD,UAAU,GAAG,MAAMF,SAAN,EAAnB;AACAG,UAAM,CAACC,MAAP,CAAcH,MAAd,EAAsBC,UAAtB;AACA,WAAOD,MAAP;AACD;;AA7BoC;AACrC;;AACOiD,yBAAY,cAAZ;AA6BTjG,aAAa,CAACqD,aAAd,CAA4B4C,YAA5B;AAEA,OAAM,MAAOG,OAAP,SAAuB1F,KAAvB,CAA4B;AAKhCa,cAAYC,IAAZ,EAAkC;AAChC,UAAMA,IAAN;AACA,SAAK6E,WAAL,GAAmB7E,IAAI,CAAC6E,WAAxB,CAFgC,CAIhC;;AACA,SAAK,IAAIjE,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAG,KAAKiE,WAAL,CAAiBhE,MAArC,EAA6C,EAAED,CAA/C,EAAkD;AAChD,UAAI,KAAKkE,SAAL,CAAe,KAAKD,WAAL,CAAiBjE,CAAjB,CAAf,CAAJ,EAAyC;AACvC,aAAKiE,WAAL,CAAiBjE,CAAjB,IAAsB,IAAtB;AACD;AACF;AACF;;AAEOkE,WAAS,CAACV,GAAD,EAAY;AAC3B,WAAOA,GAAG,GAAG,CAAN,IAAWA,GAAG,IAAI,IAAzB;AACD;AAED;;;;;;;;;;;;;;;;AAcQW,qBAAmB,CAACrE,UAAD,EAAoBgD,WAApB,EAAsC;AAC/D,UAAMsB,QAAQ,GAAG,4CAAjB;AACA,UAAMC,UAAU,GAAGvB,WAAW,CAACC,KAAZ,EAAnB;AACA,QAAIuB,KAAK,GAAG,CAAZ;AACA,QAAIC,OAAO,GAAG,IAAd;;AACA,SAAK,IAAIvE,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAGqE,UAAU,CAACpE,MAA/B,EAAuC,EAAED,CAAzC,EAA4C;AAC1C,YAAMwD,GAAG,GAAGa,UAAU,CAACrE,CAAD,CAAtB;;AACA,UAAI,KAAKkE,SAAL,CAAeV,GAAf,CAAJ,EAAyB;AACvB,YAAIe,OAAO,KAAK,IAAhB,EAAsB;AACpBA,iBAAO,GAAGvE,CAAV;AACD,SAFD,MAEO;AACL,gBAAM,IAAIzB,UAAJ,CAAe,0CAAf,CAAN;AACD;AACF,OAND,MAMO;AACL+F,aAAK,IAAId,GAAT;AACD;AACF;;AAED,UAAMgB,YAAY,GAAG1F,SAAS,CAACgB,UAAD,CAA9B;;AACA,QAAIyE,OAAO,KAAK,IAAhB,EAAsB;AACpB,UAAID,KAAK,KAAK,CAAV,IAAeE,YAAY,GAAGF,KAAf,KAAyB,CAA5C,EAA+C;AAC7C,cAAM,IAAI/F,UAAJ,CAAe6F,QAAf,CAAN;AACD;;AACDC,gBAAU,CAACE,OAAD,CAAV,GAAsBC,YAAY,GAAGF,KAArC;AACD,KALD,MAKO,IAAIE,YAAY,KAAKF,KAArB,EAA4B;AACjC,YAAM,IAAI/F,UAAJ,CAAe6F,QAAf,CAAN;AACD;;AAED,WAAOC,UAAP;AACD;;AAEDxB,oBAAkB,CAAC/C,UAAD,EAAkB;AAClC,QAAI2E,cAAc,GAAG,KAArB;;AACA,SAAK,IAAIzE,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAGF,UAAU,CAACG,MAA/B,EAAuC,EAAED,CAAzC,EAA4C;AAC1C,UAAI,KAAKkE,SAAL,CAAepE,UAAU,CAACE,CAAD,CAAzB,CAAJ,EAAmC;AACjCyE,sBAAc,GAAG,IAAjB;AACA;AACD;AACF;;AAED,QAAIA,cAAJ,EAAoB;AAClB,aAAO3E,UAAU,CAACiD,KAAX,CAAiB,CAAjB,EAAoB,CAApB,EAAuB2B,MAAvB,CAA8B,KAAKT,WAAnC,CAAP;AACD,KAFD,MAEO;AACL,aAAOnE,UAAU,CAACiD,KAAX,CAAiB,CAAjB,EAAoB,CAApB,EAAuB2B,MAAvB,CACH,KAAKP,mBAAL,CAAyBrE,UAAU,CAACiD,KAAX,CAAiB,CAAjB,CAAzB,EAA8C,KAAKkB,WAAnD,CADG,CAAP;AAED;AACF;;AAED9D,MAAI,CAACC,MAAD,EAA0BC,MAA1B,EAAwC;AAC1C,WAAOxC,IAAI,CAAC,MAAK;AACf,WAAKyC,cAAL,CAAoBF,MAApB,EAA4BC,MAA5B;AACA,YAAMR,KAAK,GAAGZ,mBAAmB,CAACmB,MAAD,CAAjC;AACA,YAAMN,UAAU,GAAGD,KAAK,CAACE,KAAzB;AACA,YAAM+C,WAAW,GAAGhD,UAAU,CAACiD,KAAX,CAAiB,CAAjB,EAAoB,CAApB,EAAuB2B,MAAvB,CAChB,KAAKP,mBAAL,CAAyBrE,UAAU,CAACiD,KAAX,CAAiB,CAAjB,CAAzB,EAA8C,KAAKkB,WAAnD,CADgB,CAApB;AAEA,aAAOtG,OAAO,CAACkC,KAAD,EAAQiD,WAAR,CAAd;AACD,KAPU,CAAX;AAQD;;AAEDnC,WAAS;AACP,UAAMC,MAAM,GAAG;AACbqD,iBAAW,EAAE,KAAKA;AADL,KAAf;AAGA,UAAMpD,UAAU,GAAG,MAAMF,SAAN,EAAnB;AACAG,UAAM,CAACC,MAAP,CAAcH,MAAd,EAAsBC,UAAtB;AACA,WAAOD,MAAP;AACD;;AArG+B;AAChC;;AACOoD,oBAAY,SAAZ;AAqGTpG,aAAa,CAACqD,aAAd,CAA4B+C,OAA5B;AAYA,OAAM,MAAOW,OAAP,SAAuBrG,KAAvB,CAA4B;AAMhCa,cAAYC,IAAZ,EAAkC;AAChC,UAAMA,IAAN;;AACA,QAAIA,IAAI,CAACwF,IAAL,IAAa,IAAjB,EAAuB;AACrB,YAAM,IAAIC,KAAJ,CACF,mEACA,mBAFE,CAAN;AAGD;;AACD,QAAI,CAACC,KAAK,CAACC,OAAN,CAAc3F,IAAI,CAACwF,IAAnB,CAAL,EAA+B;AAC7B,YAAM,IAAIC,KAAJ,CACF,sEACA,GAAGzF,IAAI,CAACwF,IAAI,WAFV,CAAN;AAGD,KAX+B,CAahC;;;AACA,UAAMI,qBAAqB,GAAGjG,KAAK,CAAC,CAAD,EAAIK,IAAI,CAACwF,IAAL,CAAU3E,MAAV,GAAmB,CAAvB,CAAnC;;AACA,QAAI,CAAClC,IAAI,CAACkH,WAAL,CAAiB7F,IAAI,CAACwF,IAAL,CAAU7B,KAAV,GAAkBmC,IAAlB,EAAjB,EAA2CF,qBAA3C,CAAL,EAAwE;AACtE,YAAM,IAAIH,KAAJ,CACF,iCAAiCM,IAAI,CAACC,SAAL,CAAehG,IAAI,CAACwF,IAApB,CAAjC,GACA,4DAFE,CAAN;AAGD;;AAED,SAAKA,IAAL,GAAYxF,IAAI,CAACwF,IAAjB;AACA,SAAKS,kBAAL,GAA0B,CAAC,CAAD,EAAIX,MAAJ,CAAW,KAAKE,IAAhB,CAA1B;AACA,SAAKzD,SAAL,GAAiB,CAAC,IAAI9C,SAAJ,CAAc;AAAC+C,UAAI,EAAE,KAAKwD,IAAL,CAAU3E,MAAV,GAAmB;AAA1B,KAAd,CAAD,CAAjB;AACD;;AAED4C,oBAAkB,CAAC/C,UAAD,EAA0B;AAC1CA,cAAU,GAAGd,kBAAkB,CAACc,UAAD,CAA/B;AACA,UAAMgD,WAAW,GAAGhD,UAAU,CAACiD,KAAX,EAApB;AACA,SAAK6B,IAAL,CAAUU,OAAV,CAAkB,CAAC9B,GAAD,EAAcxD,CAAd,KAA2B;AAC3C8C,iBAAW,CAAC9C,CAAC,GAAG,CAAL,CAAX,GAAsBF,UAAoB,CAAC0D,GAAD,CAA1C;AACD,KAFD;AAGA,WAAOV,WAAP;AACD;;AAED3C,MAAI,CAACC,MAAD,EAA0BC,MAA1B,EAAwC;AAC1C,WAAOvC,SAAS,CAACmB,mBAAmB,CAACmB,MAAD,CAApB,EAA8B,KAAKiF,kBAAnC,CAAhB;AACD;;AAED1E,WAAS;AACP,UAAMC,MAAM,GAAG;AACbgE,UAAI,EAAE,KAAKA;AADE,KAAf;AAGA,UAAM/D,UAAU,GAAG,MAAMF,SAAN,EAAnB;AACAG,UAAM,CAACC,MAAP,CAAcH,MAAd,EAAsBC,UAAtB;AACA,WAAOD,MAAP;AACD;;AApD+B;AAChC;;AACO+D,oBAAY,SAAZ;AAoDT/G,aAAa,CAACqD,aAAd,CAA4B0D,OAA5B;AASA,OAAM,MAAOY,OAAP,SAAuBjH,KAAvB,CAA4B;AAKhCa,cAAYC,IAAZ,EAA8B;AAC5B,UAAMA,IAAI,IAAI,IAAR,GAAe,EAAf,GAAoBA,IAA1B;AACA,SAAKO,eAAL,GAAuB,IAAvB;;AACA,QAAIP,IAAI,IAAI,IAAZ,EAAkB;AAChB,WAAKoG,SAAL,GAAiBpG,IAAI,CAACoG,SAAL,IAAkB,IAAlB,GAAyB,CAAzB,GAA6BpG,IAAI,CAACoG,SAAnD;AACD,KAFD,MAEO;AACL,WAAKA,SAAL,GAAiB,CAAjB;AACD;AACF;;AAED3C,oBAAkB,CAAC/C,UAAD,EAA0B;AAC1C,WAAOA,UAAP;AACD;;AAEDa,WAAS;AACP,UAAME,UAAU,GAAG,MAAMF,SAAN,EAAnB;AACA,UAAMC,MAAM,GAAG;AAAC4E,eAAS,EAAE,KAAKA;AAAjB,KAAf;AACA1E,UAAM,CAACC,MAAP,CAAcH,MAAd,EAAsBC,UAAtB;AACA,WAAOD,MAAP;AACD;;AAED6E,aAAW,CAACrF,MAAD,EAA0BsF,IAA1B,EAAgD;AACzD,UAAM7F,KAAK,GAAGZ,mBAAmB,CAACmB,MAAD,CAAjC;AACA,UAAMuF,IAAI,GAAG,CAAC,CAAd;AACA,WAAOpI,GAAG,CAACG,QAAQ,CAACmC,KAAD,EAAQ,KAAK2F,SAAb,CAAT,EAAkCG,IAAlC,CAAV;AACD;;AAEDxF,MAAI,CAACC,MAAD,EAA0BC,MAA1B,EAAwC;AAC1C,WAAOxC,IAAI,CAAC,MAAK;AACf,WAAKyC,cAAL,CAAoBF,MAApB,EAA4BC,MAA5B;AACA,YAAMR,KAAK,GAAGZ,mBAAmB,CAACmB,MAAD,CAAjC;AACA,YAAMuF,IAAI,GAAG,CAAC,CAAd;AACA,YAAMC,QAAQ,GAAG,IAAjB;AACA,YAAMC,WAAW,GAAGtI,GAAG,CAACG,QAAQ,CAACmC,KAAD,EAAQ,KAAK2F,SAAb,CAAT,EAAkCG,IAAlC,EAAwCC,QAAxC,CAAvB;AACA,YAAMpF,MAAM,GAAG/C,GAAG,CAACoC,KAAD,EAAQrC,IAAI,CAACqI,WAAD,EAAchG,KAAK,CAACiG,KAApB,CAAZ,CAAlB;AACA,aAAOtF,MAAP;AACD,KARU,CAAX;AASD;;AA1C+B;AAChC;;AACO+E,oBAAY,SAAZ;AA0CT3H,aAAa,CAACqD,aAAd,CAA4BsE,OAA5B","names":["any","cast","mul","notEqual","reshape","serialization","tidy","transpose","util","getActivation","serializeActivation","K","getConstraint","serializeConstraint","InputSpec","Layer","ValueError","getInitializer","serializeInitializer","getRegularizer","serializeRegularizer","assertPositiveInteger","mapActivationToFusedKernel","arrayProd","range","getExactlyOneShape","getExactlyOneTensor","Dropout","constructor","args","rate","Math","max","min","noiseShape","seed","supportsMasking","getNoiseShape","input","inputShape","shape","i","length","push","call","inputs","kwargs","invokeCallHook","training","output","inTrainPhase","dropout","getConfig","config","baseConfig","Object","assign","dispose","registerClass","SpatialDropout1D","inputSpec","ndim","Dense","batchInputShape","inputDim","batchSize","units","activation","useBias","kernelInitializer","DEFAULT_KERNEL_INITIALIZER","biasInitializer","DEFAULT_BIAS_INITIALIZER","kernelConstraint","biasConstraint","kernelRegularizer","biasRegularizer","activityRegularizer","minNDim","build","inputLastDim","kernel","addWeight","bias","axes","built","computeOutputShape","outputShape","slice","fusedActivationName","getClassName","dot","read","biasAdd","apply","Flatten","dataFormat","dim","rank","permutation","batchFlatten","Activation","RepeatVector","n","repeat","Reshape","targetShape","isUnknown","fixUnknownDimension","errorMsg","finalShape","known","unknown","originalSize","anyUnknownDims","concat","Permute","dims","Error","Array","isArray","expectedSortedIndices","arraysEqual","sort","JSON","stringify","dimsIncludingBatch","forEach","Masking","maskValue","computeMask","mask","axis","keepDims","booleanMask","dtype"],"sources":["/home/nadimakhtar97/smart-attendance-system/tfjs-layers/src/layers/core.ts"],"sourcesContent":["/**\n * @license\n * Copyright 2018 Google LLC\n *\n * Use of this source code is governed by an MIT-style\n * license that can be found in the LICENSE file or at\n * https://opensource.org/licenses/MIT.\n * =============================================================================\n */\n\n/**\n * TensorFlow.js Layers: Basic Layers.\n */\n\nimport {any, cast, mul, notEqual, reshape, serialization, Tensor, tidy, transpose, util} from '@tensorflow/tfjs-core';\n\nimport {Activation as ActivationFn, getActivation, serializeActivation} from '../activations';\nimport * as K from '../backend/tfjs_backend';\nimport {Constraint, ConstraintIdentifier, getConstraint, serializeConstraint} from '../constraints';\nimport {DisposeResult, InputSpec, Layer, LayerArgs} from '../engine/topology';\nimport {ValueError} from '../errors';\nimport {getInitializer, Initializer, InitializerIdentifier, serializeInitializer} from '../initializers';\nimport {ActivationIdentifier} from '../keras_format/activation_config';\nimport {DataFormat, Shape} from '../keras_format/common';\nimport {LayerConfig} from '../keras_format/topology_config';\nimport {getRegularizer, Regularizer, RegularizerIdentifier, serializeRegularizer} from '../regularizers';\nimport {Kwargs} from '../types';\nimport {assertPositiveInteger, mapActivationToFusedKernel} from '../utils/generic_utils';\nimport {arrayProd, range} from '../utils/math_utils';\nimport {getExactlyOneShape, getExactlyOneTensor} from '../utils/types_utils';\nimport {LayerVariable} from '../variables';\n\nexport declare interface DropoutLayerArgs extends LayerArgs {\n  /** Float between 0 and 1. Fraction of the input units to drop. */\n  rate: number;\n\n  /**\n   * Integer array representing the shape of the binary dropout mask that will\n   * be multiplied with the input.\n   *\n   * For instance, if your inputs have shape `(batchSize, timesteps, features)`\n   * and you want the dropout mask to be the same for all timesteps, you can use\n   * `noise_shape=(batch_size, 1, features)`.\n   */\n  noiseShape?: number[];\n\n  /** An integer to use as random seed. */\n  seed?: number;\n}\n\nexport class Dropout extends Layer {\n  /** @nocollapse */\n  static className = 'Dropout';\n  private readonly rate: number;\n  private readonly noiseShape: number[];\n  private readonly seed: number;\n\n  constructor(args: DropoutLayerArgs) {\n    super(args);\n    this.rate = Math.max(Math.min(args.rate, 1), 0);\n    // So that the scalar doesn't get tidied up between executions.\n    this.noiseShape = args.noiseShape;\n    this.seed = args.seed;\n    this.supportsMasking = true;\n  }\n\n  protected getNoiseShape(input: Tensor): Shape {\n    if (this.noiseShape == null) {\n      return this.noiseShape;\n    }\n    const inputShape = input.shape;\n    const noiseShape: Shape = [];\n    for (let i = 0; i < this.noiseShape.length; ++i) {\n      noiseShape.push(\n          this.noiseShape[i] == null ? inputShape[i] : this.noiseShape[i]);\n    }\n    return noiseShape;\n  }\n\n  call(inputs: Tensor|Tensor[], kwargs: Kwargs): Tensor|Tensor[] {\n    return tidy(() => {\n      this.invokeCallHook(inputs, kwargs);\n      const input = getExactlyOneTensor(inputs);\n      if (0 < this.rate && this.rate < 1) {\n        const training =\n            kwargs['training'] == null ? false : kwargs['training'];\n        const noiseShape = this.getNoiseShape(input);\n        const output = K.inTrainPhase(\n            () => K.dropout(input, this.rate, noiseShape, this.seed),\n            () => input, training);\n        return output;\n      }\n      return inputs;\n    });\n  }\n\n  getConfig(): serialization.ConfigDict {\n    const config = {\n      rate: this.rate,\n      noiseShape: this.noiseShape,\n      seed: this.seed,\n    };\n    const baseConfig = super.getConfig();\n    Object.assign(config, baseConfig);\n    return config;\n  }\n\n  dispose(): DisposeResult {\n    return super.dispose();\n  }\n}\nserialization.registerClass(Dropout);\n\nexport declare interface DenseLayerArgs extends LayerArgs {\n  /** Positive integer, dimensionality of the output space. */\n  units: number;\n  /**\n   * Activation function to use.\n   *\n   * If unspecified, no activation is applied.\n   */\n  activation?: ActivationIdentifier;\n  /** Whether to apply a bias. */\n  useBias?: boolean;\n  /**\n   * Initializer for the dense kernel weights matrix.\n   */\n  kernelInitializer?: InitializerIdentifier|Initializer;\n  /**\n   * Initializer for the bias vector.\n   */\n  biasInitializer?: InitializerIdentifier|Initializer;\n  /**\n   * If specified, defines inputShape as `[inputDim]`.\n   */\n  inputDim?: number;\n\n  /**\n   * Constraint for the kernel weights.\n   */\n  kernelConstraint?: ConstraintIdentifier|Constraint;\n\n  /**\n   * Constraint for the bias vector.\n   */\n  biasConstraint?: ConstraintIdentifier|Constraint;\n\n  /**\n   * Regularizer function applied to the dense kernel weights matrix.\n   */\n  kernelRegularizer?: RegularizerIdentifier|Regularizer;\n\n  /**\n   * Regularizer function applied to the bias vector.\n   */\n  biasRegularizer?: RegularizerIdentifier|Regularizer;\n\n  /**\n   * Regularizer function applied to the activation.\n   */\n  activityRegularizer?: RegularizerIdentifier|Regularizer;\n}\n\nexport interface SpatialDropout1DLayerConfig extends LayerConfig {\n  /** Float between 0 and 1. Fraction of the input units to drop. */\n  rate: number;\n\n  /** An integer to use as random seed. */\n  seed?: number;\n}\n\nexport class SpatialDropout1D extends Dropout {\n  /** @nocollapse */\n  static className = 'SpatialDropout1D';\n\n  constructor(args: SpatialDropout1DLayerConfig) {\n    super(args);\n    this.inputSpec = [{ndim: 3}];\n  }\n\n  protected getNoiseShape(input: Tensor): Shape {\n    const inputShape = input.shape;\n    return [inputShape[0], 1, inputShape[2]];\n  }\n}\nserialization.registerClass(SpatialDropout1D);\n\nexport class Dense extends Layer {\n  /** @nocollapse */\n  static className = 'Dense';\n  private units: number;\n  // Default activation: Linear (none).\n  private activation: ActivationFn = null;\n  private useBias = true;\n  private kernelInitializer: Initializer;\n  private biasInitializer: Initializer;\n  private kernel: LayerVariable = null;\n  private bias: LayerVariable = null;\n\n  readonly DEFAULT_KERNEL_INITIALIZER: InitializerIdentifier = 'glorotNormal';\n  readonly DEFAULT_BIAS_INITIALIZER: InitializerIdentifier = 'zeros';\n  private readonly kernelConstraint?: Constraint;\n  private readonly biasConstraint?: Constraint;\n  private readonly kernelRegularizer?: Regularizer;\n  private readonly biasRegularizer?: Regularizer;\n\n  constructor(args: DenseLayerArgs) {\n    super(args);\n    if (args.batchInputShape == null && args.inputShape == null &&\n        args.inputDim != null) {\n      // This logic is copied from Layer's constructor, since we can't\n      // do exactly what the Python constructor does for Dense().\n      let batchSize: number = null;\n      if (args.batchSize != null) {\n        batchSize = args.batchSize;\n      }\n      this.batchInputShape = [batchSize, args.inputDim];\n    }\n\n    this.units = args.units;\n    assertPositiveInteger(this.units, 'units');\n    this.activation = getActivation(args.activation);\n    if (args.useBias != null) {\n      this.useBias = args.useBias;\n    }\n    this.kernelInitializer = getInitializer(\n        args.kernelInitializer || this.DEFAULT_KERNEL_INITIALIZER);\n    this.biasInitializer =\n        getInitializer(args.biasInitializer || this.DEFAULT_BIAS_INITIALIZER);\n    this.kernelConstraint = getConstraint(args.kernelConstraint);\n    this.biasConstraint = getConstraint(args.biasConstraint);\n    this.kernelRegularizer = getRegularizer(args.kernelRegularizer);\n    this.biasRegularizer = getRegularizer(args.biasRegularizer);\n    this.activityRegularizer = getRegularizer(args.activityRegularizer);\n    this.supportsMasking = true;\n\n    this.inputSpec = [{minNDim: 2}];\n  }\n\n  public build(inputShape: Shape|Shape[]): void {\n    inputShape = getExactlyOneShape(inputShape);\n    const inputLastDim = inputShape[inputShape.length - 1];\n    if (this.kernel == null) {\n      this.kernel = this.addWeight(\n          'kernel', [inputLastDim, this.units], null, this.kernelInitializer,\n          this.kernelRegularizer, true, this.kernelConstraint);\n      if (this.useBias) {\n        this.bias = this.addWeight(\n            'bias', [this.units], null, this.biasInitializer,\n            this.biasRegularizer, true, this.biasConstraint);\n      }\n    }\n\n    this.inputSpec = [{minNDim: 2, axes: {[-1]: inputLastDim}}];\n    this.built = true;\n  }\n\n  computeOutputShape(inputShape: Shape|Shape[]): Shape|Shape[] {\n    inputShape = getExactlyOneShape(inputShape);\n    const outputShape = inputShape.slice();\n    outputShape[outputShape.length - 1] = this.units;\n    return outputShape;\n  }\n\n  call(inputs: Tensor|Tensor[], kwargs: Kwargs): Tensor|Tensor[] {\n    return tidy(() => {\n      this.invokeCallHook(inputs, kwargs);\n      // Dense layer accepts only a single input.\n      const input = getExactlyOneTensor(inputs);\n      const fusedActivationName =\n          mapActivationToFusedKernel(this.activation.getClassName());\n      let output: Tensor;\n\n      if (fusedActivationName != null) {\n        output = K.dot(\n            input, this.kernel.read(), fusedActivationName,\n            this.bias ? this.bias.read() : null);\n      } else {\n        output = K.dot(input, this.kernel.read());\n        if (this.bias != null) {\n          output = K.biasAdd(output, this.bias.read());\n        }\n        if (this.activation != null) {\n          output = this.activation.apply(output);\n        }\n      }\n\n      return output;\n    });\n  }\n\n  getConfig(): serialization.ConfigDict {\n    const config: serialization.ConfigDict = {\n      units: this.units,\n      activation: serializeActivation(this.activation),\n      useBias: this.useBias,\n      kernelInitializer: serializeInitializer(this.kernelInitializer),\n      biasInitializer: serializeInitializer(this.biasInitializer),\n      kernelRegularizer: serializeRegularizer(this.kernelRegularizer),\n      biasRegularizer: serializeRegularizer(this.biasRegularizer),\n      activityRegularizer: serializeRegularizer(this.activityRegularizer),\n      kernelConstraint: serializeConstraint(this.kernelConstraint),\n      biasConstraint: serializeConstraint(this.biasConstraint)\n    };\n    const baseConfig = super.getConfig();\n    Object.assign(config, baseConfig);\n    return config;\n  }\n}\nserialization.registerClass(Dense);\n\nexport declare interface FlattenLayerArgs extends LayerArgs {\n  /** Image data format: channeLast (default) or channelFirst. */\n  dataFormat?: DataFormat;\n}\n\nexport class Flatten extends Layer {\n  private dataFormat: DataFormat;\n\n  /** @nocollapse */\n  static className = 'Flatten';\n  constructor(args?: FlattenLayerArgs) {\n    args = args || {};\n    super(args);\n    this.inputSpec = [{minNDim: 3}];\n    this.dataFormat = args.dataFormat;\n  }\n\n  computeOutputShape(inputShape: Shape|Shape[]): Shape|Shape[] {\n    inputShape = getExactlyOneShape(inputShape);\n    for (const dim of inputShape.slice(1)) {\n      if (dim == null) {\n        throw new ValueError(\n            `The shape of the input to \"Flatten\" is not fully defined ` +\n            `(got ${inputShape.slice(1)}). Make sure to pass a complete ` +\n            `\"input_shape\" or \"batch_input_shape\" argument to the first ` +\n            `layer in your model.`);\n      }\n    }\n    return [inputShape[0], arrayProd(inputShape, 1)];\n  }\n\n  call(inputs: Tensor|Tensor[], kwargs: Kwargs): Tensor|Tensor[] {\n    return tidy(() => {\n      this.invokeCallHook(inputs, kwargs);\n\n      let input = getExactlyOneTensor(inputs);\n      if (this.dataFormat === 'channelsFirst' && input.rank > 1) {\n        const permutation: number[] = [0];\n        for (let i = 2; i < input.rank; ++i) {\n          permutation.push(i);\n        }\n        permutation.push(1);\n        input = transpose(input, permutation);\n      }\n\n      return K.batchFlatten(input);\n    });\n  }\n\n  getConfig(): serialization.ConfigDict {\n    const config: serialization.ConfigDict = {};\n    if (this.dataFormat != null) {\n      config['dataFormat'] = this.dataFormat;\n    }\n    const baseConfig = super.getConfig();\n    Object.assign(config, baseConfig);\n    return config;\n  }\n}\nserialization.registerClass(Flatten);\n\nexport declare interface ActivationLayerArgs extends LayerArgs {\n  /**\n   * Name of the activation function to use.\n   */\n  activation: ActivationIdentifier;\n}\n\nexport class Activation extends Layer {\n  /** @nocollapse */\n  static className = 'Activation';\n  activation: ActivationFn;\n\n  constructor(args: ActivationLayerArgs) {\n    super(args);\n    this.supportsMasking = true;\n    this.activation = getActivation(args.activation);\n  }\n\n  call(inputs: Tensor|Tensor[], kwargs: Kwargs): Tensor|Tensor[] {\n    return tidy(() => {\n      this.invokeCallHook(inputs, kwargs);\n      const input = getExactlyOneTensor(inputs);\n      return this.activation.apply(input);\n    });\n  }\n\n  getConfig(): serialization.ConfigDict {\n    const config = {activation: serializeActivation(this.activation)};\n    const baseConfig = super.getConfig();\n    Object.assign(config, baseConfig);\n    return config;\n  }\n}\nserialization.registerClass(Activation);\n\nexport declare interface ReshapeLayerArgs extends LayerArgs {\n  /** The target shape. Does not include the batch axis. */\n  targetShape: Shape;\n}\n\nexport declare interface RepeatVectorLayerArgs extends LayerArgs {\n  /**\n   * The integer number of times to repeat the input.\n   */\n  n: number;\n}\n\nexport class RepeatVector extends Layer {\n  /** @nocollapse */\n  static className = 'RepeatVector';\n  readonly n: number;\n\n  constructor(args: RepeatVectorLayerArgs) {\n    super(args);\n    this.n = args.n;\n    this.inputSpec = [{ndim: 2}];\n  }\n\n  computeOutputShape(inputShape: Shape): Shape {\n    return [inputShape[0], this.n, inputShape[1]];\n  }\n\n  call(inputs: Tensor|Tensor[], kwargs: Kwargs): Tensor|Tensor[] {\n    return tidy(() => {\n      inputs = getExactlyOneTensor(inputs);\n      return K.repeat(inputs, this.n);\n    });\n  }\n\n  getConfig(): serialization.ConfigDict {\n    const config = {\n      n: this.n,\n    };\n    const baseConfig = super.getConfig();\n    Object.assign(config, baseConfig);\n    return config;\n  }\n}\nserialization.registerClass(RepeatVector);\n\nexport class Reshape extends Layer {\n  /** @nocollapse */\n  static className = 'Reshape';\n  private targetShape: Shape;\n\n  constructor(args: ReshapeLayerArgs) {\n    super(args);\n    this.targetShape = args.targetShape;\n\n    // Make sure that all unknown dimensions are represented as `null`.\n    for (let i = 0; i < this.targetShape.length; ++i) {\n      if (this.isUnknown(this.targetShape[i])) {\n        this.targetShape[i] = null;\n      }\n    }\n  }\n\n  private isUnknown(dim: number): boolean {\n    return dim < 0 || dim == null;\n  }\n\n  /**\n   * Finds and replaces a missing dimension in output shape.\n   *\n   * This is a near direct port of the internal Numpy function\n   * `_fix_unknown_dimension` in `numpy/core/src/multiarray/shape.c`.\n   *\n   * @param inputShape: Original shape of array begin reshape.\n   * @param outputShape: Target shape of the array, with at most a single\n   * `null` or negative number, which indicates an underdetermined dimension\n   * that should be derived from `inputShape` and the known dimensions of\n   *   `outputShape`.\n   * @returns: The output shape with `null` replaced with its computed value.\n   * @throws: ValueError: If `inputShape` and `outputShape` do not match.\n   */\n  private fixUnknownDimension(inputShape: Shape, outputShape: Shape): Shape {\n    const errorMsg = 'Total size of new array must be unchanged.';\n    const finalShape = outputShape.slice();\n    let known = 1;\n    let unknown = null;\n    for (let i = 0; i < finalShape.length; ++i) {\n      const dim = finalShape[i];\n      if (this.isUnknown(dim)) {\n        if (unknown === null) {\n          unknown = i;\n        } else {\n          throw new ValueError('Can only specifiy one unknown dimension.');\n        }\n      } else {\n        known *= dim;\n      }\n    }\n\n    const originalSize = arrayProd(inputShape);\n    if (unknown !== null) {\n      if (known === 0 || originalSize % known !== 0) {\n        throw new ValueError(errorMsg);\n      }\n      finalShape[unknown] = originalSize / known;\n    } else if (originalSize !== known) {\n      throw new ValueError(errorMsg);\n    }\n\n    return finalShape;\n  }\n\n  computeOutputShape(inputShape: Shape): Shape {\n    let anyUnknownDims = false;\n    for (let i = 0; i < inputShape.length; ++i) {\n      if (this.isUnknown(inputShape[i])) {\n        anyUnknownDims = true;\n        break;\n      }\n    }\n\n    if (anyUnknownDims) {\n      return inputShape.slice(0, 1).concat(this.targetShape);\n    } else {\n      return inputShape.slice(0, 1).concat(\n          this.fixUnknownDimension(inputShape.slice(1), this.targetShape));\n    }\n  }\n\n  call(inputs: Tensor|Tensor[], kwargs: Kwargs): Tensor|Tensor[] {\n    return tidy(() => {\n      this.invokeCallHook(inputs, kwargs);\n      const input = getExactlyOneTensor(inputs);\n      const inputShape = input.shape;\n      const outputShape = inputShape.slice(0, 1).concat(\n          this.fixUnknownDimension(inputShape.slice(1), this.targetShape));\n      return reshape(input, outputShape);\n    });\n  }\n\n  getConfig(): serialization.ConfigDict {\n    const config = {\n      targetShape: this.targetShape,\n    };\n    const baseConfig = super.getConfig();\n    Object.assign(config, baseConfig);\n    return config;\n  }\n}\nserialization.registerClass(Reshape);\n\nexport declare interface PermuteLayerArgs extends LayerArgs {\n  /**\n   * Array of integers. Permutation pattern. Does not include the\n   * sample (batch) dimension. Index starts at 1.\n   * For instance, `[2, 1]` permutes the first and second dimensions\n   * of the input.\n   */\n  dims: number[];\n}\n\nexport class Permute extends Layer {\n  /** @nocollapse */\n  static className = 'Permute';\n  readonly dims: number[];\n  private readonly dimsIncludingBatch: number[];\n\n  constructor(args: PermuteLayerArgs) {\n    super(args);\n    if (args.dims == null) {\n      throw new Error(\n          'Required configuration field `dims` is missing during Permute ' +\n          'constructor call.');\n    }\n    if (!Array.isArray(args.dims)) {\n      throw new Error(\n          'Permute constructor requires `dims` to be an Array, but received ' +\n          `${args.dims} instead.`);\n    }\n\n    // Check the validity of the permutation indices.\n    const expectedSortedIndices = range(1, args.dims.length + 1);\n    if (!util.arraysEqual(args.dims.slice().sort(), expectedSortedIndices)) {\n      throw new Error(\n          'Invalid permutation `dims`: ' + JSON.stringify(args.dims) +\n          ' `dims` must contain consecutive integers starting from 1.');\n    }\n\n    this.dims = args.dims;\n    this.dimsIncludingBatch = [0].concat(this.dims);\n    this.inputSpec = [new InputSpec({ndim: this.dims.length + 1})];\n  }\n\n  computeOutputShape(inputShape: Shape|Shape[]): Shape|Shape[] {\n    inputShape = getExactlyOneShape(inputShape);\n    const outputShape = inputShape.slice();\n    this.dims.forEach((dim: number, i: number) => {\n      outputShape[i + 1] = (inputShape as Shape)[dim];\n    });\n    return outputShape;\n  }\n\n  call(inputs: Tensor|Tensor[], kwargs: Kwargs): Tensor|Tensor[] {\n    return transpose(getExactlyOneTensor(inputs), this.dimsIncludingBatch);\n  }\n\n  getConfig(): serialization.ConfigDict {\n    const config = {\n      dims: this.dims,\n    };\n    const baseConfig = super.getConfig();\n    Object.assign(config, baseConfig);\n    return config;\n  }\n}\nserialization.registerClass(Permute);\n\nexport declare interface MaskingArgs extends LayerArgs {\n  /**\n   * Masking Value. Defaults to `0.0`.\n   */\n  maskValue?: number;\n}\n\nexport class Masking extends Layer {\n  /** @nocollapse */\n  static className = 'Masking';\n  maskValue: number;\n\n  constructor(args?: MaskingArgs) {\n    super(args == null ? {} : args);\n    this.supportsMasking = true;\n    if (args != null) {\n      this.maskValue = args.maskValue == null ? 0 : args.maskValue;\n    } else {\n      this.maskValue = 0;\n    }\n  }\n\n  computeOutputShape(inputShape: Shape|Shape[]): Shape|Shape[] {\n    return inputShape;\n  }\n\n  getConfig() {\n    const baseConfig = super.getConfig();\n    const config = {maskValue: this.maskValue};\n    Object.assign(config, baseConfig);\n    return config;\n  }\n\n  computeMask(inputs: Tensor|Tensor[], mask?: Tensor|Tensor[]): Tensor {\n    const input = getExactlyOneTensor(inputs);\n    const axis = -1;\n    return any(notEqual(input, this.maskValue), axis);\n  }\n\n  call(inputs: Tensor|Tensor[], kwargs: Kwargs): Tensor|Tensor[] {\n    return tidy(() => {\n      this.invokeCallHook(inputs, kwargs);\n      const input = getExactlyOneTensor(inputs);\n      const axis = -1;\n      const keepDims = true;\n      const booleanMask = any(notEqual(input, this.maskValue), axis, keepDims);\n      const output = mul(input, cast(booleanMask, input.dtype));\n      return output;\n    });\n  }\n}\nserialization.registerClass(Masking);\n"]},"metadata":{},"sourceType":"module"}