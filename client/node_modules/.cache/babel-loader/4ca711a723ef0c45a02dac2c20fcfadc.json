{"ast":null,"code":"/**\n * @license\n * Copyright 2018 Google LLC\n *\n * Use of this source code is governed by an MIT-style\n * license that can be found in the LICENSE file or at\n * https://opensource.org/licenses/MIT.\n * =============================================================================\n */\nimport { eye, linalg, mul, ones, randomUniform, scalar, serialization, tidy, transpose, truncatedNormal, zeros } from '@tensorflow/tfjs-core';\nimport * as K from './backend/tfjs_backend';\nimport { checkDataFormat } from './common';\nimport { NotImplementedError, ValueError } from './errors';\nimport { VALID_DISTRIBUTION_VALUES, VALID_FAN_MODE_VALUES } from './keras_format/initializer_config';\nimport { checkStringTypeUnionValue, deserializeKerasObject, serializeKerasObject } from './utils/generic_utils';\nimport { arrayProd } from './utils/math_utils';\nexport function checkFanMode(value) {\n  checkStringTypeUnionValue(VALID_FAN_MODE_VALUES, 'FanMode', value);\n}\nexport function checkDistribution(value) {\n  checkStringTypeUnionValue(VALID_DISTRIBUTION_VALUES, 'Distribution', value);\n}\n/**\n * Initializer base class.\n *\n * @doc {\n *   heading: 'Initializers', subheading: 'Classes', namespace: 'initializers'}\n */\n\nexport class Initializer extends serialization.Serializable {\n  fromConfigUsesCustomObjects() {\n    return false;\n  }\n\n  getConfig() {\n    return {};\n  }\n\n}\nexport class Zeros extends Initializer {\n  apply(shape, dtype) {\n    return zeros(shape, dtype);\n  }\n\n}\n/** @nocollapse */\n\nZeros.className = 'Zeros';\nserialization.registerClass(Zeros);\nexport class Ones extends Initializer {\n  apply(shape, dtype) {\n    return ones(shape, dtype);\n  }\n\n}\n/** @nocollapse */\n\nOnes.className = 'Ones';\nserialization.registerClass(Ones);\nexport class Constant extends Initializer {\n  constructor(args) {\n    super();\n\n    if (typeof args !== 'object') {\n      throw new ValueError(`Expected argument of type ConstantConfig but got ${args}`);\n    }\n\n    if (args.value === undefined) {\n      throw new ValueError(`config must have value set but got ${args}`);\n    }\n\n    this.value = args.value;\n  }\n\n  apply(shape, dtype) {\n    return tidy(() => mul(scalar(this.value), ones(shape, dtype)));\n  }\n\n  getConfig() {\n    return {\n      value: this.value\n    };\n  }\n\n}\n/** @nocollapse */\n\nConstant.className = 'Constant';\nserialization.registerClass(Constant);\nexport class RandomUniform extends Initializer {\n  constructor(args) {\n    super();\n    this.DEFAULT_MINVAL = -0.05;\n    this.DEFAULT_MAXVAL = 0.05;\n    this.minval = args.minval || this.DEFAULT_MINVAL;\n    this.maxval = args.maxval || this.DEFAULT_MAXVAL;\n    this.seed = args.seed;\n  }\n\n  apply(shape, dtype) {\n    return randomUniform(shape, this.minval, this.maxval, dtype);\n  }\n\n  getConfig() {\n    return {\n      minval: this.minval,\n      maxval: this.maxval,\n      seed: this.seed\n    };\n  }\n\n}\n/** @nocollapse */\n\nRandomUniform.className = 'RandomUniform';\nserialization.registerClass(RandomUniform);\nexport class RandomNormal extends Initializer {\n  constructor(args) {\n    super();\n    this.DEFAULT_MEAN = 0.;\n    this.DEFAULT_STDDEV = 0.05;\n    this.mean = args.mean || this.DEFAULT_MEAN;\n    this.stddev = args.stddev || this.DEFAULT_STDDEV;\n    this.seed = args.seed;\n  }\n\n  apply(shape, dtype) {\n    dtype = dtype || 'float32';\n\n    if (dtype !== 'float32' && dtype !== 'int32') {\n      throw new NotImplementedError(`randomNormal does not support dType ${dtype}.`);\n    }\n\n    return K.randomNormal(shape, this.mean, this.stddev, dtype, this.seed);\n  }\n\n  getConfig() {\n    return {\n      mean: this.mean,\n      stddev: this.stddev,\n      seed: this.seed\n    };\n  }\n\n}\n/** @nocollapse */\n\nRandomNormal.className = 'RandomNormal';\nserialization.registerClass(RandomNormal);\nexport class TruncatedNormal extends Initializer {\n  constructor(args) {\n    super();\n    this.DEFAULT_MEAN = 0.;\n    this.DEFAULT_STDDEV = 0.05;\n    this.mean = args.mean || this.DEFAULT_MEAN;\n    this.stddev = args.stddev || this.DEFAULT_STDDEV;\n    this.seed = args.seed;\n  }\n\n  apply(shape, dtype) {\n    dtype = dtype || 'float32';\n\n    if (dtype !== 'float32' && dtype !== 'int32') {\n      throw new NotImplementedError(`truncatedNormal does not support dType ${dtype}.`);\n    }\n\n    return truncatedNormal(shape, this.mean, this.stddev, dtype, this.seed);\n  }\n\n  getConfig() {\n    return {\n      mean: this.mean,\n      stddev: this.stddev,\n      seed: this.seed\n    };\n  }\n\n}\n/** @nocollapse */\n\nTruncatedNormal.className = 'TruncatedNormal';\nserialization.registerClass(TruncatedNormal);\nexport class Identity extends Initializer {\n  constructor(args) {\n    super();\n    this.gain = args.gain != null ? args.gain : 1.0;\n  }\n\n  apply(shape, dtype) {\n    return tidy(() => {\n      if (shape.length !== 2 || shape[0] !== shape[1]) {\n        throw new ValueError('Identity matrix initializer can only be used for' + ' 2D square matrices.');\n      } else {\n        return mul(this.gain, eye(shape[0]));\n      }\n    });\n  }\n\n  getConfig() {\n    return {\n      gain: this.gain\n    };\n  }\n\n}\n/** @nocollapse */\n\nIdentity.className = 'Identity';\nserialization.registerClass(Identity);\n/**\n * Computes the number of input and output units for a weight shape.\n * @param shape Shape of weight.\n * @param dataFormat data format to use for convolution kernels.\n *   Note that all kernels in Keras are standardized on the\n *   CHANNEL_LAST ordering (even when inputs are set to CHANNEL_FIRST).\n * @return An length-2 array: fanIn, fanOut.\n */\n\nfunction computeFans(shape) {\n  let dataFormat = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : 'channelsLast';\n  let fanIn;\n  let fanOut;\n  checkDataFormat(dataFormat);\n\n  if (shape.length === 2) {\n    fanIn = shape[0];\n    fanOut = shape[1];\n  } else if ([3, 4, 5].indexOf(shape.length) !== -1) {\n    if (dataFormat === 'channelsFirst') {\n      const receptiveFieldSize = arrayProd(shape, 2);\n      fanIn = shape[1] * receptiveFieldSize;\n      fanOut = shape[0] * receptiveFieldSize;\n    } else if (dataFormat === 'channelsLast') {\n      const receptiveFieldSize = arrayProd(shape, 0, shape.length - 2);\n      fanIn = shape[shape.length - 2] * receptiveFieldSize;\n      fanOut = shape[shape.length - 1] * receptiveFieldSize;\n    }\n  } else {\n    const shapeProd = arrayProd(shape);\n    fanIn = Math.sqrt(shapeProd);\n    fanOut = Math.sqrt(shapeProd);\n  }\n\n  return [fanIn, fanOut];\n}\n\nexport class VarianceScaling extends Initializer {\n  /**\n   * Constructor of VarianceScaling.\n   * @throws ValueError for invalid value in scale.\n   */\n  constructor(args) {\n    super();\n\n    if (args.scale < 0.0) {\n      throw new ValueError(`scale must be a positive float. Got: ${args.scale}`);\n    }\n\n    this.scale = args.scale == null ? 1.0 : args.scale;\n    this.mode = args.mode == null ? 'fanIn' : args.mode;\n    checkFanMode(this.mode);\n    this.distribution = args.distribution == null ? 'normal' : args.distribution;\n    checkDistribution(this.distribution);\n    this.seed = args.seed;\n  }\n\n  apply(shape, dtype) {\n    const fans = computeFans(shape);\n    const fanIn = fans[0];\n    const fanOut = fans[1];\n    let scale = this.scale;\n\n    if (this.mode === 'fanIn') {\n      scale /= Math.max(1, fanIn);\n    } else if (this.mode === 'fanOut') {\n      scale /= Math.max(1, fanOut);\n    } else {\n      scale /= Math.max(1, (fanIn + fanOut) / 2);\n    }\n\n    if (this.distribution === 'normal') {\n      const stddev = Math.sqrt(scale);\n      dtype = dtype || 'float32';\n\n      if (dtype !== 'float32' && dtype !== 'int32') {\n        throw new NotImplementedError(`${this.getClassName()} does not support dType ${dtype}.`);\n      }\n\n      return truncatedNormal(shape, 0, stddev, dtype, this.seed);\n    } else {\n      const limit = Math.sqrt(3 * scale);\n      return randomUniform(shape, -limit, limit, dtype);\n    }\n  }\n\n  getConfig() {\n    return {\n      scale: this.scale,\n      mode: this.mode,\n      distribution: this.distribution,\n      seed: this.seed\n    };\n  }\n\n}\n/** @nocollapse */\n\nVarianceScaling.className = 'VarianceScaling';\nserialization.registerClass(VarianceScaling);\nexport class GlorotUniform extends VarianceScaling {\n  /**\n   * Constructor of GlorotUniform\n   * @param scale\n   * @param mode\n   * @param distribution\n   * @param seed\n   */\n  constructor(args) {\n    super({\n      scale: 1.0,\n      mode: 'fanAvg',\n      distribution: 'uniform',\n      seed: args == null ? null : args.seed\n    });\n  }\n\n  getClassName() {\n    // In Python Keras, GlorotUniform is not a class, but a helper method\n    // that creates a VarianceScaling object. Use 'VarianceScaling' as\n    // class name to be compatible with that.\n    return VarianceScaling.className;\n  }\n\n}\n/** @nocollapse */\n\nGlorotUniform.className = 'GlorotUniform';\nserialization.registerClass(GlorotUniform);\nexport class GlorotNormal extends VarianceScaling {\n  /**\n   * Constructor of GlorotNormal.\n   * @param scale\n   * @param mode\n   * @param distribution\n   * @param seed\n   */\n  constructor(args) {\n    super({\n      scale: 1.0,\n      mode: 'fanAvg',\n      distribution: 'normal',\n      seed: args == null ? null : args.seed\n    });\n  }\n\n  getClassName() {\n    // In Python Keras, GlorotNormal is not a class, but a helper method\n    // that creates a VarianceScaling object. Use 'VarianceScaling' as\n    // class name to be compatible with that.\n    return VarianceScaling.className;\n  }\n\n}\n/** @nocollapse */\n\nGlorotNormal.className = 'GlorotNormal';\nserialization.registerClass(GlorotNormal);\nexport class HeNormal extends VarianceScaling {\n  constructor(args) {\n    super({\n      scale: 2.0,\n      mode: 'fanIn',\n      distribution: 'normal',\n      seed: args == null ? null : args.seed\n    });\n  }\n\n  getClassName() {\n    // In Python Keras, HeNormal is not a class, but a helper method\n    // that creates a VarianceScaling object. Use 'VarianceScaling' as\n    // class name to be compatible with that.\n    return VarianceScaling.className;\n  }\n\n}\n/** @nocollapse */\n\nHeNormal.className = 'HeNormal';\nserialization.registerClass(HeNormal);\nexport class HeUniform extends VarianceScaling {\n  constructor(args) {\n    super({\n      scale: 2.0,\n      mode: 'fanIn',\n      distribution: 'uniform',\n      seed: args == null ? null : args.seed\n    });\n  }\n\n  getClassName() {\n    // In Python Keras, HeUniform is not a class, but a helper method\n    // that creates a VarianceScaling object. Use 'VarianceScaling' as\n    // class name to be compatible with that.\n    return VarianceScaling.className;\n  }\n\n}\n/** @nocollapse */\n\nHeUniform.className = 'HeUniform';\nserialization.registerClass(HeUniform);\nexport class LeCunNormal extends VarianceScaling {\n  constructor(args) {\n    super({\n      scale: 1.0,\n      mode: 'fanIn',\n      distribution: 'normal',\n      seed: args == null ? null : args.seed\n    });\n  }\n\n  getClassName() {\n    // In Python Keras, LeCunNormal is not a class, but a helper method\n    // that creates a VarianceScaling object. Use 'VarianceScaling' as\n    // class name to be compatible with that.\n    return VarianceScaling.className;\n  }\n\n}\n/** @nocollapse */\n\nLeCunNormal.className = 'LeCunNormal';\nserialization.registerClass(LeCunNormal);\nexport class LeCunUniform extends VarianceScaling {\n  constructor(args) {\n    super({\n      scale: 1.0,\n      mode: 'fanIn',\n      distribution: 'uniform',\n      seed: args == null ? null : args.seed\n    });\n  }\n\n  getClassName() {\n    // In Python Keras, LeCunUniform is not a class, but a helper method\n    // that creates a VarianceScaling object. Use 'VarianceScaling' as\n    // class name to be compatible with that.\n    return VarianceScaling.className;\n  }\n\n}\n/** @nocollapse */\n\nLeCunUniform.className = 'LeCunNormal';\nserialization.registerClass(LeCunUniform);\nexport class Orthogonal extends Initializer {\n  constructor(args) {\n    super();\n    this.DEFAULT_GAIN = 1;\n    this.gain = args.gain == null ? this.DEFAULT_GAIN : args.gain;\n    this.seed = args.seed;\n\n    if (this.seed != null) {\n      throw new NotImplementedError('Random seed is not implemented for Orthogonal Initializer yet.');\n    }\n  }\n\n  apply(shape, dtype) {\n    return tidy(() => {\n      if (shape.length < 2) {\n        throw new NotImplementedError('Shape must be at least 2D.');\n      }\n\n      if (shape[0] * shape[1] > 2000) {\n        console.warn(`Orthogonal initializer is being called on a matrix with more ` + `than 2000 (${shape[0] * shape[1]}) elements: ` + `Slowness may result.`);\n      } // TODO(cais): Add seed support.\n\n\n      const normalizedShape = shape[0] > shape[1] ? [shape[1], shape[0]] : shape;\n      const a = K.randomNormal(normalizedShape, 0, 1, 'float32');\n      let q = linalg.gramSchmidt(a);\n\n      if (shape[0] > shape[1]) {\n        q = transpose(q);\n      }\n\n      return mul(this.gain, q);\n    });\n  }\n\n  getConfig() {\n    return {\n      gain: this.gain,\n      seed: this.seed\n    };\n  }\n\n}\n/** @nocollapse */\n\nOrthogonal.className = 'Orthogonal';\nserialization.registerClass(Orthogonal); // Maps the JavaScript-like identifier keys to the corresponding registry\n// symbols.\n\nexport const INITIALIZER_IDENTIFIER_REGISTRY_SYMBOL_MAP = {\n  'constant': 'Constant',\n  'glorotNormal': 'GlorotNormal',\n  'glorotUniform': 'GlorotUniform',\n  'heNormal': 'HeNormal',\n  'heUniform': 'HeUniform',\n  'identity': 'Identity',\n  'leCunNormal': 'LeCunNormal',\n  'leCunUniform': 'LeCunUniform',\n  'ones': 'Ones',\n  'orthogonal': 'Orthogonal',\n  'randomNormal': 'RandomNormal',\n  'randomUniform': 'RandomUniform',\n  'truncatedNormal': 'TruncatedNormal',\n  'varianceScaling': 'VarianceScaling',\n  'zeros': 'Zeros'\n};\n\nfunction deserializeInitializer(config) {\n  let customObjects = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {};\n  return deserializeKerasObject(config, serialization.SerializationMap.getMap().classNameMap, customObjects, 'initializer');\n}\n\nexport function serializeInitializer(initializer) {\n  return serializeKerasObject(initializer);\n}\nexport function getInitializer(identifier) {\n  if (typeof identifier === 'string') {\n    const className = identifier in INITIALIZER_IDENTIFIER_REGISTRY_SYMBOL_MAP ? INITIALIZER_IDENTIFIER_REGISTRY_SYMBOL_MAP[identifier] : identifier;\n    /* We have four 'helper' classes for common initializers that\n    all get serialized as 'VarianceScaling' and shouldn't go through\n    the deserializeInitializer pathway. */\n\n    if (className === 'GlorotNormal') {\n      return new GlorotNormal();\n    } else if (className === 'GlorotUniform') {\n      return new GlorotUniform();\n    } else if (className === 'HeNormal') {\n      return new HeNormal();\n    } else if (className === 'HeUniform') {\n      return new HeUniform();\n    } else if (className === 'LeCunNormal') {\n      return new LeCunNormal();\n    } else if (className === 'LeCunUniform') {\n      return new LeCunUniform();\n    } else {\n      const config = {};\n      config['className'] = className;\n      config['config'] = {};\n      return deserializeInitializer(config);\n    }\n  } else if (identifier instanceof Initializer) {\n    return identifier;\n  } else {\n    return deserializeInitializer(identifier);\n  }\n}","map":{"version":3,"mappings":"AAAA;;;;;;;;;AAUA,SAAkBA,GAAlB,EAAuBC,MAAvB,EAA+BC,GAA/B,EAAoCC,IAApC,EAA0CC,aAA1C,EAAyDC,MAAzD,EAAiEC,aAAjE,EAAkGC,IAAlG,EAAwGC,SAAxG,EAAmHC,eAAnH,EAAoIC,KAApI,QAAgJ,uBAAhJ;AAEA,OAAO,KAAKC,CAAZ,MAAmB,wBAAnB;AACA,SAAQC,eAAR,QAA8B,UAA9B;AACA,SAAQC,mBAAR,EAA6BC,UAA7B,QAA8C,UAA9C;AAEA,SAA+BC,yBAA/B,EAA0DC,qBAA1D,QAAsF,mCAAtF;AACA,SAAQC,yBAAR,EAAmCC,sBAAnC,EAA2DC,oBAA3D,QAAsF,uBAAtF;AACA,SAAQC,SAAR,QAAwB,oBAAxB;AAEA,OAAM,SAAUC,YAAV,CAAuBC,KAAvB,EAAqC;AACzCL,2BAAyB,CAACD,qBAAD,EAAwB,SAAxB,EAAmCM,KAAnC,CAAzB;AACD;AAED,OAAM,SAAUC,iBAAV,CAA4BD,KAA5B,EAA0C;AAC9CL,2BAAyB,CAACF,yBAAD,EAA4B,cAA5B,EAA4CO,KAA5C,CAAzB;AACD;AAED;;;;;;;AAMA,OAAM,MAAgBE,WAAhB,SAAoClB,aAAa,CAACmB,YAAlD,CAA8D;AAC3DC,6BAA2B;AAChC,WAAO,KAAP;AACD;;AASDC,WAAS;AACP,WAAO,EAAP;AACD;;AAdiE;AAiBpE,OAAM,MAAOC,KAAP,SAAqBJ,WAArB,CAAgC;AAIpCK,OAAK,CAACC,KAAD,EAAeC,KAAf,EAA+B;AAClC,WAAOrB,KAAK,CAACoB,KAAD,EAAQC,KAAR,CAAZ;AACD;;AANmC;AACpC;;AACOH,kBAAY,OAAZ;AAMTtB,aAAa,CAAC0B,aAAd,CAA4BJ,KAA5B;AAEA,OAAM,MAAOK,IAAP,SAAoBT,WAApB,CAA+B;AAInCK,OAAK,CAACC,KAAD,EAAeC,KAAf,EAA+B;AAClC,WAAO5B,IAAI,CAAC2B,KAAD,EAAQC,KAAR,CAAX;AACD;;AANkC;AACnC;;AACOE,iBAAY,MAAZ;AAMT3B,aAAa,CAAC0B,aAAd,CAA4BC,IAA5B;AAOA,OAAM,MAAOC,QAAP,SAAwBV,WAAxB,CAAmC;AAIvCW,cAAYC,IAAZ,EAA8B;AAC5B;;AACA,QAAI,OAAOA,IAAP,KAAgB,QAApB,EAA8B;AAC5B,YAAM,IAAItB,UAAJ,CACF,oDAAoDsB,IAAI,EADtD,CAAN;AAED;;AACD,QAAIA,IAAI,CAACd,KAAL,KAAee,SAAnB,EAA8B;AAC5B,YAAM,IAAIvB,UAAJ,CAAe,sCAAsCsB,IAAI,EAAzD,CAAN;AACD;;AACD,SAAKd,KAAL,GAAac,IAAI,CAACd,KAAlB;AACD;;AAEDO,OAAK,CAACC,KAAD,EAAeC,KAAf,EAA+B;AAClC,WAAOxB,IAAI,CAAC,MAAML,GAAG,CAACG,MAAM,CAAC,KAAKiB,KAAN,CAAP,EAAqBnB,IAAI,CAAC2B,KAAD,EAAQC,KAAR,CAAzB,CAAV,CAAX;AACD;;AAEDJ,WAAS;AACP,WAAO;AACLL,WAAK,EAAE,KAAKA;AADP,KAAP;AAGD;;AAxBsC;AACvC;;AACOY,qBAAY,UAAZ;AAwBT5B,aAAa,CAAC0B,aAAd,CAA4BE,QAA5B;AAWA,OAAM,MAAOI,aAAP,SAA6Bd,WAA7B,CAAwC;AAS5CW,cAAYC,IAAZ,EAAmC;AACjC;AAPO,0BAAiB,CAAC,IAAlB;AACA,0BAAiB,IAAjB;AAOP,SAAKG,MAAL,GAAcH,IAAI,CAACG,MAAL,IAAe,KAAKC,cAAlC;AACA,SAAKC,MAAL,GAAcL,IAAI,CAACK,MAAL,IAAe,KAAKC,cAAlC;AACA,SAAKC,IAAL,GAAYP,IAAI,CAACO,IAAjB;AACD;;AAEDd,OAAK,CAACC,KAAD,EAAeC,KAAf,EAA+B;AAClC,WAAO3B,aAAa,CAAC0B,KAAD,EAAQ,KAAKS,MAAb,EAAqB,KAAKE,MAA1B,EAAkCV,KAAlC,CAApB;AACD;;AAEDJ,WAAS;AACP,WAAO;AAACY,YAAM,EAAE,KAAKA,MAAd;AAAsBE,YAAM,EAAE,KAAKA,MAAnC;AAA2CE,UAAI,EAAE,KAAKA;AAAtD,KAAP;AACD;;AAtB2C;AAC5C;;AACOL,0BAAY,eAAZ;AAsBThC,aAAa,CAAC0B,aAAd,CAA4BM,aAA5B;AAWA,OAAM,MAAOM,YAAP,SAA4BpB,WAA5B,CAAuC;AAS3CW,cAAYC,IAAZ,EAAkC;AAChC;AAPO,wBAAe,EAAf;AACA,0BAAiB,IAAjB;AAOP,SAAKS,IAAL,GAAYT,IAAI,CAACS,IAAL,IAAa,KAAKC,YAA9B;AACA,SAAKC,MAAL,GAAcX,IAAI,CAACW,MAAL,IAAe,KAAKC,cAAlC;AACA,SAAKL,IAAL,GAAYP,IAAI,CAACO,IAAjB;AACD;;AAEDd,OAAK,CAACC,KAAD,EAAeC,KAAf,EAA+B;AAClCA,SAAK,GAAGA,KAAK,IAAI,SAAjB;;AACA,QAAIA,KAAK,KAAK,SAAV,IAAuBA,KAAK,KAAK,OAArC,EAA8C;AAC5C,YAAM,IAAIlB,mBAAJ,CACF,uCAAuCkB,KAAK,GAD1C,CAAN;AAED;;AAED,WAAOpB,CAAC,CAACsC,YAAF,CAAenB,KAAf,EAAsB,KAAKe,IAA3B,EAAiC,KAAKE,MAAtC,EAA8ChB,KAA9C,EAAqD,KAAKY,IAA1D,CAAP;AACD;;AAEDhB,WAAS;AACP,WAAO;AAACkB,UAAI,EAAE,KAAKA,IAAZ;AAAkBE,YAAM,EAAE,KAAKA,MAA/B;AAAuCJ,UAAI,EAAE,KAAKA;AAAlD,KAAP;AACD;;AA5B0C;AAC3C;;AACOC,yBAAY,cAAZ;AA4BTtC,aAAa,CAAC0B,aAAd,CAA4BY,YAA5B;AAWA,OAAM,MAAOM,eAAP,SAA+B1B,WAA/B,CAA0C;AAU9CW,cAAYC,IAAZ,EAAqC;AACnC;AAPO,wBAAe,EAAf;AACA,0BAAiB,IAAjB;AAOP,SAAKS,IAAL,GAAYT,IAAI,CAACS,IAAL,IAAa,KAAKC,YAA9B;AACA,SAAKC,MAAL,GAAcX,IAAI,CAACW,MAAL,IAAe,KAAKC,cAAlC;AACA,SAAKL,IAAL,GAAYP,IAAI,CAACO,IAAjB;AACD;;AAEDd,OAAK,CAACC,KAAD,EAAeC,KAAf,EAA+B;AAClCA,SAAK,GAAGA,KAAK,IAAI,SAAjB;;AACA,QAAIA,KAAK,KAAK,SAAV,IAAuBA,KAAK,KAAK,OAArC,EAA8C;AAC5C,YAAM,IAAIlB,mBAAJ,CACF,0CAA0CkB,KAAK,GAD7C,CAAN;AAED;;AACD,WAAOtB,eAAe,CAACqB,KAAD,EAAQ,KAAKe,IAAb,EAAmB,KAAKE,MAAxB,EAAgChB,KAAhC,EAAuC,KAAKY,IAA5C,CAAtB;AACD;;AAEDhB,WAAS;AACP,WAAO;AAACkB,UAAI,EAAE,KAAKA,IAAZ;AAAkBE,YAAM,EAAE,KAAKA,MAA/B;AAAuCJ,UAAI,EAAE,KAAKA;AAAlD,KAAP;AACD;;AA5B6C;AAC9C;;AACOO,4BAAY,iBAAZ;AA4BT5C,aAAa,CAAC0B,aAAd,CAA4BkB,eAA5B;AASA,OAAM,MAAOC,QAAP,SAAwB3B,WAAxB,CAAmC;AAIvCW,cAAYC,IAAZ,EAA8B;AAC5B;AACA,SAAKgB,IAAL,GAAYhB,IAAI,CAACgB,IAAL,IAAa,IAAb,GAAoBhB,IAAI,CAACgB,IAAzB,GAAgC,GAA5C;AACD;;AAEDvB,OAAK,CAACC,KAAD,EAAeC,KAAf,EAA+B;AAClC,WAAOxB,IAAI,CAAC,MAAK;AACf,UAAIuB,KAAK,CAACuB,MAAN,KAAiB,CAAjB,IAAsBvB,KAAK,CAAC,CAAD,CAAL,KAAaA,KAAK,CAAC,CAAD,CAA5C,EAAiD;AAC/C,cAAM,IAAIhB,UAAJ,CACF,qDACA,sBAFE,CAAN;AAGD,OAJD,MAIO;AACL,eAAOZ,GAAG,CAAC,KAAKkD,IAAN,EAAYpD,GAAG,CAAC8B,KAAK,CAAC,CAAD,CAAN,CAAf,CAAV;AACD;AACF,KARU,CAAX;AASD;;AAEDH,WAAS;AACP,WAAO;AAACyB,UAAI,EAAE,KAAKA;AAAZ,KAAP;AACD;;AAvBsC;AACvC;;AACOD,qBAAY,UAAZ;AAuBT7C,aAAa,CAAC0B,aAAd,CAA4BmB,QAA5B;AAEA;;;;;;;;;AAQA,SAASG,WAAT,CACIxB,KADJ,EACyD;AAAA,MAAvCyB,UAAuC,uEAAd,cAAc;AACvD,MAAIC,KAAJ;AACA,MAAIC,MAAJ;AACA7C,iBAAe,CAAC2C,UAAD,CAAf;;AACA,MAAIzB,KAAK,CAACuB,MAAN,KAAiB,CAArB,EAAwB;AACtBG,SAAK,GAAG1B,KAAK,CAAC,CAAD,CAAb;AACA2B,UAAM,GAAG3B,KAAK,CAAC,CAAD,CAAd;AACD,GAHD,MAGO,IAAI,CAAC,CAAD,EAAI,CAAJ,EAAO,CAAP,EAAU4B,OAAV,CAAkB5B,KAAK,CAACuB,MAAxB,MAAoC,CAAC,CAAzC,EAA4C;AACjD,QAAIE,UAAU,KAAK,eAAnB,EAAoC;AAClC,YAAMI,kBAAkB,GAAGvC,SAAS,CAACU,KAAD,EAAQ,CAAR,CAApC;AACA0B,WAAK,GAAG1B,KAAK,CAAC,CAAD,CAAL,GAAW6B,kBAAnB;AACAF,YAAM,GAAG3B,KAAK,CAAC,CAAD,CAAL,GAAW6B,kBAApB;AACD,KAJD,MAIO,IAAIJ,UAAU,KAAK,cAAnB,EAAmC;AACxC,YAAMI,kBAAkB,GAAGvC,SAAS,CAACU,KAAD,EAAQ,CAAR,EAAWA,KAAK,CAACuB,MAAN,GAAe,CAA1B,CAApC;AACAG,WAAK,GAAG1B,KAAK,CAACA,KAAK,CAACuB,MAAN,GAAe,CAAhB,CAAL,GAA0BM,kBAAlC;AACAF,YAAM,GAAG3B,KAAK,CAACA,KAAK,CAACuB,MAAN,GAAe,CAAhB,CAAL,GAA0BM,kBAAnC;AACD;AACF,GAVM,MAUA;AACL,UAAMC,SAAS,GAAGxC,SAAS,CAACU,KAAD,CAA3B;AACA0B,SAAK,GAAGK,IAAI,CAACC,IAAL,CAAUF,SAAV,CAAR;AACAH,UAAM,GAAGI,IAAI,CAACC,IAAL,CAAUF,SAAV,CAAT;AACD;;AAED,SAAO,CAACJ,KAAD,EAAQC,MAAR,CAAP;AACD;;AAgBD,OAAM,MAAOM,eAAP,SAA+BvC,WAA/B,CAA0C;AAQ9C;;;;AAIAW,cAAYC,IAAZ,EAAqC;AACnC;;AACA,QAAIA,IAAI,CAAC4B,KAAL,GAAa,GAAjB,EAAsB;AACpB,YAAM,IAAIlD,UAAJ,CACF,wCAAwCsB,IAAI,CAAC4B,KAAK,EADhD,CAAN;AAED;;AACD,SAAKA,KAAL,GAAa5B,IAAI,CAAC4B,KAAL,IAAc,IAAd,GAAqB,GAArB,GAA2B5B,IAAI,CAAC4B,KAA7C;AACA,SAAKC,IAAL,GAAY7B,IAAI,CAAC6B,IAAL,IAAa,IAAb,GAAoB,OAApB,GAA8B7B,IAAI,CAAC6B,IAA/C;AACA5C,gBAAY,CAAC,KAAK4C,IAAN,CAAZ;AACA,SAAKC,YAAL,GACI9B,IAAI,CAAC8B,YAAL,IAAqB,IAArB,GAA4B,QAA5B,GAAuC9B,IAAI,CAAC8B,YADhD;AAEA3C,qBAAiB,CAAC,KAAK2C,YAAN,CAAjB;AACA,SAAKvB,IAAL,GAAYP,IAAI,CAACO,IAAjB;AACD;;AAEDd,OAAK,CAACC,KAAD,EAAeC,KAAf,EAA+B;AAClC,UAAMoC,IAAI,GAAGb,WAAW,CAACxB,KAAD,CAAxB;AACA,UAAM0B,KAAK,GAAGW,IAAI,CAAC,CAAD,CAAlB;AACA,UAAMV,MAAM,GAAGU,IAAI,CAAC,CAAD,CAAnB;AACA,QAAIH,KAAK,GAAG,KAAKA,KAAjB;;AACA,QAAI,KAAKC,IAAL,KAAc,OAAlB,EAA2B;AACzBD,WAAK,IAAIH,IAAI,CAACO,GAAL,CAAS,CAAT,EAAYZ,KAAZ,CAAT;AACD,KAFD,MAEO,IAAI,KAAKS,IAAL,KAAc,QAAlB,EAA4B;AACjCD,WAAK,IAAIH,IAAI,CAACO,GAAL,CAAS,CAAT,EAAYX,MAAZ,CAAT;AACD,KAFM,MAEA;AACLO,WAAK,IAAIH,IAAI,CAACO,GAAL,CAAS,CAAT,EAAY,CAACZ,KAAK,GAAGC,MAAT,IAAmB,CAA/B,CAAT;AACD;;AAED,QAAI,KAAKS,YAAL,KAAsB,QAA1B,EAAoC;AAClC,YAAMnB,MAAM,GAAGc,IAAI,CAACC,IAAL,CAAUE,KAAV,CAAf;AACAjC,WAAK,GAAGA,KAAK,IAAI,SAAjB;;AACA,UAAIA,KAAK,KAAK,SAAV,IAAuBA,KAAK,KAAK,OAArC,EAA8C;AAC5C,cAAM,IAAIlB,mBAAJ,CACF,GAAG,KAAKwD,YAAL,EAAmB,2BAA2BtC,KAAK,GADpD,CAAN;AAED;;AACD,aAAOtB,eAAe,CAACqB,KAAD,EAAQ,CAAR,EAAWiB,MAAX,EAAmBhB,KAAnB,EAA0B,KAAKY,IAA/B,CAAtB;AACD,KARD,MAQO;AACL,YAAM2B,KAAK,GAAGT,IAAI,CAACC,IAAL,CAAU,IAAIE,KAAd,CAAd;AACA,aAAO5D,aAAa,CAAC0B,KAAD,EAAQ,CAACwC,KAAT,EAAgBA,KAAhB,EAAuBvC,KAAvB,CAApB;AACD;AACF;;AAEDJ,WAAS;AACP,WAAO;AACLqC,WAAK,EAAE,KAAKA,KADP;AAELC,UAAI,EAAE,KAAKA,IAFN;AAGLC,kBAAY,EAAE,KAAKA,YAHd;AAILvB,UAAI,EAAE,KAAKA;AAJN,KAAP;AAMD;;AA7D6C;AAC9C;;AACOoB,4BAAY,iBAAZ;AA6DTzD,aAAa,CAAC0B,aAAd,CAA4B+B,eAA5B;AAOA,OAAM,MAAOQ,aAAP,SAA6BR,eAA7B,CAA4C;AAIhD;;;;;;;AAOA5B,cAAYC,IAAZ,EAA0C;AACxC,UAAM;AACJ4B,WAAK,EAAE,GADH;AAEJC,UAAI,EAAE,QAFF;AAGJC,kBAAY,EAAE,SAHV;AAIJvB,UAAI,EAAEP,IAAI,IAAI,IAAR,GAAe,IAAf,GAAsBA,IAAI,CAACO;AAJ7B,KAAN;AAMD;;AAED0B,cAAY;AACV;AACA;AACA;AACA,WAAON,eAAe,CAACS,SAAvB;AACD;;AAzB+C;AAChD;;AACOD,0BAAY,eAAZ;AAyBTjE,aAAa,CAAC0B,aAAd,CAA4BuC,aAA5B;AAEA,OAAM,MAAOE,YAAP,SAA4BV,eAA5B,CAA2C;AAI/C;;;;;;;AAOA5B,cAAYC,IAAZ,EAA0C;AACxC,UAAM;AACJ4B,WAAK,EAAE,GADH;AAEJC,UAAI,EAAE,QAFF;AAGJC,kBAAY,EAAE,QAHV;AAIJvB,UAAI,EAAEP,IAAI,IAAI,IAAR,GAAe,IAAf,GAAsBA,IAAI,CAACO;AAJ7B,KAAN;AAMD;;AAED0B,cAAY;AACV;AACA;AACA;AACA,WAAON,eAAe,CAACS,SAAvB;AACD;;AAzB8C;AAC/C;;AACOC,yBAAY,cAAZ;AAyBTnE,aAAa,CAAC0B,aAAd,CAA4ByC,YAA5B;AAEA,OAAM,MAAOC,QAAP,SAAwBX,eAAxB,CAAuC;AAI3C5B,cAAYC,IAAZ,EAA0C;AACxC,UAAM;AACJ4B,WAAK,EAAE,GADH;AAEJC,UAAI,EAAE,OAFF;AAGJC,kBAAY,EAAE,QAHV;AAIJvB,UAAI,EAAEP,IAAI,IAAI,IAAR,GAAe,IAAf,GAAsBA,IAAI,CAACO;AAJ7B,KAAN;AAMD;;AAED0B,cAAY;AACV;AACA;AACA;AACA,WAAON,eAAe,CAACS,SAAvB;AACD;;AAlB0C;AAC3C;;AACOE,qBAAY,UAAZ;AAkBTpE,aAAa,CAAC0B,aAAd,CAA4B0C,QAA5B;AAEA,OAAM,MAAOC,SAAP,SAAyBZ,eAAzB,CAAwC;AAI5C5B,cAAYC,IAAZ,EAA0C;AACxC,UAAM;AACJ4B,WAAK,EAAE,GADH;AAEJC,UAAI,EAAE,OAFF;AAGJC,kBAAY,EAAE,SAHV;AAIJvB,UAAI,EAAEP,IAAI,IAAI,IAAR,GAAe,IAAf,GAAsBA,IAAI,CAACO;AAJ7B,KAAN;AAMD;;AAED0B,cAAY;AACV;AACA;AACA;AACA,WAAON,eAAe,CAACS,SAAvB;AACD;;AAlB2C;AAC5C;;AACOG,sBAAY,WAAZ;AAkBTrE,aAAa,CAAC0B,aAAd,CAA4B2C,SAA5B;AAEA,OAAM,MAAOC,WAAP,SAA2Bb,eAA3B,CAA0C;AAI9C5B,cAAYC,IAAZ,EAA0C;AACxC,UAAM;AACJ4B,WAAK,EAAE,GADH;AAEJC,UAAI,EAAE,OAFF;AAGJC,kBAAY,EAAE,QAHV;AAIJvB,UAAI,EAAEP,IAAI,IAAI,IAAR,GAAe,IAAf,GAAsBA,IAAI,CAACO;AAJ7B,KAAN;AAMD;;AAED0B,cAAY;AACV;AACA;AACA;AACA,WAAON,eAAe,CAACS,SAAvB;AACD;;AAlB6C;AAC9C;;AACOI,wBAAY,aAAZ;AAkBTtE,aAAa,CAAC0B,aAAd,CAA4B4C,WAA5B;AAEA,OAAM,MAAOC,YAAP,SAA4Bd,eAA5B,CAA2C;AAI/C5B,cAAYC,IAAZ,EAA0C;AACxC,UAAM;AACJ4B,WAAK,EAAE,GADH;AAEJC,UAAI,EAAE,OAFF;AAGJC,kBAAY,EAAE,SAHV;AAIJvB,UAAI,EAAEP,IAAI,IAAI,IAAR,GAAe,IAAf,GAAsBA,IAAI,CAACO;AAJ7B,KAAN;AAMD;;AAED0B,cAAY;AACV;AACA;AACA;AACA,WAAON,eAAe,CAACS,SAAvB;AACD;;AAlB8C;AAC/C;;AACOK,yBAAY,aAAZ;AAkBTvE,aAAa,CAAC0B,aAAd,CAA4B6C,YAA5B;AASA,OAAM,MAAOC,UAAP,SAA0BtD,WAA1B,CAAqC;AAOzCW,cAAYC,IAAZ,EAAiC;AAC/B;AALO,wBAAe,CAAf;AAMP,SAAKgB,IAAL,GAAYhB,IAAI,CAACgB,IAAL,IAAa,IAAb,GAAoB,KAAK2B,YAAzB,GAAwC3C,IAAI,CAACgB,IAAzD;AACA,SAAKT,IAAL,GAAYP,IAAI,CAACO,IAAjB;;AAEA,QAAI,KAAKA,IAAL,IAAa,IAAjB,EAAuB;AACrB,YAAM,IAAI9B,mBAAJ,CACF,gEADE,CAAN;AAED;AACF;;AAEDgB,OAAK,CAACC,KAAD,EAAeC,KAAf,EAA+B;AAClC,WAAOxB,IAAI,CAAC,MAAK;AACf,UAAIuB,KAAK,CAACuB,MAAN,GAAe,CAAnB,EAAsB;AACpB,cAAM,IAAIxC,mBAAJ,CAAwB,4BAAxB,CAAN;AACD;;AACD,UAAIiB,KAAK,CAAC,CAAD,CAAL,GAAWA,KAAK,CAAC,CAAD,CAAhB,GAAsB,IAA1B,EAAgC;AAC9BkD,eAAO,CAACC,IAAR,CACI,kEACA,cAAcnD,KAAK,CAAC,CAAD,CAAL,GAAWA,KAAK,CAAC,CAAD,CAAG,cADjC,GAEA,sBAHJ;AAID,OATc,CAWf;;;AACA,YAAMoD,eAAe,GACjBpD,KAAK,CAAC,CAAD,CAAL,GAAWA,KAAK,CAAC,CAAD,CAAhB,GAAsB,CAACA,KAAK,CAAC,CAAD,CAAN,EAAWA,KAAK,CAAC,CAAD,CAAhB,CAAtB,GAA6CA,KADjD;AAEA,YAAMqD,CAAC,GAAGxE,CAAC,CAACsC,YAAF,CAAeiC,eAAf,EAAgC,CAAhC,EAAmC,CAAnC,EAAsC,SAAtC,CAAV;AACA,UAAIE,CAAC,GAAGnF,MAAM,CAACoF,WAAP,CAAmBF,CAAnB,CAAR;;AACA,UAAIrD,KAAK,CAAC,CAAD,CAAL,GAAWA,KAAK,CAAC,CAAD,CAApB,EAAyB;AACvBsD,SAAC,GAAG5E,SAAS,CAAC4E,CAAD,CAAb;AACD;;AACD,aAAOlF,GAAG,CAAC,KAAKkD,IAAN,EAAYgC,CAAZ,CAAV;AACD,KApBU,CAAX;AAqBD;;AAEDzD,WAAS;AACP,WAAO;AACLyB,UAAI,EAAE,KAAKA,IADN;AAELT,UAAI,EAAE,KAAKA;AAFN,KAAP;AAID;;AA/CwC;AACzC;;AACOmC,uBAAY,YAAZ;AA+CTxE,aAAa,CAAC0B,aAAd,CAA4B8C,UAA5B,E,CAQA;AACA;;AACA,OAAO,MAAMQ,0CAA0C,GACD;AAChD,cAAY,UADoC;AAEhD,kBAAgB,cAFgC;AAGhD,mBAAiB,eAH+B;AAIhD,cAAY,UAJoC;AAKhD,eAAa,WALmC;AAMhD,cAAY,UANoC;AAOhD,iBAAe,aAPiC;AAQhD,kBAAgB,cARgC;AAShD,UAAQ,MATwC;AAUhD,gBAAc,YAVkC;AAWhD,kBAAgB,cAXgC;AAYhD,mBAAiB,eAZ+B;AAahD,qBAAmB,iBAb6B;AAchD,qBAAmB,iBAd6B;AAehD,WAAS;AAfuC,CAD/C;;AAmBP,SAASC,sBAAT,CACIC,MADJ,EAEgD;AAAA,MAA5CC,aAA4C,uEAAF,EAAE;AAC9C,SAAOvE,sBAAsB,CACzBsE,MADyB,EACjBlF,aAAa,CAACoF,gBAAd,CAA+BC,MAA/B,GAAwCC,YADvB,EAEzBH,aAFyB,EAEV,aAFU,CAA7B;AAGD;;AAED,OAAM,SAAUI,oBAAV,CAA+BC,WAA/B,EAAuD;AAE3D,SAAO3E,oBAAoB,CAAC2E,WAAD,CAA3B;AACD;AAED,OAAM,SAAUC,cAAV,CAAyBC,UAAzB,EACiD;AACrD,MAAI,OAAOA,UAAP,KAAsB,QAA1B,EAAoC;AAClC,UAAMxB,SAAS,GAAGwB,UAAU,IAAIV,0CAAd,GACdA,0CAA0C,CAACU,UAAD,CAD5B,GAEdA,UAFJ;AAGA;;;;AAGA,QAAIxB,SAAS,KAAK,cAAlB,EAAkC;AAChC,aAAO,IAAIC,YAAJ,EAAP;AACD,KAFD,MAEO,IAAID,SAAS,KAAK,eAAlB,EAAmC;AACxC,aAAO,IAAID,aAAJ,EAAP;AACD,KAFM,MAEA,IAAIC,SAAS,KAAK,UAAlB,EAA8B;AACnC,aAAO,IAAIE,QAAJ,EAAP;AACD,KAFM,MAEA,IAAIF,SAAS,KAAK,WAAlB,EAA+B;AACpC,aAAO,IAAIG,SAAJ,EAAP;AACD,KAFM,MAEA,IAAIH,SAAS,KAAK,aAAlB,EAAiC;AACtC,aAAO,IAAII,WAAJ,EAAP;AACD,KAFM,MAEA,IAAIJ,SAAS,KAAK,cAAlB,EAAkC;AACvC,aAAO,IAAIK,YAAJ,EAAP;AACD,KAFM,MAEA;AACL,YAAMW,MAAM,GAA6B,EAAzC;AACAA,YAAM,CAAC,WAAD,CAAN,GAAsBhB,SAAtB;AACAgB,YAAM,CAAC,QAAD,CAAN,GAAmB,EAAnB;AACA,aAAOD,sBAAsB,CAACC,MAAD,CAA7B;AACD;AACF,GAzBD,MAyBO,IAAIQ,UAAU,YAAYxE,WAA1B,EAAuC;AAC5C,WAAOwE,UAAP;AACD,GAFM,MAEA;AACL,WAAOT,sBAAsB,CAACS,UAAD,CAA7B;AACD;AACF","names":["eye","linalg","mul","ones","randomUniform","scalar","serialization","tidy","transpose","truncatedNormal","zeros","K","checkDataFormat","NotImplementedError","ValueError","VALID_DISTRIBUTION_VALUES","VALID_FAN_MODE_VALUES","checkStringTypeUnionValue","deserializeKerasObject","serializeKerasObject","arrayProd","checkFanMode","value","checkDistribution","Initializer","Serializable","fromConfigUsesCustomObjects","getConfig","Zeros","apply","shape","dtype","registerClass","Ones","Constant","constructor","args","undefined","RandomUniform","minval","DEFAULT_MINVAL","maxval","DEFAULT_MAXVAL","seed","RandomNormal","mean","DEFAULT_MEAN","stddev","DEFAULT_STDDEV","randomNormal","TruncatedNormal","Identity","gain","length","computeFans","dataFormat","fanIn","fanOut","indexOf","receptiveFieldSize","shapeProd","Math","sqrt","VarianceScaling","scale","mode","distribution","fans","max","getClassName","limit","GlorotUniform","className","GlorotNormal","HeNormal","HeUniform","LeCunNormal","LeCunUniform","Orthogonal","DEFAULT_GAIN","console","warn","normalizedShape","a","q","gramSchmidt","INITIALIZER_IDENTIFIER_REGISTRY_SYMBOL_MAP","deserializeInitializer","config","customObjects","SerializationMap","getMap","classNameMap","serializeInitializer","initializer","getInitializer","identifier"],"sources":["/home/nadimakhtar97/smart-attendance-system/tfjs-layers/src/initializers.ts"],"sourcesContent":["/**\n * @license\n * Copyright 2018 Google LLC\n *\n * Use of this source code is governed by an MIT-style\n * license that can be found in the LICENSE file or at\n * https://opensource.org/licenses/MIT.\n * =============================================================================\n */\n\nimport {DataType, eye, linalg, mul, ones, randomUniform, scalar, serialization, Tensor, Tensor2D, tidy, transpose, truncatedNormal, zeros} from '@tensorflow/tfjs-core';\n\nimport * as K from './backend/tfjs_backend';\nimport {checkDataFormat} from './common';\nimport {NotImplementedError, ValueError} from './errors';\nimport {DataFormat, Shape} from './keras_format/common';\nimport {Distribution, FanMode, VALID_DISTRIBUTION_VALUES, VALID_FAN_MODE_VALUES} from './keras_format/initializer_config';\nimport {checkStringTypeUnionValue, deserializeKerasObject, serializeKerasObject} from './utils/generic_utils';\nimport {arrayProd} from './utils/math_utils';\n\nexport function checkFanMode(value?: string): void {\n  checkStringTypeUnionValue(VALID_FAN_MODE_VALUES, 'FanMode', value);\n}\n\nexport function checkDistribution(value?: string): void {\n  checkStringTypeUnionValue(VALID_DISTRIBUTION_VALUES, 'Distribution', value);\n}\n\n/**\n * Initializer base class.\n *\n * @doc {\n *   heading: 'Initializers', subheading: 'Classes', namespace: 'initializers'}\n */\nexport abstract class Initializer extends serialization.Serializable {\n  public fromConfigUsesCustomObjects(): boolean {\n    return false;\n  }\n  /**\n   * Generate an initial value.\n   * @param shape\n   * @param dtype\n   * @return The init value.\n   */\n  abstract apply(shape: Shape, dtype?: DataType): Tensor;\n\n  getConfig(): serialization.ConfigDict {\n    return {};\n  }\n}\n\nexport class Zeros extends Initializer {\n  /** @nocollapse */\n  static className = 'Zeros';\n\n  apply(shape: Shape, dtype?: DataType): Tensor {\n    return zeros(shape, dtype);\n  }\n}\nserialization.registerClass(Zeros);\n\nexport class Ones extends Initializer {\n  /** @nocollapse */\n  static className = 'Ones';\n\n  apply(shape: Shape, dtype?: DataType): Tensor {\n    return ones(shape, dtype);\n  }\n}\nserialization.registerClass(Ones);\n\nexport interface ConstantArgs {\n  /** The value for each element in the variable. */\n  value: number;\n}\n\nexport class Constant extends Initializer {\n  /** @nocollapse */\n  static className = 'Constant';\n  private value: number;\n  constructor(args: ConstantArgs) {\n    super();\n    if (typeof args !== 'object') {\n      throw new ValueError(\n          `Expected argument of type ConstantConfig but got ${args}`);\n    }\n    if (args.value === undefined) {\n      throw new ValueError(`config must have value set but got ${args}`);\n    }\n    this.value = args.value;\n  }\n\n  apply(shape: Shape, dtype?: DataType): Tensor {\n    return tidy(() => mul(scalar(this.value), ones(shape, dtype)));\n  }\n\n  getConfig(): serialization.ConfigDict {\n    return {\n      value: this.value,\n    };\n  }\n}\nserialization.registerClass(Constant);\n\nexport interface RandomUniformArgs {\n  /** Lower bound of the range of random values to generate. */\n  minval?: number;\n  /** Upper bound of the range of random values to generate. */\n  maxval?: number;\n  /** Used to seed the random generator. */\n  seed?: number;\n}\n\nexport class RandomUniform extends Initializer {\n  /** @nocollapse */\n  static className = 'RandomUniform';\n  readonly DEFAULT_MINVAL = -0.05;\n  readonly DEFAULT_MAXVAL = 0.05;\n  private minval: number;\n  private maxval: number;\n  private seed: number;\n\n  constructor(args: RandomUniformArgs) {\n    super();\n    this.minval = args.minval || this.DEFAULT_MINVAL;\n    this.maxval = args.maxval || this.DEFAULT_MAXVAL;\n    this.seed = args.seed;\n  }\n\n  apply(shape: Shape, dtype?: DataType): Tensor {\n    return randomUniform(shape, this.minval, this.maxval, dtype);\n  }\n\n  getConfig(): serialization.ConfigDict {\n    return {minval: this.minval, maxval: this.maxval, seed: this.seed};\n  }\n}\nserialization.registerClass(RandomUniform);\n\nexport interface RandomNormalArgs {\n  /** Mean of the random values to generate. */\n  mean?: number;\n  /** Standard deviation of the random values to generate. */\n  stddev?: number;\n  /** Used to seed the random generator. */\n  seed?: number;\n}\n\nexport class RandomNormal extends Initializer {\n  /** @nocollapse */\n  static className = 'RandomNormal';\n  readonly DEFAULT_MEAN = 0.;\n  readonly DEFAULT_STDDEV = 0.05;\n  private mean: number;\n  private stddev: number;\n  private seed: number;\n\n  constructor(args: RandomNormalArgs) {\n    super();\n    this.mean = args.mean || this.DEFAULT_MEAN;\n    this.stddev = args.stddev || this.DEFAULT_STDDEV;\n    this.seed = args.seed;\n  }\n\n  apply(shape: Shape, dtype?: DataType): Tensor {\n    dtype = dtype || 'float32';\n    if (dtype !== 'float32' && dtype !== 'int32') {\n      throw new NotImplementedError(\n          `randomNormal does not support dType ${dtype}.`);\n    }\n\n    return K.randomNormal(shape, this.mean, this.stddev, dtype, this.seed);\n  }\n\n  getConfig(): serialization.ConfigDict {\n    return {mean: this.mean, stddev: this.stddev, seed: this.seed};\n  }\n}\nserialization.registerClass(RandomNormal);\n\nexport interface TruncatedNormalArgs {\n  /** Mean of the random values to generate. */\n  mean?: number;\n  /** Standard deviation of the random values to generate. */\n  stddev?: number;\n  /** Used to seed the random generator. */\n  seed?: number;\n}\n\nexport class TruncatedNormal extends Initializer {\n  /** @nocollapse */\n  static className = 'TruncatedNormal';\n\n  readonly DEFAULT_MEAN = 0.;\n  readonly DEFAULT_STDDEV = 0.05;\n  private mean: number;\n  private stddev: number;\n  private seed: number;\n\n  constructor(args: TruncatedNormalArgs) {\n    super();\n    this.mean = args.mean || this.DEFAULT_MEAN;\n    this.stddev = args.stddev || this.DEFAULT_STDDEV;\n    this.seed = args.seed;\n  }\n\n  apply(shape: Shape, dtype?: DataType): Tensor {\n    dtype = dtype || 'float32';\n    if (dtype !== 'float32' && dtype !== 'int32') {\n      throw new NotImplementedError(\n          `truncatedNormal does not support dType ${dtype}.`);\n    }\n    return truncatedNormal(shape, this.mean, this.stddev, dtype, this.seed);\n  }\n\n  getConfig(): serialization.ConfigDict {\n    return {mean: this.mean, stddev: this.stddev, seed: this.seed};\n  }\n}\nserialization.registerClass(TruncatedNormal);\n\nexport interface IdentityArgs {\n  /**\n   * Multiplicative factor to apply to the identity matrix.\n   */\n  gain?: number;\n}\n\nexport class Identity extends Initializer {\n  /** @nocollapse */\n  static className = 'Identity';\n  private gain: number;\n  constructor(args: IdentityArgs) {\n    super();\n    this.gain = args.gain != null ? args.gain : 1.0;\n  }\n\n  apply(shape: Shape, dtype?: DataType): Tensor {\n    return tidy(() => {\n      if (shape.length !== 2 || shape[0] !== shape[1]) {\n        throw new ValueError(\n            'Identity matrix initializer can only be used for' +\n            ' 2D square matrices.');\n      } else {\n        return mul(this.gain, eye(shape[0]));\n      }\n    });\n  }\n\n  getConfig(): serialization.ConfigDict {\n    return {gain: this.gain};\n  }\n}\nserialization.registerClass(Identity);\n\n/**\n * Computes the number of input and output units for a weight shape.\n * @param shape Shape of weight.\n * @param dataFormat data format to use for convolution kernels.\n *   Note that all kernels in Keras are standardized on the\n *   CHANNEL_LAST ordering (even when inputs are set to CHANNEL_FIRST).\n * @return An length-2 array: fanIn, fanOut.\n */\nfunction computeFans(\n    shape: Shape, dataFormat: DataFormat = 'channelsLast'): number[] {\n  let fanIn: number;\n  let fanOut: number;\n  checkDataFormat(dataFormat);\n  if (shape.length === 2) {\n    fanIn = shape[0];\n    fanOut = shape[1];\n  } else if ([3, 4, 5].indexOf(shape.length) !== -1) {\n    if (dataFormat === 'channelsFirst') {\n      const receptiveFieldSize = arrayProd(shape, 2);\n      fanIn = shape[1] * receptiveFieldSize;\n      fanOut = shape[0] * receptiveFieldSize;\n    } else if (dataFormat === 'channelsLast') {\n      const receptiveFieldSize = arrayProd(shape, 0, shape.length - 2);\n      fanIn = shape[shape.length - 2] * receptiveFieldSize;\n      fanOut = shape[shape.length - 1] * receptiveFieldSize;\n    }\n  } else {\n    const shapeProd = arrayProd(shape);\n    fanIn = Math.sqrt(shapeProd);\n    fanOut = Math.sqrt(shapeProd);\n  }\n\n  return [fanIn, fanOut];\n}\n\nexport interface VarianceScalingArgs {\n  /** Scaling factor (positive float). */\n  scale?: number;\n\n  /** Fanning mode for inputs and outputs. */\n  mode?: FanMode;\n\n  /** Probabilistic distribution of the values. */\n  distribution?: Distribution;\n\n  /** Random number generator seed. */\n  seed?: number;\n}\n\nexport class VarianceScaling extends Initializer {\n  /** @nocollapse */\n  static className = 'VarianceScaling';\n  private scale: number;\n  private mode: FanMode;\n  private distribution: Distribution;\n  private seed: number;\n\n  /**\n   * Constructor of VarianceScaling.\n   * @throws ValueError for invalid value in scale.\n   */\n  constructor(args: VarianceScalingArgs) {\n    super();\n    if (args.scale < 0.0) {\n      throw new ValueError(\n          `scale must be a positive float. Got: ${args.scale}`);\n    }\n    this.scale = args.scale == null ? 1.0 : args.scale;\n    this.mode = args.mode == null ? 'fanIn' : args.mode;\n    checkFanMode(this.mode);\n    this.distribution =\n        args.distribution == null ? 'normal' : args.distribution;\n    checkDistribution(this.distribution);\n    this.seed = args.seed;\n  }\n\n  apply(shape: Shape, dtype?: DataType): Tensor {\n    const fans = computeFans(shape);\n    const fanIn = fans[0];\n    const fanOut = fans[1];\n    let scale = this.scale;\n    if (this.mode === 'fanIn') {\n      scale /= Math.max(1, fanIn);\n    } else if (this.mode === 'fanOut') {\n      scale /= Math.max(1, fanOut);\n    } else {\n      scale /= Math.max(1, (fanIn + fanOut) / 2);\n    }\n\n    if (this.distribution === 'normal') {\n      const stddev = Math.sqrt(scale);\n      dtype = dtype || 'float32';\n      if (dtype !== 'float32' && dtype !== 'int32') {\n        throw new NotImplementedError(\n            `${this.getClassName()} does not support dType ${dtype}.`);\n      }\n      return truncatedNormal(shape, 0, stddev, dtype, this.seed);\n    } else {\n      const limit = Math.sqrt(3 * scale);\n      return randomUniform(shape, -limit, limit, dtype);\n    }\n  }\n\n  getConfig(): serialization.ConfigDict {\n    return {\n      scale: this.scale,\n      mode: this.mode,\n      distribution: this.distribution,\n      seed: this.seed\n    };\n  }\n}\nserialization.registerClass(VarianceScaling);\n\nexport interface SeedOnlyInitializerArgs {\n  /** Random number generator seed. */\n  seed?: number;\n}\n\nexport class GlorotUniform extends VarianceScaling {\n  /** @nocollapse */\n  static className = 'GlorotUniform';\n\n  /**\n   * Constructor of GlorotUniform\n   * @param scale\n   * @param mode\n   * @param distribution\n   * @param seed\n   */\n  constructor(args?: SeedOnlyInitializerArgs) {\n    super({\n      scale: 1.0,\n      mode: 'fanAvg',\n      distribution: 'uniform',\n      seed: args == null ? null : args.seed\n    });\n  }\n\n  getClassName(): string {\n    // In Python Keras, GlorotUniform is not a class, but a helper method\n    // that creates a VarianceScaling object. Use 'VarianceScaling' as\n    // class name to be compatible with that.\n    return VarianceScaling.className;\n  }\n}\nserialization.registerClass(GlorotUniform);\n\nexport class GlorotNormal extends VarianceScaling {\n  /** @nocollapse */\n  static className = 'GlorotNormal';\n\n  /**\n   * Constructor of GlorotNormal.\n   * @param scale\n   * @param mode\n   * @param distribution\n   * @param seed\n   */\n  constructor(args?: SeedOnlyInitializerArgs) {\n    super({\n      scale: 1.0,\n      mode: 'fanAvg',\n      distribution: 'normal',\n      seed: args == null ? null : args.seed\n    });\n  }\n\n  getClassName(): string {\n    // In Python Keras, GlorotNormal is not a class, but a helper method\n    // that creates a VarianceScaling object. Use 'VarianceScaling' as\n    // class name to be compatible with that.\n    return VarianceScaling.className;\n  }\n}\nserialization.registerClass(GlorotNormal);\n\nexport class HeNormal extends VarianceScaling {\n  /** @nocollapse */\n  static className = 'HeNormal';\n\n  constructor(args?: SeedOnlyInitializerArgs) {\n    super({\n      scale: 2.0,\n      mode: 'fanIn',\n      distribution: 'normal',\n      seed: args == null ? null : args.seed\n    });\n  }\n\n  getClassName(): string {\n    // In Python Keras, HeNormal is not a class, but a helper method\n    // that creates a VarianceScaling object. Use 'VarianceScaling' as\n    // class name to be compatible with that.\n    return VarianceScaling.className;\n  }\n}\nserialization.registerClass(HeNormal);\n\nexport class HeUniform extends VarianceScaling {\n  /** @nocollapse */\n  static className = 'HeUniform';\n\n  constructor(args?: SeedOnlyInitializerArgs) {\n    super({\n      scale: 2.0,\n      mode: 'fanIn',\n      distribution: 'uniform',\n      seed: args == null ? null : args.seed\n    });\n  }\n\n  getClassName(): string {\n    // In Python Keras, HeUniform is not a class, but a helper method\n    // that creates a VarianceScaling object. Use 'VarianceScaling' as\n    // class name to be compatible with that.\n    return VarianceScaling.className;\n  }\n}\nserialization.registerClass(HeUniform);\n\nexport class LeCunNormal extends VarianceScaling {\n  /** @nocollapse */\n  static className = 'LeCunNormal';\n\n  constructor(args?: SeedOnlyInitializerArgs) {\n    super({\n      scale: 1.0,\n      mode: 'fanIn',\n      distribution: 'normal',\n      seed: args == null ? null : args.seed\n    });\n  }\n\n  getClassName(): string {\n    // In Python Keras, LeCunNormal is not a class, but a helper method\n    // that creates a VarianceScaling object. Use 'VarianceScaling' as\n    // class name to be compatible with that.\n    return VarianceScaling.className;\n  }\n}\nserialization.registerClass(LeCunNormal);\n\nexport class LeCunUniform extends VarianceScaling {\n  /** @nocollapse */\n  static className = 'LeCunNormal';\n\n  constructor(args?: SeedOnlyInitializerArgs) {\n    super({\n      scale: 1.0,\n      mode: 'fanIn',\n      distribution: 'uniform',\n      seed: args == null ? null : args.seed\n    });\n  }\n\n  getClassName(): string {\n    // In Python Keras, LeCunUniform is not a class, but a helper method\n    // that creates a VarianceScaling object. Use 'VarianceScaling' as\n    // class name to be compatible with that.\n    return VarianceScaling.className;\n  }\n}\nserialization.registerClass(LeCunUniform);\n\nexport interface OrthogonalArgs extends SeedOnlyInitializerArgs {\n  /**\n   * Multiplicative factor to apply to the orthogonal matrix. Defaults to 1.\n   */\n  gain?: number;\n}\n\nexport class Orthogonal extends Initializer {\n  /** @nocollapse */\n  static className = 'Orthogonal';\n  readonly DEFAULT_GAIN = 1;\n  protected readonly gain: number;\n  protected readonly seed: number;\n\n  constructor(args?: OrthogonalArgs) {\n    super();\n    this.gain = args.gain == null ? this.DEFAULT_GAIN : args.gain;\n    this.seed = args.seed;\n\n    if (this.seed != null) {\n      throw new NotImplementedError(\n          'Random seed is not implemented for Orthogonal Initializer yet.');\n    }\n  }\n\n  apply(shape: Shape, dtype?: DataType): Tensor {\n    return tidy(() => {\n      if (shape.length < 2) {\n        throw new NotImplementedError('Shape must be at least 2D.');\n      }\n      if (shape[0] * shape[1] > 2000) {\n        console.warn(\n            `Orthogonal initializer is being called on a matrix with more ` +\n            `than 2000 (${shape[0] * shape[1]}) elements: ` +\n            `Slowness may result.`);\n      }\n\n      // TODO(cais): Add seed support.\n      const normalizedShape =\n          shape[0] > shape[1] ? [shape[1], shape[0]] : shape;\n      const a = K.randomNormal(normalizedShape, 0, 1, 'float32') as Tensor2D;\n      let q = linalg.gramSchmidt(a) as Tensor2D;\n      if (shape[0] > shape[1]) {\n        q = transpose(q);\n      }\n      return mul(this.gain, q);\n    });\n  }\n\n  getConfig(): serialization.ConfigDict {\n    return {\n      gain: this.gain,\n      seed: this.seed,\n    };\n  }\n}\nserialization.registerClass(Orthogonal);\n\n/** @docinline */\nexport type InitializerIdentifier =\n    'constant'|'glorotNormal'|'glorotUniform'|'heNormal'|'heUniform'|'identity'|\n    'leCunNormal'|'leCunUniform'|'ones'|'orthogonal'|'randomNormal'|\n    'randomUniform'|'truncatedNormal'|'varianceScaling'|'zeros'|string;\n\n// Maps the JavaScript-like identifier keys to the corresponding registry\n// symbols.\nexport const INITIALIZER_IDENTIFIER_REGISTRY_SYMBOL_MAP:\n    {[identifier in InitializerIdentifier]: string} = {\n      'constant': 'Constant',\n      'glorotNormal': 'GlorotNormal',\n      'glorotUniform': 'GlorotUniform',\n      'heNormal': 'HeNormal',\n      'heUniform': 'HeUniform',\n      'identity': 'Identity',\n      'leCunNormal': 'LeCunNormal',\n      'leCunUniform': 'LeCunUniform',\n      'ones': 'Ones',\n      'orthogonal': 'Orthogonal',\n      'randomNormal': 'RandomNormal',\n      'randomUniform': 'RandomUniform',\n      'truncatedNormal': 'TruncatedNormal',\n      'varianceScaling': 'VarianceScaling',\n      'zeros': 'Zeros'\n    };\n\nfunction deserializeInitializer(\n    config: serialization.ConfigDict,\n    customObjects: serialization.ConfigDict = {}): Initializer {\n  return deserializeKerasObject(\n      config, serialization.SerializationMap.getMap().classNameMap,\n      customObjects, 'initializer');\n}\n\nexport function serializeInitializer(initializer: Initializer):\n    serialization.ConfigDictValue {\n  return serializeKerasObject(initializer);\n}\n\nexport function getInitializer(identifier: InitializerIdentifier|Initializer|\n                               serialization.ConfigDict): Initializer {\n  if (typeof identifier === 'string') {\n    const className = identifier in INITIALIZER_IDENTIFIER_REGISTRY_SYMBOL_MAP ?\n        INITIALIZER_IDENTIFIER_REGISTRY_SYMBOL_MAP[identifier] :\n        identifier;\n    /* We have four 'helper' classes for common initializers that\n    all get serialized as 'VarianceScaling' and shouldn't go through\n    the deserializeInitializer pathway. */\n    if (className === 'GlorotNormal') {\n      return new GlorotNormal();\n    } else if (className === 'GlorotUniform') {\n      return new GlorotUniform();\n    } else if (className === 'HeNormal') {\n      return new HeNormal();\n    } else if (className === 'HeUniform') {\n      return new HeUniform();\n    } else if (className === 'LeCunNormal') {\n      return new LeCunNormal();\n    } else if (className === 'LeCunUniform') {\n      return new LeCunUniform();\n    } else {\n      const config: serialization.ConfigDict = {};\n      config['className'] = className;\n      config['config'] = {};\n      return deserializeInitializer(config);\n    }\n  } else if (identifier instanceof Initializer) {\n    return identifier;\n  } else {\n    return deserializeInitializer(identifier);\n  }\n}\n"]},"metadata":{},"sourceType":"module"}