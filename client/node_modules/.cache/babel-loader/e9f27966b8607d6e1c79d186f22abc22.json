{"ast":null,"code":"var _jsxFileName = \"/home/nadimakhtar97/smart-attendance-system/client/src/Components/WebCam/WebCam.js\",\n    _s = $RefreshSig$();\n\nimport React, { useState, useRef, useCallback } from 'react';\nimport Webcam from \"react-webcam\";\nimport styles from \"../WebCam/WebCam.module.css\";\nimport * as tf from '@tensorflow/tfjs';\nimport axios from 'axios';\nimport { Button, Box, Image, Flex, Text } from '@chakra-ui/react';\nimport draw from '../Utilities';\nimport { jsxDEV as _jsxDEV } from \"react/jsx-dev-runtime\";\n\nfunction WebCam() {\n  _s();\n\n  const [image, setImage] = useState('');\n  const videoConstraints = {\n    width: 720,\n    height: 360,\n    facingMode: \"user\"\n  };\n  const webcamRef = useRef(null);\n  const canvasRef = useRef(null);\n\n  const blazeface = require('@tensorflow-models/blazeface');\n\n  const runFacedetection = async () => {\n    const model = await blazeface.load();\n    console.log(\"FaceDetection Model is Loaded..\");\n    setInterval(() => {\n      detect(model);\n    }, 100);\n  }; // runFacedetection();\n\n\n  const capture = useCallback(async () => {\n    console.log(\"hello\");\n\n    try {\n      const imageSrc = webcamRef.current.getScreenshot();\n      setImage(imageSrc);\n      const response = await axios.post('http://localhost:5000/img', {\n        \"base64image\": imageSrc\n      });\n      console.log(response);\n    } catch (error) {\n      console.log(error);\n    }\n  }, [webcamRef]);\n  return /*#__PURE__*/_jsxDEV(Flex, {\n    justifyContent: \"center\",\n    alignItems: \"center\",\n    alignContent: \"space-between\",\n    direction: \"column\",\n    children: [/*#__PURE__*/_jsxDEV(Webcam, {\n      className: styles.cam,\n      mirrored: true,\n      ref: webcamRef,\n      screenshotFormat: \"image/jpeg\",\n      screenshotQuality: 1,\n      height: 360,\n      width: 720,\n      videoConstraints: videoConstraints\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 56,\n      columnNumber: 13\n    }, this), /*#__PURE__*/_jsxDEV(Button, {\n      size: \"md\",\n      width: \"40%\",\n      m: \"20px\",\n      colorScheme: \"blue\",\n      onClick: () => {\n        capture();\n      },\n      children: /*#__PURE__*/_jsxDEV(Text, {\n        children: \"Capture\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 66,\n        columnNumber: 101\n      }, this)\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 66,\n      columnNumber: 13\n    }, this)]\n  }, void 0, true, {\n    fileName: _jsxFileName,\n    lineNumber: 55,\n    columnNumber: 9\n  }, this);\n}\n\n_s(WebCam, \"1uHxV1fXTrsU8yLFUPuHv7WOTqw=\");\n\n_c = WebCam;\nexport default WebCam;\n\nvar _c;\n\n$RefreshReg$(_c, \"WebCam\");","map":{"version":3,"sources":["/home/nadimakhtar97/smart-attendance-system/client/src/Components/WebCam/WebCam.js"],"names":["React","useState","useRef","useCallback","Webcam","styles","tf","axios","Button","Box","Image","Flex","Text","draw","WebCam","image","setImage","videoConstraints","width","height","facingMode","webcamRef","canvasRef","blazeface","require","runFacedetection","model","load","console","log","setInterval","detect","capture","imageSrc","current","getScreenshot","response","post","error","cam"],"mappings":";;;AAAA,OAAOA,KAAP,IAAgBC,QAAhB,EAA0BC,MAA1B,EAAkCC,WAAlC,QAAqD,OAArD;AACA,OAAOC,MAAP,MAAmB,cAAnB;AACA,OAAOC,MAAP,MAAmB,6BAAnB;AACA,OAAO,KAAKC,EAAZ,MAAoB,kBAApB;AACA,OAAOC,KAAP,MAAkB,OAAlB;AACA,SAASC,MAAT,EAAiBC,GAAjB,EAAsBC,KAAtB,EAA6BC,IAA7B,EAAmCC,IAAnC,QAA+C,kBAA/C;AACA,OAAOC,IAAP,MAAiB,cAAjB;;;AAEA,SAASC,MAAT,GAAkB;AAAA;;AAEd,QAAM,CAACC,KAAD,EAAQC,QAAR,IAAoBf,QAAQ,CAAC,EAAD,CAAlC;AACA,QAAMgB,gBAAgB,GAAG;AACrBC,IAAAA,KAAK,EAAE,GADc;AAErBC,IAAAA,MAAM,EAAE,GAFa;AAGrBC,IAAAA,UAAU,EAAE;AAHS,GAAzB;AAMA,QAAMC,SAAS,GAAGnB,MAAM,CAAC,IAAD,CAAxB;AACA,QAAMoB,SAAS,GAAGpB,MAAM,CAAC,IAAD,CAAxB;;AACA,QAAMqB,SAAS,GAAGC,OAAO,CAAC,8BAAD,CAAzB;;AAEA,QAAMC,gBAAgB,GAAG,YAAY;AAEjC,UAAMC,KAAK,GAAG,MAAMH,SAAS,CAACI,IAAV,EAApB;AACAC,IAAAA,OAAO,CAACC,GAAR,CAAY,iCAAZ;AACAC,IAAAA,WAAW,CAAC,MAAM;AACdC,MAAAA,MAAM,CAACL,KAAD,CAAN;AACH,KAFU,EAER,GAFQ,CAAX;AAIH,GARD,CAbc,CA0Bd;;;AAEA,QAAMM,OAAO,GAAG7B,WAAW,CACvB,YAAY;AACRyB,IAAAA,OAAO,CAACC,GAAR,CAAY,OAAZ;;AACA,QAAI;AACA,YAAMI,QAAQ,GAAGZ,SAAS,CAACa,OAAV,CAAkBC,aAAlB,EAAjB;AACAnB,MAAAA,QAAQ,CAACiB,QAAD,CAAR;AACA,YAAMG,QAAQ,GAAG,MAAM7B,KAAK,CAAC8B,IAAN,CAAW,2BAAX,EAAwC;AAAE,uBAAeJ;AAAjB,OAAxC,CAAvB;AACAL,MAAAA,OAAO,CAACC,GAAR,CAAYO,QAAZ;AAEH,KAND,CAOA,OAAOE,KAAP,EAAc;AACVV,MAAAA,OAAO,CAACC,GAAR,CAAYS,KAAZ;AACH;AAEJ,GAdsB,EAevB,CAACjB,SAAD,CAfuB,CAA3B;AAiBA,sBACI,QAAC,IAAD;AAAM,IAAA,cAAc,EAAC,QAArB;AAA8B,IAAA,UAAU,EAAC,QAAzC;AAAkD,IAAA,YAAY,EAAC,eAA/D;AAA+E,IAAA,SAAS,EAAC,QAAzF;AAAA,4BACI,QAAC,MAAD;AACI,MAAA,SAAS,EAAEhB,MAAM,CAACkC,GADtB;AAEI,MAAA,QAAQ,EAAE,IAFd;AAGI,MAAA,GAAG,EAAElB,SAHT;AAII,MAAA,gBAAgB,EAAC,YAJrB;AAKI,MAAA,iBAAiB,EAAE,CALvB;AAMI,MAAA,MAAM,EAAE,GANZ;AAOI,MAAA,KAAK,EAAE,GAPX;AAQI,MAAA,gBAAgB,EAAEJ;AARtB;AAAA;AAAA;AAAA;AAAA,YADJ,eAWI,QAAC,MAAD;AAAQ,MAAA,IAAI,EAAC,IAAb;AAAkB,MAAA,KAAK,EAAC,KAAxB;AAA8B,MAAA,CAAC,EAAC,MAAhC;AAAuC,MAAA,WAAW,EAAC,MAAnD;AAA0D,MAAA,OAAO,EAAE,MAAM;AAAEe,QAAAA,OAAO;AAAI,OAAtF;AAAA,6BAAwF,QAAC,IAAD;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAxF;AAAA;AAAA;AAAA;AAAA,YAXJ;AAAA;AAAA;AAAA;AAAA;AAAA,UADJ;AAmBH;;GAhEQlB,M;;KAAAA,M;AAkET,eAAeA,MAAf","sourcesContent":["import React, { useState, useRef, useCallback } from 'react'\nimport Webcam from \"react-webcam\";\nimport styles from \"../WebCam/WebCam.module.css\";\nimport * as tf from '@tensorflow/tfjs';\nimport axios from 'axios'\nimport { Button, Box, Image, Flex, Text } from '@chakra-ui/react'\nimport draw from '../Utilities'\n\nfunction WebCam() {\n\n    const [image, setImage] = useState('')\n    const videoConstraints = {\n        width: 720,\n        height: 360,\n        facingMode: \"user\"\n    };\n\n    const webcamRef = useRef(null);\n    const canvasRef = useRef(null);\n    const blazeface = require('@tensorflow-models/blazeface');\n\n    const runFacedetection = async () => {\n\n        const model = await blazeface.load()\n        console.log(\"FaceDetection Model is Loaded..\")\n        setInterval(() => {\n            detect(model);\n        }, 100);\n\n    }\n\n\n\n\n    // runFacedetection();\n\n    const capture = useCallback(\n        async () => {\n            console.log(\"hello\")\n            try {\n                const imageSrc = webcamRef.current.getScreenshot();\n                setImage(imageSrc);\n                const response = await axios.post('http://localhost:5000/img', { \"base64image\": imageSrc })\n                console.log(response);\n\n            }\n            catch (error) {\n                console.log(error)\n            }\n\n        },\n        [webcamRef]\n    );\n    return (\n        <Flex justifyContent='center' alignItems='center' alignContent='space-between' direction='column'>\n            <Webcam\n                className={styles.cam}\n                mirrored={true}\n                ref={webcamRef}\n                screenshotFormat=\"image/jpeg\"\n                screenshotQuality={1}\n                height={360}\n                width={720}\n                videoConstraints={videoConstraints}\n            ></Webcam>\n            <Button size='md' width='40%' m='20px' colorScheme='blue' onClick={() => { capture() }}><Text>Capture</Text></Button>\n            {/* {image ? <Box>\n                <Image src={image}/>\n            </Box> : null} */}\n        </Flex>\n\n    )\n}\n\nexport default WebCam"]},"metadata":{},"sourceType":"module"}