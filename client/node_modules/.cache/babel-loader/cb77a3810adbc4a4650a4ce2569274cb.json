{"ast":null,"code":"/**\n * @license\n * Copyright 2020 Google LLC\n *\n * Use of this source code is governed by an MIT-style\n * license that can be found in the LICENSE file or at\n * https://opensource.org/licenses/MIT.\n * =============================================================================\n */\nvar __rest = this && this.__rest || function (s, e) {\n  var t = {};\n\n  for (var p in s) if (Object.prototype.hasOwnProperty.call(s, p) && e.indexOf(p) < 0) t[p] = s[p];\n\n  if (s != null && typeof Object.getOwnPropertySymbols === \"function\") for (var i = 0, p = Object.getOwnPropertySymbols(s); i < p.length; i++) {\n    if (e.indexOf(p[i]) < 0 && Object.prototype.propertyIsEnumerable.call(s, p[i])) t[p[i]] = s[p[i]];\n  }\n  return t;\n};\n\nimport * as tfc from '@tensorflow/tfjs-core';\nimport { util } from '@tensorflow/tfjs-core';\nimport * as K from '../backend/tfjs_backend';\nimport { checkDataFormat, checkPaddingMode } from '../common';\nimport { InputSpec } from '../engine/topology';\nimport { AttributeError, NotImplementedError, ValueError } from '../errors';\nimport { Initializer } from '../initializers';\nimport { convOutputLength, normalizeArray } from '../utils/conv_utils';\nimport { assertPositiveInteger } from '../utils/generic_utils';\nimport { getExactlyOneShape } from '../utils/types_utils';\nimport { generateDropoutMask, LSTMCell, RNN, RNNCell } from './recurrent';\n\nclass ConvRNN2DCell extends RNNCell {}\n/**\n * Base class for convolutional-recurrent layers.\n */\n\n\nclass ConvRNN2D extends RNN {\n  constructor(args) {\n    if (args.unroll) {\n      throw new NotImplementedError('Unrolling is not possible with convolutional RNNs.');\n    }\n\n    if (Array.isArray(args.cell)) {\n      throw new NotImplementedError('It is not possible at the moment to stack convolutional cells.');\n    }\n\n    super(args);\n    this.inputSpec = [new InputSpec({\n      ndim: 5\n    })];\n  }\n\n  call(inputs, kwargs) {\n    return tfc.tidy(() => {\n      if (this.cell.dropoutMask != null) {\n        tfc.dispose(this.cell.dropoutMask);\n        this.cell.dropoutMask = null;\n      }\n\n      if (this.cell.recurrentDropoutMask != null) {\n        tfc.dispose(this.cell.recurrentDropoutMask);\n        this.cell.recurrentDropoutMask = null;\n      }\n\n      if (kwargs && kwargs['constants']) {\n        throw new ValueError('ConvRNN2D cell does not support constants');\n      }\n\n      const mask = kwargs == null ? null : kwargs['mask'];\n      const training = kwargs == null ? null : kwargs['training'];\n      const initialState = kwargs == null ? null : kwargs['initialState'];\n      return super.call(inputs, {\n        mask,\n        training,\n        initialState\n      });\n    });\n  }\n\n  computeOutputShape(inputShape) {\n    let outShape = this.computeSingleOutputShape(inputShape);\n\n    if (!this.returnSequences) {\n      outShape = [outShape[0], ...outShape.slice(2)];\n    }\n\n    if (this.returnState) {\n      outShape = [outShape, ...Array(2).fill([inputShape[0], ...outShape.slice(-3)])];\n    }\n\n    return outShape;\n  }\n\n  getInitialState(inputs) {\n    return tfc.tidy(() => {\n      const {\n        stateSize\n      } = this.cell;\n      const inputShape = inputs.shape;\n      const outputShape = this.computeSingleOutputShape(inputShape);\n      const stateShape = [outputShape[0], ...outputShape.slice(2)];\n      const initialState = tfc.zeros(stateShape);\n\n      if (Array.isArray(stateSize)) {\n        return Array(stateSize.length).fill(initialState);\n      }\n\n      return [initialState];\n    });\n  }\n\n  resetStates(states) {\n    let training = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : false;\n    tfc.tidy(() => {\n      if (!this.stateful) {\n        throw new AttributeError('Cannot call resetStates() on an RNN Layer that is not stateful.');\n      }\n\n      const inputShape = this.inputSpec[0].shape;\n      const outputShape = this.computeSingleOutputShape(inputShape);\n      const stateShape = [outputShape[0], ...outputShape.slice(2)];\n      const batchSize = inputShape[0];\n\n      if (batchSize == null) {\n        throw new ValueError('If an RNN is stateful, it needs to know its batch size. Specify ' + 'the batch size of your input tensors: \\n' + '- If using a Sequential model, specify the batch size by ' + 'passing a `batchInputShape` option to your first layer.\\n' + '- If using the functional API, specify the batch size by ' + 'passing a `batchShape` option to your Input layer.');\n      } // Initialize state if null.\n\n\n      if (this.getStates() == null) {\n        if (Array.isArray(this.cell.stateSize)) {\n          this.states_ = this.cell.stateSize.map(() => tfc.zeros(stateShape));\n        } else {\n          this.states_ = [tfc.zeros(stateShape)];\n        }\n      } else if (states == null) {\n        // Dispose old state tensors.\n        tfc.dispose(this.states_); // For stateful RNNs, fully dispose kept old states.\n\n        if (this.keptStates != null) {\n          tfc.dispose(this.keptStates);\n          this.keptStates = [];\n        }\n\n        if (Array.isArray(this.cell.stateSize)) {\n          this.states_ = this.cell.stateSize.map(() => tfc.zeros(stateShape));\n        } else {\n          this.states_[0] = tfc.zeros(stateShape);\n        }\n      } else {\n        if (!Array.isArray(states)) {\n          states = [states];\n        }\n\n        if (states.length !== this.states_.length) {\n          throw new ValueError(`Layer ${this.name} expects ${this.states_.length} state(s), ` + `but it received ${states.length} state value(s). Input ` + `received: ${states}`);\n        }\n\n        if (training) {\n          // Store old state tensors for complete disposal later, i.e., during\n          // the next no-arg call to this method. We do not dispose the old\n          // states immediately because that BPTT (among other things) require\n          // them.\n          this.keptStates.push(this.states_.slice());\n        } else {\n          tfc.dispose(this.states_);\n        }\n\n        for (let index = 0; index < this.states_.length; ++index) {\n          const value = states[index];\n          const expectedShape = stateShape;\n\n          if (!util.arraysEqual(value.shape, expectedShape)) {\n            throw new ValueError(`State ${index} is incompatible with layer ${this.name}: ` + `expected shape=${expectedShape}, received shape=${value.shape}`);\n          }\n\n          this.states_[index] = value;\n        }\n      }\n\n      this.states_ = this.states_.map(state => tfc.keep(state.clone()));\n    });\n  }\n\n  computeSingleOutputShape(inputShape) {\n    const {\n      dataFormat,\n      filters,\n      kernelSize,\n      padding,\n      strides,\n      dilationRate\n    } = this.cell;\n    const isChannelsFirst = dataFormat === 'channelsFirst';\n    const h = inputShape[isChannelsFirst ? 3 : 2];\n    const w = inputShape[isChannelsFirst ? 4 : 3];\n    const hOut = convOutputLength(h, kernelSize[0], padding, strides[0], dilationRate[0]);\n    const wOut = convOutputLength(w, kernelSize[1], padding, strides[1], dilationRate[1]);\n    const outShape = [...inputShape.slice(0, 2), ...(isChannelsFirst ? [filters, hOut, wOut] : [hOut, wOut, filters])];\n    return outShape;\n  }\n\n}\n/** @nocollapse */\n\n\nConvRNN2D.className = 'ConvRNN2D';\nexport class ConvLSTM2DCell extends LSTMCell {\n  constructor(args) {\n    const {\n      filters,\n      kernelSize,\n      strides,\n      padding,\n      dataFormat,\n      dilationRate\n    } = args;\n    super(Object.assign({}, args, {\n      units: filters\n    }));\n    this.filters = filters;\n    assertPositiveInteger(this.filters, 'filters');\n    this.kernelSize = normalizeArray(kernelSize, 2, 'kernelSize');\n    this.kernelSize.forEach(size => assertPositiveInteger(size, 'kernelSize'));\n    this.strides = normalizeArray(strides || 1, 2, 'strides');\n    this.strides.forEach(stride => assertPositiveInteger(stride, 'strides'));\n    this.padding = padding || 'valid';\n    checkPaddingMode(this.padding);\n    this.dataFormat = dataFormat || 'channelsLast';\n    checkDataFormat(this.dataFormat);\n    this.dilationRate = normalizeArray(dilationRate || 1, 2, 'dilationRate');\n    this.dilationRate.forEach(rate => assertPositiveInteger(rate, 'dilationRate'));\n  }\n\n  build(inputShape) {\n    var _a;\n\n    inputShape = getExactlyOneShape(inputShape);\n    const channelAxis = this.dataFormat === 'channelsFirst' ? 1 : inputShape.length - 1;\n\n    if (inputShape[channelAxis] == null) {\n      throw new ValueError(`The channel dimension of the input should be defined. ` + `Found ${inputShape[channelAxis]}`);\n    }\n\n    const inputDim = inputShape[channelAxis];\n    const numOfKernels = 4;\n    const kernelShape = this.kernelSize.concat([inputDim, this.filters * numOfKernels]);\n    this.kernel = this.addWeight('kernel', kernelShape, null, this.kernelInitializer, this.kernelRegularizer, true, this.kernelConstraint);\n    const recurrentKernelShape = this.kernelSize.concat([this.filters, this.filters * numOfKernels]);\n    this.recurrentKernel = this.addWeight('recurrent_kernel', recurrentKernelShape, null, this.recurrentInitializer, this.recurrentRegularizer, true, this.recurrentConstraint);\n\n    if (this.useBias) {\n      let biasInitializer;\n\n      if (this.unitForgetBias) {\n        const init = this.biasInitializer;\n        const filters = this.filters;\n        biasInitializer = new (_a = class CustomInit extends Initializer {\n          apply(shape, dtype) {\n            const biasI = init.apply([filters]);\n            const biasF = tfc.ones([filters]);\n            const biasCAndO = init.apply([filters * 2]);\n            return K.concatenate([biasI, biasF, biasCAndO]);\n          }\n\n        },\n        /** @nocollapse */\n        _a.className = 'CustomInit', _a)();\n      } else {\n        biasInitializer = this.biasInitializer;\n      }\n\n      this.bias = this.addWeight('bias', [this.filters * numOfKernels], null, biasInitializer, this.biasRegularizer, true, this.biasConstraint);\n    }\n\n    this.built = true;\n  }\n\n  call(inputs, kwargs) {\n    return tfc.tidy(() => {\n      if (inputs.length !== 3) {\n        throw new ValueError(`ConvLSTM2DCell expects 3 input Tensors (inputs, h, c), got ` + `${inputs.length}.`);\n      }\n\n      const training = kwargs['training'] || false;\n      const x = inputs[0]; // Current input\n\n      const hTMinus1 = inputs[1]; // Previous memory state.\n\n      const cTMinus1 = inputs[2]; // Previous carry state.\n\n      const numOfKernels = 4;\n\n      if (0 < this.dropout && this.dropout < 1 && this.dropoutMask == null) {\n        this.dropoutMask = generateDropoutMask({\n          ones: () => tfc.onesLike(x),\n          rate: this.dropout,\n          training,\n          count: numOfKernels,\n          dropoutFunc: this.dropoutFunc\n        });\n      }\n\n      const dropoutMask = this.dropoutMask;\n\n      const applyDropout = (x, mask, index) => {\n        if (!mask || !mask[index]) {\n          return x;\n        }\n\n        return tfc.mul(mask[index], x);\n      };\n\n      let xI = applyDropout(x, dropoutMask, 0);\n      let xF = applyDropout(x, dropoutMask, 1);\n      let xC = applyDropout(x, dropoutMask, 2);\n      let xO = applyDropout(x, dropoutMask, 3);\n\n      if (0 < this.recurrentDropout && this.recurrentDropout < 1 && this.recurrentDropoutMask == null) {\n        this.recurrentDropoutMask = generateDropoutMask({\n          ones: () => tfc.onesLike(hTMinus1),\n          rate: this.recurrentDropout,\n          training,\n          count: numOfKernels,\n          dropoutFunc: this.dropoutFunc\n        });\n      }\n\n      const recDropoutMask = this.recurrentDropoutMask;\n      let hI = applyDropout(hTMinus1, recDropoutMask, 0);\n      let hF = applyDropout(hTMinus1, recDropoutMask, 1);\n      let hC = applyDropout(hTMinus1, recDropoutMask, 2);\n      let hO = applyDropout(hTMinus1, recDropoutMask, 3);\n      const kernelChannelAxis = 3;\n      const [kernelI, kernelF, kernelC, kernelO] = tfc.split(this.kernel.read(), numOfKernels, kernelChannelAxis);\n      const [biasI, biasF, biasC, biasO] = this.useBias ? tfc.split(this.bias.read(), numOfKernels) : [null, null, null, null];\n      xI = this.inputConv(xI, kernelI, biasI, this.padding);\n      xF = this.inputConv(xF, kernelF, biasF, this.padding);\n      xC = this.inputConv(xC, kernelC, biasC, this.padding);\n      xO = this.inputConv(xO, kernelO, biasO, this.padding);\n      const [recKernelI, recKernelF, recKernelC, recKernelO] = tfc.split(this.recurrentKernel.read(), numOfKernels, kernelChannelAxis);\n      hI = this.recurrentConv(hI, recKernelI);\n      hF = this.recurrentConv(hF, recKernelF);\n      hC = this.recurrentConv(hC, recKernelC);\n      hO = this.recurrentConv(hO, recKernelO);\n      const i = this.recurrentActivation.apply(tfc.add(xI, hI));\n      const f = this.recurrentActivation.apply(tfc.add(xF, hF));\n      const c = tfc.add(tfc.mul(f, cTMinus1), tfc.mul(i, this.activation.apply(tfc.add(xC, hC))));\n      const h = tfc.mul(this.recurrentActivation.apply(tfc.add(xO, hO)), this.activation.apply(c));\n      return [h, h, c];\n    });\n  }\n\n  getConfig() {\n    const _a = super.getConfig(),\n          {\n      'units': _\n    } = _a,\n          baseConfig = __rest(_a, ['units']);\n\n    const config = {\n      filters: this.filters,\n      kernelSize: this.kernelSize,\n      padding: this.padding,\n      dataFormat: this.dataFormat,\n      dilationRate: this.dilationRate,\n      strides: this.strides\n    };\n    return Object.assign({}, baseConfig, config);\n  }\n\n  inputConv(x, w, b, padding) {\n    const out = tfc.conv2d(x, w, this.strides, padding || 'valid', this.dataFormat === 'channelsFirst' ? 'NCHW' : 'NHWC', this.dilationRate);\n\n    if (b) {\n      return K.biasAdd(out, b, this.dataFormat);\n    }\n\n    return out;\n  }\n\n  recurrentConv(x, w) {\n    const strides = 1;\n    return tfc.conv2d(x, w, strides, 'same', this.dataFormat === 'channelsFirst' ? 'NCHW' : 'NHWC');\n  }\n\n}\n/** @nocollapse */\n\nConvLSTM2DCell.className = 'ConvLSTM2DCell';\ntfc.serialization.registerClass(ConvLSTM2DCell);\nexport class ConvLSTM2D extends ConvRNN2D {\n  constructor(args) {\n    const cell = new ConvLSTM2DCell(args);\n    super(Object.assign({}, args, {\n      cell\n    }));\n  }\n  /** @nocollapse */\n\n\n  static fromConfig(cls, config) {\n    return new cls(config);\n  }\n\n}\n/** @nocollapse */\n\nConvLSTM2D.className = 'ConvLSTM2D';\ntfc.serialization.registerClass(ConvLSTM2D);","map":{"version":3,"mappings":"AAAA;;;;;;;;;;;;;;;;;;;;AAUA,OAAO,KAAKA,GAAZ,MAAqB,uBAArB;AACA,SAAgBC,IAAhB,QAA2B,uBAA3B;AAGA,OAAO,KAAKC,CAAZ,MAAmB,yBAAnB;AACA,SAAQC,eAAR,EAAyBC,gBAAzB,QAAgD,WAAhD;AAEA,SAAQC,SAAR,QAAwB,oBAAxB;AACA,SAAQC,cAAR,EAAwBC,mBAAxB,EAA6CC,UAA7C,QAA8D,WAA9D;AACA,SAAQC,WAAR,QAA0B,iBAA1B;AAIA,SAAQC,gBAAR,EAA0BC,cAA1B,QAA+C,qBAA/C;AACA,SAAQC,qBAAR,QAAoC,wBAApC;AACA,SAAQC,kBAAR,QAAiC,sBAAjC;AAEA,SAA0BC,mBAA1B,EAA+CC,QAA/C,EAA2FC,GAA3F,EAAgGC,OAAhG,QAAoJ,aAApJ;;AAsDA,MAAeC,aAAf,SAAqCD,OAArC,CAA4C;AA8B5C;;;;;AAGA,MAAME,SAAN,SAAwBH,GAAxB,CAA2B;AAMzBI,cAAYC,IAAZ,EAAoC;AAClC,QAAIA,IAAI,CAACC,MAAT,EAAiB;AACf,YAAM,IAAIf,mBAAJ,CACF,oDADE,CAAN;AAED;;AAED,QAAIgB,KAAK,CAACC,OAAN,CAAcH,IAAI,CAACI,IAAnB,CAAJ,EAA8B;AAC5B,YAAM,IAAIlB,mBAAJ,CACF,gEADE,CAAN;AAED;;AAED,UAAMc,IAAN;AAEA,SAAKK,SAAL,GAAiB,CAAC,IAAIrB,SAAJ,CAAc;AAACsB,UAAI,EAAE;AAAP,KAAd,CAAD,CAAjB;AACD;;AAEDC,MAAI,CAACC,MAAD,EAA0BC,MAA1B,EAAwC;AAC1C,WAAO9B,GAAG,CAAC+B,IAAJ,CAAS,MAAK;AACnB,UAAI,KAAKN,IAAL,CAAUO,WAAV,IAAyB,IAA7B,EAAmC;AACjChC,WAAG,CAACiC,OAAJ,CAAY,KAAKR,IAAL,CAAUO,WAAtB;AAEA,aAAKP,IAAL,CAAUO,WAAV,GAAwB,IAAxB;AACD;;AAED,UAAI,KAAKP,IAAL,CAAUS,oBAAV,IAAkC,IAAtC,EAA4C;AAC1ClC,WAAG,CAACiC,OAAJ,CAAY,KAAKR,IAAL,CAAUS,oBAAtB;AAEA,aAAKT,IAAL,CAAUS,oBAAV,GAAiC,IAAjC;AACD;;AAED,UAAIJ,MAAM,IAAIA,MAAM,CAAC,WAAD,CAApB,EAAmC;AACjC,cAAM,IAAItB,UAAJ,CAAe,2CAAf,CAAN;AACD;;AAED,YAAM2B,IAAI,GAAGL,MAAM,IAAI,IAAV,GAAiB,IAAjB,GAAwBA,MAAM,CAAC,MAAD,CAA3C;AAEA,YAAMM,QAAQ,GAAGN,MAAM,IAAI,IAAV,GAAiB,IAAjB,GAAwBA,MAAM,CAAC,UAAD,CAA/C;AAEA,YAAMO,YAAY,GACdP,MAAM,IAAI,IAAV,GAAiB,IAAjB,GAAwBA,MAAM,CAAC,cAAD,CADlC;AAGA,aAAO,MAAMF,IAAN,CAAWC,MAAX,EAAmB;AAACM,YAAD;AAAOC,gBAAP;AAAiBC;AAAjB,OAAnB,CAAP;AACD,KAzBM,CAAP;AA0BD;;AAEDC,oBAAkB,CAACC,UAAD,EAAkB;AAClC,QAAIC,QAAQ,GAAU,KAAKC,wBAAL,CAA8BF,UAA9B,CAAtB;;AAEA,QAAI,CAAC,KAAKG,eAAV,EAA2B;AACzBF,cAAQ,GAAG,CAACA,QAAQ,CAAC,CAAD,CAAT,EAAc,GAAGA,QAAQ,CAACG,KAAT,CAAe,CAAf,CAAjB,CAAX;AACD;;AAED,QAAI,KAAKC,WAAT,EAAsB;AACpBJ,cAAQ,GACJ,CAACA,QAAD,EAAW,GAAGjB,KAAK,CAAC,CAAD,CAAL,CAASsB,IAAT,CAAc,CAACN,UAAU,CAAC,CAAD,CAAX,EAAgB,GAAGC,QAAQ,CAACG,KAAT,CAAe,CAAC,CAAhB,CAAnB,CAAd,CAAd,CADJ;AAED;;AAED,WAAOH,QAAP;AACD;;AAEDM,iBAAe,CAACjB,MAAD,EAAmB;AAChC,WAAO7B,GAAG,CAAC+B,IAAJ,CAAS,MAAK;AACnB,YAAM;AAACgB;AAAD,UAAc,KAAKtB,IAAzB;AAEA,YAAMc,UAAU,GAAGV,MAAM,CAACmB,KAA1B;AAEA,YAAMC,WAAW,GAAG,KAAKR,wBAAL,CAA8BF,UAA9B,CAApB;AAEA,YAAMW,UAAU,GAAG,CAACD,WAAW,CAAC,CAAD,CAAZ,EAAiB,GAAGA,WAAW,CAACN,KAAZ,CAAkB,CAAlB,CAApB,CAAnB;AAEA,YAAMN,YAAY,GAAGrC,GAAG,CAACmD,KAAJ,CAAUD,UAAV,CAArB;;AAEA,UAAI3B,KAAK,CAACC,OAAN,CAAcuB,SAAd,CAAJ,EAA8B;AAC5B,eAAOxB,KAAK,CAACwB,SAAS,CAACK,MAAX,CAAL,CAAwBP,IAAxB,CAA6BR,YAA7B,CAAP;AACD;;AAED,aAAO,CAACA,YAAD,CAAP;AACD,KAhBM,CAAP;AAiBD;;AAEDgB,aAAW,CAACC,MAAD,EAA2C;AAAA,QAAhBlB,QAAgB,uEAAL,KAAK;AACpDpC,OAAG,CAAC+B,IAAJ,CAAS,MAAK;AACZ,UAAI,CAAC,KAAKwB,QAAV,EAAoB;AAClB,cAAM,IAAIjD,cAAJ,CACF,iEADE,CAAN;AAED;;AAED,YAAMiC,UAAU,GAAG,KAAKb,SAAL,CAAe,CAAf,EAAkBsB,KAArC;AAEA,YAAMC,WAAW,GAAG,KAAKR,wBAAL,CAA8BF,UAA9B,CAApB;AAEA,YAAMW,UAAU,GAAG,CAACD,WAAW,CAAC,CAAD,CAAZ,EAAiB,GAAGA,WAAW,CAACN,KAAZ,CAAkB,CAAlB,CAApB,CAAnB;AAEA,YAAMa,SAAS,GAAGjB,UAAU,CAAC,CAAD,CAA5B;;AAEA,UAAIiB,SAAS,IAAI,IAAjB,EAAuB;AACrB,cAAM,IAAIhD,UAAJ,CACF,qEACA,0CADA,GAEA,2DAFA,GAGA,2DAHA,GAIA,2DAJA,GAKA,oDANE,CAAN;AAOD,OAtBW,CAwBZ;;;AACA,UAAI,KAAKiD,SAAL,MAAoB,IAAxB,EAA8B;AAC5B,YAAIlC,KAAK,CAACC,OAAN,CAAc,KAAKC,IAAL,CAAUsB,SAAxB,CAAJ,EAAwC;AACtC,eAAKW,OAAL,GAAe,KAAKjC,IAAL,CAAUsB,SAAV,CAAoBY,GAApB,CAAwB,MAAM3D,GAAG,CAACmD,KAAJ,CAAUD,UAAV,CAA9B,CAAf;AACD,SAFD,MAEO;AACL,eAAKQ,OAAL,GAAe,CAAC1D,GAAG,CAACmD,KAAJ,CAAUD,UAAV,CAAD,CAAf;AACD;AACF,OAND,MAMO,IAAII,MAAM,IAAI,IAAd,EAAoB;AACzB;AACAtD,WAAG,CAACiC,OAAJ,CAAY,KAAKyB,OAAjB,EAFyB,CAIzB;;AACA,YAAI,KAAKE,UAAL,IAAmB,IAAvB,EAA6B;AAC3B5D,aAAG,CAACiC,OAAJ,CAAY,KAAK2B,UAAjB;AACA,eAAKA,UAAL,GAAkB,EAAlB;AACD;;AAED,YAAIrC,KAAK,CAACC,OAAN,CAAc,KAAKC,IAAL,CAAUsB,SAAxB,CAAJ,EAAwC;AACtC,eAAKW,OAAL,GAAe,KAAKjC,IAAL,CAAUsB,SAAV,CAAoBY,GAApB,CAAwB,MAAM3D,GAAG,CAACmD,KAAJ,CAAUD,UAAV,CAA9B,CAAf;AACD,SAFD,MAEO;AACL,eAAKQ,OAAL,CAAa,CAAb,IAAkB1D,GAAG,CAACmD,KAAJ,CAAUD,UAAV,CAAlB;AACD;AACF,OAfM,MAeA;AACL,YAAI,CAAC3B,KAAK,CAACC,OAAN,CAAc8B,MAAd,CAAL,EAA4B;AAC1BA,gBAAM,GAAG,CAACA,MAAD,CAAT;AACD;;AAED,YAAIA,MAAM,CAACF,MAAP,KAAkB,KAAKM,OAAL,CAAaN,MAAnC,EAA2C;AACzC,gBAAM,IAAI5C,UAAJ,CACF,SAAS,KAAKqD,IAAI,YAAY,KAAKH,OAAL,CAAaN,MAAM,aAAjD,GACA,mBAAmBE,MAAM,CAACF,MAAM,yBADhC,GAEA,aAAaE,MAAM,EAHjB,CAAN;AAID;;AAED,YAAIlB,QAAJ,EAAc;AACZ;AACA;AACA;AACA;AACA,eAAKwB,UAAL,CAAgBE,IAAhB,CAAqB,KAAKJ,OAAL,CAAaf,KAAb,EAArB;AACD,SAND,MAMO;AACL3C,aAAG,CAACiC,OAAJ,CAAY,KAAKyB,OAAjB;AACD;;AAED,aAAK,IAAIK,KAAK,GAAG,CAAjB,EAAoBA,KAAK,GAAG,KAAKL,OAAL,CAAaN,MAAzC,EAAiD,EAAEW,KAAnD,EAA0D;AACxD,gBAAMC,KAAK,GAAGV,MAAM,CAACS,KAAD,CAApB;AAEA,gBAAME,aAAa,GAAGf,UAAtB;;AAEA,cAAI,CAACjD,IAAI,CAACiE,WAAL,CAAiBF,KAAK,CAAChB,KAAvB,EAA8BiB,aAA9B,CAAL,EAAmD;AACjD,kBAAM,IAAIzD,UAAJ,CACF,SAASuD,KAAK,+BAA+B,KAAKF,IAAI,IAAtD,GACA,kBAAkBI,aAAa,oBAC3BD,KAAK,CAAChB,KAAK,EAHb,CAAN;AAID;;AAED,eAAKU,OAAL,CAAaK,KAAb,IAAsBC,KAAtB;AACD;AACF;;AAED,WAAKN,OAAL,GAAe,KAAKA,OAAL,CAAaC,GAAb,CAAiBQ,KAAK,IAAInE,GAAG,CAACoE,IAAJ,CAASD,KAAK,CAACE,KAAN,EAAT,CAA1B,CAAf;AACD,KArFD;AAsFD;;AAES5B,0BAAwB,CAACF,UAAD,EAAkB;AAClD,UAAM;AAAC+B,gBAAD;AAAaC,aAAb;AAAsBC,gBAAtB;AAAkCC,aAAlC;AAA2CC,aAA3C;AAAoDC;AAApD,QACF,KAAKlD,IADT;AAGA,UAAMmD,eAAe,GAAGN,UAAU,KAAK,eAAvC;AAEA,UAAMO,CAAC,GAAGtC,UAAU,CAACqC,eAAe,GAAG,CAAH,GAAO,CAAvB,CAApB;AACA,UAAME,CAAC,GAAGvC,UAAU,CAACqC,eAAe,GAAG,CAAH,GAAO,CAAvB,CAApB;AAEA,UAAMG,IAAI,GAAGrE,gBAAgB,CACzBmE,CADyB,EACtBL,UAAU,CAAC,CAAD,CADY,EACPC,OADO,EACEC,OAAO,CAAC,CAAD,CADT,EACcC,YAAY,CAAC,CAAD,CAD1B,CAA7B;AAEA,UAAMK,IAAI,GAAGtE,gBAAgB,CACzBoE,CADyB,EACtBN,UAAU,CAAC,CAAD,CADY,EACPC,OADO,EACEC,OAAO,CAAC,CAAD,CADT,EACcC,YAAY,CAAC,CAAD,CAD1B,CAA7B;AAGA,UAAMnC,QAAQ,GAAU,CACtB,GAAGD,UAAU,CAACI,KAAX,CAAiB,CAAjB,EAAoB,CAApB,CADmB,EAEtB,IAAIiC,eAAe,GAAG,CAACL,OAAD,EAAUQ,IAAV,EAAgBC,IAAhB,CAAH,GAA2B,CAACD,IAAD,EAAOC,IAAP,EAAaT,OAAb,CAA9C,CAFsB,CAAxB;AAKA,WAAO/B,QAAP;AACD;;AAnMwB;AACzB;;;AACOrB,sBAAY,WAAZ;AAuMT,OAAM,MAAO8D,cAAP,SAA8BlE,QAA9B,CAAsC;AAW1CK,cAAYC,IAAZ,EAAoC;AAClC,UAAM;AACJkD,aADI;AAEJC,gBAFI;AAGJE,aAHI;AAIJD,aAJI;AAKJH,gBALI;AAMJK;AANI,QAOFtD,IAPJ;AASA,UAAK6D,kBAAK7D,IAAL,EAAS;AAAE8D,WAAK,EAAEZ;AAAT,KAAT,CAAL;AAEA,SAAKA,OAAL,GAAeA,OAAf;AACA3D,yBAAqB,CAAC,KAAK2D,OAAN,EAAe,SAAf,CAArB;AAEA,SAAKC,UAAL,GAAkB7D,cAAc,CAAC6D,UAAD,EAAa,CAAb,EAAgB,YAAhB,CAAhC;AACA,SAAKA,UAAL,CAAgBY,OAAhB,CAAwBC,IAAI,IAAIzE,qBAAqB,CAACyE,IAAD,EAAO,YAAP,CAArD;AAEA,SAAKX,OAAL,GAAe/D,cAAc,CAAC+D,OAAO,IAAI,CAAZ,EAAe,CAAf,EAAkB,SAAlB,CAA7B;AACA,SAAKA,OAAL,CAAaU,OAAb,CAAqBE,MAAM,IAAI1E,qBAAqB,CAAC0E,MAAD,EAAS,SAAT,CAApD;AAEA,SAAKb,OAAL,GAAeA,OAAO,IAAI,OAA1B;AACArE,oBAAgB,CAAC,KAAKqE,OAAN,CAAhB;AAEA,SAAKH,UAAL,GAAkBA,UAAU,IAAI,cAAhC;AACAnE,mBAAe,CAAC,KAAKmE,UAAN,CAAf;AAEA,SAAKK,YAAL,GAAoBhE,cAAc,CAACgE,YAAY,IAAI,CAAjB,EAAoB,CAApB,EAAuB,cAAvB,CAAlC;AACA,SAAKA,YAAL,CAAkBS,OAAlB,CACIG,IAAI,IAAI3E,qBAAqB,CAAC2E,IAAD,EAAO,cAAP,CADjC;AAED;;AAEMC,OAAK,CAACjD,UAAD,EAA0B;;;AACpCA,cAAU,GAAG1B,kBAAkB,CAAC0B,UAAD,CAA/B;AAEA,UAAMkD,WAAW,GACb,KAAKnB,UAAL,KAAoB,eAApB,GAAsC,CAAtC,GAA0C/B,UAAU,CAACa,MAAX,GAAoB,CADlE;;AAGA,QAAIb,UAAU,CAACkD,WAAD,CAAV,IAA2B,IAA/B,EAAqC;AACnC,YAAM,IAAIjF,UAAJ,CACF,2DACA,SAAS+B,UAAU,CAACkD,WAAD,CAAa,EAF9B,CAAN;AAGD;;AAED,UAAMC,QAAQ,GAAGnD,UAAU,CAACkD,WAAD,CAA3B;AAEA,UAAME,YAAY,GAAG,CAArB;AAEA,UAAMC,WAAW,GACb,KAAKpB,UAAL,CAAgBqB,MAAhB,CAAuB,CAACH,QAAD,EAAW,KAAKnB,OAAL,GAAeoB,YAA1B,CAAvB,CADJ;AAGA,SAAKG,MAAL,GAAc,KAAKC,SAAL,CACV,QADU,EACAH,WADA,EACa,IADb,EACmB,KAAKI,iBADxB,EAEV,KAAKC,iBAFK,EAEc,IAFd,EAEoB,KAAKC,gBAFzB,CAAd;AAIA,UAAMC,oBAAoB,GACtB,KAAK3B,UAAL,CAAgBqB,MAAhB,CAAuB,CAAC,KAAKtB,OAAN,EAAe,KAAKA,OAAL,GAAeoB,YAA9B,CAAvB,CADJ;AAGA,SAAKS,eAAL,GAAuB,KAAKL,SAAL,CACnB,kBADmB,EACCI,oBADD,EACuB,IADvB,EAEnB,KAAKE,oBAFc,EAEQ,KAAKC,oBAFb,EAEmC,IAFnC,EAGnB,KAAKC,mBAHc,CAAvB;;AAKA,QAAI,KAAKC,OAAT,EAAkB;AAChB,UAAIC,eAAJ;;AAEA,UAAI,KAAKC,cAAT,EAAyB;AACvB,cAAMC,IAAI,GAAG,KAAKF,eAAlB;AAEA,cAAMlC,OAAO,GAAG,KAAKA,OAArB;AAEAkC,uBAAe,GAAG,KAAIG,KAAC,MAAMC,UAAN,SAAyBpG,WAAzB,CAAoC;AAIzDqG,eAAK,CAAC9D,KAAD,EAAe+D,KAAf,EAA+B;AAClC,kBAAMC,KAAK,GAAGL,IAAI,CAACG,KAAL,CAAW,CAACvC,OAAD,CAAX,CAAd;AACA,kBAAM0C,KAAK,GAAGjH,GAAG,CAACkH,IAAJ,CAAS,CAAC3C,OAAD,CAAT,CAAd;AACA,kBAAM4C,SAAS,GAAGR,IAAI,CAACG,KAAL,CAAW,CAACvC,OAAO,GAAG,CAAX,CAAX,CAAlB;AACA,mBAAOrE,CAAC,CAACkH,WAAF,CAAc,CAACJ,KAAD,EAAQC,KAAR,EAAeE,SAAf,CAAd,CAAP;AACD;;AATwD,SAArC;AACpB;AACOP,uBAAY,YAFC,IAAJ,GAAlB;AAWD,OAhBD,MAgBO;AACLH,uBAAe,GAAG,KAAKA,eAAvB;AACD;;AAED,WAAKY,IAAL,GAAY,KAAKtB,SAAL,CACR,MADQ,EACA,CAAC,KAAKxB,OAAL,GAAeoB,YAAhB,CADA,EAC+B,IAD/B,EACqCc,eADrC,EAER,KAAKa,eAFG,EAEc,IAFd,EAEoB,KAAKC,cAFzB,CAAZ;AAGD;;AAED,SAAKC,KAAL,GAAa,IAAb;AACD;;AAED5F,MAAI,CAACC,MAAD,EAAuBC,MAAvB,EAAqC;AACvC,WAAO9B,GAAG,CAAC+B,IAAJ,CAAS,MAAK;AACnB,UAAIF,MAAM,CAACuB,MAAP,KAAkB,CAAtB,EAAyB;AACvB,cAAM,IAAI5C,UAAJ,CACF,gEACA,GAAGqB,MAAM,CAACuB,MAAM,GAFd,CAAN;AAGD;;AAED,YAAMhB,QAAQ,GAAGN,MAAM,CAAC,UAAD,CAAN,IAAsB,KAAvC;AAEA,YAAM2F,CAAC,GAAG5F,MAAM,CAAC,CAAD,CAAhB,CATmB,CASU;;AAC7B,YAAM6F,QAAQ,GAAG7F,MAAM,CAAC,CAAD,CAAvB,CAVmB,CAUU;;AAC7B,YAAM8F,QAAQ,GAAG9F,MAAM,CAAC,CAAD,CAAvB,CAXmB,CAWU;;AAE7B,YAAM8D,YAAY,GAAG,CAArB;;AAIA,UAAI,IAAI,KAAKiC,OAAT,IAAoB,KAAKA,OAAL,GAAe,CAAnC,IAAwC,KAAK5F,WAAL,IAAoB,IAAhE,EAAsE;AACpE,aAAKA,WAAL,GAAmBlB,mBAAmB,CAAC;AAClBoG,cAAI,EAAE,MAAMlH,GAAG,CAAC6H,QAAJ,CAAaJ,CAAb,CADM;AAElBlC,cAAI,EAAE,KAAKqC,OAFO;AAGlBxF,kBAHkB;AAIlB0F,eAAK,EAAEnC,YAJW;AAKlBoC,qBAAW,EAAE,KAAKA;AALA,SAAD,CAAtC;AAOD;;AAED,YAAM/F,WAAW,GAAG,KAAKA,WAAzB;;AAEA,YAAMgG,YAAY,GACd,CAACP,CAAD,EAAgBtF,IAAhB,EAAoC4B,KAApC,KAAqD;AACnD,YAAI,CAAC5B,IAAD,IAAS,CAACA,IAAI,CAAC4B,KAAD,CAAlB,EAA2B;AACzB,iBAAO0D,CAAP;AACD;;AAED,eAAOzH,GAAG,CAACiI,GAAJ,CAAQ9F,IAAI,CAAC4B,KAAD,CAAZ,EAAqB0D,CAArB,CAAP;AACD,OAPL;;AASA,UAAIS,EAAE,GAAGF,YAAY,CAACP,CAAD,EAAIzF,WAAJ,EAAiB,CAAjB,CAArB;AACA,UAAImG,EAAE,GAAGH,YAAY,CAACP,CAAD,EAAIzF,WAAJ,EAAiB,CAAjB,CAArB;AACA,UAAIoG,EAAE,GAAGJ,YAAY,CAACP,CAAD,EAAIzF,WAAJ,EAAiB,CAAjB,CAArB;AACA,UAAIqG,EAAE,GAAGL,YAAY,CAACP,CAAD,EAAIzF,WAAJ,EAAiB,CAAjB,CAArB;;AAEA,UAAI,IAAI,KAAKsG,gBAAT,IAA6B,KAAKA,gBAAL,GAAwB,CAArD,IACA,KAAKpG,oBAAL,IAA6B,IADjC,EACuC;AACrC,aAAKA,oBAAL,GAA4BpB,mBAAmB,CAAC;AAClBoG,cAAI,EAAE,MAAMlH,GAAG,CAAC6H,QAAJ,CAAaH,QAAb,CADM;AAElBnC,cAAI,EAAE,KAAK+C,gBAFO;AAGlBlG,kBAHkB;AAIlB0F,eAAK,EAAEnC,YAJW;AAKlBoC,qBAAW,EAAE,KAAKA;AALA,SAAD,CAA/C;AAOD;;AAED,YAAMQ,cAAc,GAAG,KAAKrG,oBAA5B;AAEA,UAAIsG,EAAE,GAAGR,YAAY,CAACN,QAAD,EAAWa,cAAX,EAA2B,CAA3B,CAArB;AACA,UAAIE,EAAE,GAAGT,YAAY,CAACN,QAAD,EAAWa,cAAX,EAA2B,CAA3B,CAArB;AACA,UAAIG,EAAE,GAAGV,YAAY,CAACN,QAAD,EAAWa,cAAX,EAA2B,CAA3B,CAArB;AACA,UAAII,EAAE,GAAGX,YAAY,CAACN,QAAD,EAAWa,cAAX,EAA2B,CAA3B,CAArB;AAEA,YAAMK,iBAAiB,GAAG,CAA1B;AAEA,YAAM,CAACC,OAAD,EAAUC,OAAV,EAAmBC,OAAnB,EAA4BC,OAA5B,IACFhJ,GAAG,CAACiJ,KAAJ,CAAU,KAAKnD,MAAL,CAAYoD,IAAZ,EAAV,EAA8BvD,YAA9B,EAA4CiD,iBAA5C,CADJ;AAGA,YAAM,CAAC5B,KAAD,EAAQC,KAAR,EAAekC,KAAf,EAAsBC,KAAtB,IAA6C,KAAK5C,OAAL,GAC/CxG,GAAG,CAACiJ,KAAJ,CAAU,KAAK5B,IAAL,CAAU6B,IAAV,EAAV,EAA4BvD,YAA5B,CAD+C,GAE/C,CAAC,IAAD,EAAO,IAAP,EAAa,IAAb,EAAmB,IAAnB,CAFJ;AAIAuC,QAAE,GAAG,KAAKmB,SAAL,CAAenB,EAAf,EAAmBW,OAAnB,EAA4B7B,KAA5B,EAAmC,KAAKvC,OAAxC,CAAL;AACA0D,QAAE,GAAG,KAAKkB,SAAL,CAAelB,EAAf,EAAmBW,OAAnB,EAA4B7B,KAA5B,EAAmC,KAAKxC,OAAxC,CAAL;AACA2D,QAAE,GAAG,KAAKiB,SAAL,CAAejB,EAAf,EAAmBW,OAAnB,EAA4BI,KAA5B,EAAmC,KAAK1E,OAAxC,CAAL;AACA4D,QAAE,GAAG,KAAKgB,SAAL,CAAehB,EAAf,EAAmBW,OAAnB,EAA4BI,KAA5B,EAAmC,KAAK3E,OAAxC,CAAL;AAEA,YAAM,CAAC6E,UAAD,EAAaC,UAAb,EAAyBC,UAAzB,EAAqCC,UAArC,IACFzJ,GAAG,CAACiJ,KAAJ,CACI,KAAK7C,eAAL,CAAqB8C,IAArB,EADJ,EACiCvD,YADjC,EAC+CiD,iBAD/C,CADJ;AAIAJ,QAAE,GAAG,KAAKkB,aAAL,CAAmBlB,EAAnB,EAAuBc,UAAvB,CAAL;AACAb,QAAE,GAAG,KAAKiB,aAAL,CAAmBjB,EAAnB,EAAuBc,UAAvB,CAAL;AACAb,QAAE,GAAG,KAAKgB,aAAL,CAAmBhB,EAAnB,EAAuBc,UAAvB,CAAL;AACAb,QAAE,GAAG,KAAKe,aAAL,CAAmBf,EAAnB,EAAuBc,UAAvB,CAAL;AAEA,YAAME,CAAC,GAAG,KAAKC,mBAAL,CAAyB9C,KAAzB,CAA+B9G,GAAG,CAAC6J,GAAJ,CAAQ3B,EAAR,EAAYM,EAAZ,CAA/B,CAAV;AACA,YAAMsB,CAAC,GAAG,KAAKF,mBAAL,CAAyB9C,KAAzB,CAA+B9G,GAAG,CAAC6J,GAAJ,CAAQ1B,EAAR,EAAYM,EAAZ,CAA/B,CAAV;AACA,YAAMsB,CAAC,GAAG/J,GAAG,CAAC6J,GAAJ,CACN7J,GAAG,CAACiI,GAAJ,CAAQ6B,CAAR,EAAWnC,QAAX,CADM,EAEN3H,GAAG,CAACiI,GAAJ,CAAQ0B,CAAR,EAAW,KAAKK,UAAL,CAAgBlD,KAAhB,CAAsB9G,GAAG,CAAC6J,GAAJ,CAAQzB,EAAR,EAAYM,EAAZ,CAAtB,CAAX,CAFM,CAAV;AAGA,YAAM7D,CAAC,GAAG7E,GAAG,CAACiI,GAAJ,CACN,KAAK2B,mBAAL,CAAyB9C,KAAzB,CAA+B9G,GAAG,CAAC6J,GAAJ,CAAQxB,EAAR,EAAYM,EAAZ,CAA/B,CADM,EAEN,KAAKqB,UAAL,CAAgBlD,KAAhB,CAAsBiD,CAAtB,CAFM,CAAV;AAIA,aAAO,CAAClF,CAAD,EAAIA,CAAJ,EAAOkF,CAAP,CAAP;AACD,KA9FM,CAAP;AA+FD;;AAEDE,WAAS;AACP,UAAMrD,sBAAN;AAAA,UAAM;AAAC,eAASsD;AAAV,QAAWtD,EAAjB;AAAA,UAAmBuD,kCAAnB;;AAEA,UAAMC,MAAM,GAAiC;AAC3C7F,aAAO,EAAE,KAAKA,OAD6B;AAE3CC,gBAAU,EAAE,KAAKA,UAF0B;AAG3CC,aAAO,EAAE,KAAKA,OAH6B;AAI3CH,gBAAU,EAAE,KAAKA,UAJ0B;AAK3CK,kBAAY,EAAE,KAAKA,YALwB;AAM3CD,aAAO,EAAE,KAAKA;AAN6B,KAA7C;AASA,6BAAWyF,UAAX,EAA0BC,MAA1B;AACD;;AAEDf,WAAS,CAAC5B,CAAD,EAAY3C,CAAZ,EAAuBuF,CAAvB,EAAmC5F,OAAnC,EAAwD;AAC/D,UAAM6F,GAAG,GAAGtK,GAAG,CAACuK,MAAJ,CACR9C,CADQ,EACW3C,CADX,EAC8B,KAAKJ,OADnC,EAEPD,OAAO,IAAI,OAFJ,EAGR,KAAKH,UAAL,KAAoB,eAApB,GAAsC,MAAtC,GAA+C,MAHvC,EAIR,KAAKK,YAJG,CAAZ;;AAMA,QAAI0F,CAAJ,EAAO;AACL,aAAOnK,CAAC,CAACsK,OAAF,CAAUF,GAAV,EAAeD,CAAf,EAAkB,KAAK/F,UAAvB,CAAP;AACD;;AAED,WAAOgG,GAAP;AACD;;AAEDZ,eAAa,CAACjC,CAAD,EAAY3C,CAAZ,EAAqB;AAChC,UAAMJ,OAAO,GAAG,CAAhB;AAEA,WAAO1E,GAAG,CAACuK,MAAJ,CACH9C,CADG,EACgB3C,CADhB,EACmCJ,OADnC,EAC4C,MAD5C,EAEH,KAAKJ,UAAL,KAAoB,eAApB,GAAsC,MAAtC,GAA+C,MAF5C,CAAP;AAGD;;AA9OyC;AAC1C;;AACOW,2BAAY,gBAAZ;AA+OTjF,GAAG,CAACyK,aAAJ,CAAkBC,aAAlB,CAAgCzF,cAAhC;AAKA,OAAM,MAAO0F,UAAP,SAA0BxJ,SAA1B,CAAmC;AAIvCC,cAAYC,IAAZ,EAAgC;AAC9B,UAAMI,IAAI,GAAG,IAAIwD,cAAJ,CAAmB5D,IAAnB,CAAb;AAEA,UAAM6D,kBAAI7D,IAAJ,EAAQ;AAAEI;AAAF,KAAR,CAAN;AACD;AAED;;;AACiB,SAAVmJ,UAAU,CACbC,GADa,EAEbT,MAFa,EAEuB;AACtC,WAAO,IAAIS,GAAJ,CAAQT,MAAR,CAAP;AACD;;AAfsC;AACvC;;AACOO,uBAAY,YAAZ;AAgBT3K,GAAG,CAACyK,aAAJ,CAAkBC,aAAlB,CAAgCC,UAAhC","names":["tfc","util","K","checkDataFormat","checkPaddingMode","InputSpec","AttributeError","NotImplementedError","ValueError","Initializer","convOutputLength","normalizeArray","assertPositiveInteger","getExactlyOneShape","generateDropoutMask","LSTMCell","RNN","RNNCell","ConvRNN2DCell","ConvRNN2D","constructor","args","unroll","Array","isArray","cell","inputSpec","ndim","call","inputs","kwargs","tidy","dropoutMask","dispose","recurrentDropoutMask","mask","training","initialState","computeOutputShape","inputShape","outShape","computeSingleOutputShape","returnSequences","slice","returnState","fill","getInitialState","stateSize","shape","outputShape","stateShape","zeros","length","resetStates","states","stateful","batchSize","getStates","states_","map","keptStates","name","push","index","value","expectedShape","arraysEqual","state","keep","clone","dataFormat","filters","kernelSize","padding","strides","dilationRate","isChannelsFirst","h","w","hOut","wOut","ConvLSTM2DCell","Object","units","forEach","size","stride","rate","build","channelAxis","inputDim","numOfKernels","kernelShape","concat","kernel","addWeight","kernelInitializer","kernelRegularizer","kernelConstraint","recurrentKernelShape","recurrentKernel","recurrentInitializer","recurrentRegularizer","recurrentConstraint","useBias","biasInitializer","unitForgetBias","init","_a","CustomInit","apply","dtype","biasI","biasF","ones","biasCAndO","concatenate","bias","biasRegularizer","biasConstraint","built","x","hTMinus1","cTMinus1","dropout","onesLike","count","dropoutFunc","applyDropout","mul","xI","xF","xC","xO","recurrentDropout","recDropoutMask","hI","hF","hC","hO","kernelChannelAxis","kernelI","kernelF","kernelC","kernelO","split","read","biasC","biasO","inputConv","recKernelI","recKernelF","recKernelC","recKernelO","recurrentConv","i","recurrentActivation","add","f","c","activation","getConfig","_","baseConfig","config","b","out","conv2d","biasAdd","serialization","registerClass","ConvLSTM2D","fromConfig","cls"],"sources":["/home/nadimakhtar97/smart-attendance-system/tfjs-layers/src/layers/convolutional_recurrent.ts"],"sourcesContent":["/**\n * @license\n * Copyright 2020 Google LLC\n *\n * Use of this source code is governed by an MIT-style\n * license that can be found in the LICENSE file or at\n * https://opensource.org/licenses/MIT.\n * =============================================================================\n */\n\nimport * as tfc from '@tensorflow/tfjs-core';\nimport {Tensor, util} from '@tensorflow/tfjs-core';\n\nimport {Activation} from '../activations';\nimport * as K from '../backend/tfjs_backend';\nimport {checkDataFormat, checkPaddingMode} from '../common';\nimport {Constraint} from '../constraints';\nimport {InputSpec} from '../engine/topology';\nimport {AttributeError, NotImplementedError, ValueError} from '../errors';\nimport {Initializer} from '../initializers';\nimport {DataFormat, DataType, PaddingMode, Shape} from '../keras_format/common';\nimport {Regularizer} from '../regularizers';\nimport {Kwargs} from '../types';\nimport {convOutputLength, normalizeArray} from '../utils/conv_utils';\nimport {assertPositiveInteger} from '../utils/generic_utils';\nimport {getExactlyOneShape} from '../utils/types_utils';\n\nimport {BaseRNNLayerArgs, generateDropoutMask, LSTMCell, LSTMCellLayerArgs, LSTMLayerArgs, RNN, RNNCell, RNNLayerArgs, SimpleRNNCellLayerArgs} from './recurrent';\n\ndeclare interface ConvRNN2DCellArgs extends\n    Omit<SimpleRNNCellLayerArgs, 'units'> {\n  /**\n   * The dimensionality of the output space (i.e. the number of filters in the\n   * convolution).\n   */\n  filters: number;\n\n  /**\n   * The dimensions of the convolution window. If kernelSize is a number, the\n   * convolutional window will be square.\n   */\n  kernelSize: number|number[];\n\n  /**\n   * The strides of the convolution in each dimension. If strides is a number,\n   * strides in both dimensions are equal.\n   *\n   * Specifying any stride value != 1 is incompatible with specifying any\n   * `dilationRate` value != 1.\n   */\n  strides?: number|number[];\n\n  /**\n   * Padding mode.\n   */\n  padding?: PaddingMode;\n\n  /**\n   * Format of the data, which determines the ordering of the dimensions in\n   * the inputs.\n   *\n   * `channels_last` corresponds to inputs with shape\n   *   `(batch, ..., channels)`\n   *\n   *  `channels_first` corresponds to inputs with shape `(batch, channels,\n   * ...)`.\n   *\n   * Defaults to `channels_last`.\n   */\n  dataFormat?: DataFormat;\n\n  /**\n   * The dilation rate to use for the dilated convolution in each dimension.\n   * Should be an integer or array of two or three integers.\n   *\n   * Currently, specifying any `dilationRate` value != 1 is incompatible with\n   * specifying any `strides` value != 1.\n   */\n  dilationRate?: number|[number]|[number, number];\n}\n\nabstract class ConvRNN2DCell extends RNNCell {\n  readonly filters: number;\n  readonly kernelSize: number[];\n  readonly strides: number[];\n  readonly padding: PaddingMode;\n  readonly dataFormat: DataFormat;\n  readonly dilationRate: number[];\n\n  readonly activation: Activation;\n  readonly useBias: boolean;\n\n  readonly kernelInitializer: Initializer;\n  readonly recurrentInitializer: Initializer;\n  readonly biasInitializer: Initializer;\n\n  readonly kernelConstraint: Constraint;\n  readonly recurrentConstraint: Constraint;\n  readonly biasConstraint: Constraint;\n\n  readonly kernelRegularizer: Regularizer;\n  readonly recurrentRegularizer: Regularizer;\n  readonly biasRegularizer: Regularizer;\n\n  readonly dropout: number;\n  readonly recurrentDropout: number;\n}\n\ndeclare interface ConvRNN2DLayerArgs extends BaseRNNLayerArgs,\n                                             ConvRNN2DCellArgs {}\n\n/**\n * Base class for convolutional-recurrent layers.\n */\nclass ConvRNN2D extends RNN {\n  /** @nocollapse */\n  static className = 'ConvRNN2D';\n\n  readonly cell: ConvRNN2DCell;\n\n  constructor(args: ConvRNN2DLayerArgs) {\n    if (args.unroll) {\n      throw new NotImplementedError(\n          'Unrolling is not possible with convolutional RNNs.');\n    }\n\n    if (Array.isArray(args.cell)) {\n      throw new NotImplementedError(\n          'It is not possible at the moment to stack convolutional cells.');\n    }\n\n    super(args as RNNLayerArgs);\n\n    this.inputSpec = [new InputSpec({ndim: 5})];\n  }\n\n  call(inputs: Tensor|Tensor[], kwargs: Kwargs): Tensor|Tensor[] {\n    return tfc.tidy(() => {\n      if (this.cell.dropoutMask != null) {\n        tfc.dispose(this.cell.dropoutMask);\n\n        this.cell.dropoutMask = null;\n      }\n\n      if (this.cell.recurrentDropoutMask != null) {\n        tfc.dispose(this.cell.recurrentDropoutMask);\n\n        this.cell.recurrentDropoutMask = null;\n      }\n\n      if (kwargs && kwargs['constants']) {\n        throw new ValueError('ConvRNN2D cell does not support constants');\n      }\n\n      const mask = kwargs == null ? null : kwargs['mask'];\n\n      const training = kwargs == null ? null : kwargs['training'];\n\n      const initialState: Tensor[] =\n          kwargs == null ? null : kwargs['initialState'];\n\n      return super.call(inputs, {mask, training, initialState});\n    });\n  }\n\n  computeOutputShape(inputShape: Shape): Shape|Shape[] {\n    let outShape: Shape = this.computeSingleOutputShape(inputShape);\n\n    if (!this.returnSequences) {\n      outShape = [outShape[0], ...outShape.slice(2)];\n    }\n\n    if (this.returnState) {\n      outShape =\n          [outShape, ...Array(2).fill([inputShape[0], ...outShape.slice(-3)])];\n    }\n\n    return outShape;\n  }\n\n  getInitialState(inputs: tfc.Tensor): tfc.Tensor[] {\n    return tfc.tidy(() => {\n      const {stateSize} = this.cell;\n\n      const inputShape = inputs.shape;\n\n      const outputShape = this.computeSingleOutputShape(inputShape);\n\n      const stateShape = [outputShape[0], ...outputShape.slice(2)];\n\n      const initialState = tfc.zeros(stateShape);\n\n      if (Array.isArray(stateSize)) {\n        return Array(stateSize.length).fill(initialState);\n      }\n\n      return [initialState];\n    });\n  }\n\n  resetStates(states?: Tensor|Tensor[], training = false): void {\n    tfc.tidy(() => {\n      if (!this.stateful) {\n        throw new AttributeError(\n            'Cannot call resetStates() on an RNN Layer that is not stateful.');\n      }\n\n      const inputShape = this.inputSpec[0].shape;\n\n      const outputShape = this.computeSingleOutputShape(inputShape);\n\n      const stateShape = [outputShape[0], ...outputShape.slice(2)];\n\n      const batchSize = inputShape[0];\n\n      if (batchSize == null) {\n        throw new ValueError(\n            'If an RNN is stateful, it needs to know its batch size. Specify ' +\n            'the batch size of your input tensors: \\n' +\n            '- If using a Sequential model, specify the batch size by ' +\n            'passing a `batchInputShape` option to your first layer.\\n' +\n            '- If using the functional API, specify the batch size by ' +\n            'passing a `batchShape` option to your Input layer.');\n      }\n\n      // Initialize state if null.\n      if (this.getStates() == null) {\n        if (Array.isArray(this.cell.stateSize)) {\n          this.states_ = this.cell.stateSize.map(() => tfc.zeros(stateShape));\n        } else {\n          this.states_ = [tfc.zeros(stateShape)];\n        }\n      } else if (states == null) {\n        // Dispose old state tensors.\n        tfc.dispose(this.states_);\n\n        // For stateful RNNs, fully dispose kept old states.\n        if (this.keptStates != null) {\n          tfc.dispose(this.keptStates);\n          this.keptStates = [];\n        }\n\n        if (Array.isArray(this.cell.stateSize)) {\n          this.states_ = this.cell.stateSize.map(() => tfc.zeros(stateShape));\n        } else {\n          this.states_[0] = tfc.zeros(stateShape);\n        }\n      } else {\n        if (!Array.isArray(states)) {\n          states = [states];\n        }\n\n        if (states.length !== this.states_.length) {\n          throw new ValueError(\n              `Layer ${this.name} expects ${this.states_.length} state(s), ` +\n              `but it received ${states.length} state value(s). Input ` +\n              `received: ${states}`);\n        }\n\n        if (training) {\n          // Store old state tensors for complete disposal later, i.e., during\n          // the next no-arg call to this method. We do not dispose the old\n          // states immediately because that BPTT (among other things) require\n          // them.\n          this.keptStates.push(this.states_.slice());\n        } else {\n          tfc.dispose(this.states_);\n        }\n\n        for (let index = 0; index < this.states_.length; ++index) {\n          const value = states[index];\n\n          const expectedShape = stateShape;\n\n          if (!util.arraysEqual(value.shape, expectedShape)) {\n            throw new ValueError(\n                `State ${index} is incompatible with layer ${this.name}: ` +\n                `expected shape=${expectedShape}, received shape=${\n                    value.shape}`);\n          }\n\n          this.states_[index] = value;\n        }\n      }\n\n      this.states_ = this.states_.map(state => tfc.keep(state.clone()));\n    });\n  }\n\n  protected computeSingleOutputShape(inputShape: Shape): Shape {\n    const {dataFormat, filters, kernelSize, padding, strides, dilationRate} =\n        this.cell;\n\n    const isChannelsFirst = dataFormat === 'channelsFirst';\n\n    const h = inputShape[isChannelsFirst ? 3 : 2];\n    const w = inputShape[isChannelsFirst ? 4 : 3];\n\n    const hOut = convOutputLength(\n        h, kernelSize[0], padding, strides[0], dilationRate[0]);\n    const wOut = convOutputLength(\n        w, kernelSize[1], padding, strides[1], dilationRate[1]);\n\n    const outShape: Shape = [\n      ...inputShape.slice(0, 2),\n      ...(isChannelsFirst ? [filters, hOut, wOut] : [hOut, wOut, filters])\n    ];\n\n    return outShape;\n  }\n}\n\nexport declare interface ConvLSTM2DCellArgs extends\n    Omit<LSTMCellLayerArgs, 'units'>, ConvRNN2DCellArgs {}\n\nexport class ConvLSTM2DCell extends LSTMCell implements ConvRNN2DCell {\n  /** @nocollapse */\n  static className = 'ConvLSTM2DCell';\n\n  readonly filters: number;\n  readonly kernelSize: number[];\n  readonly strides: number[];\n  readonly padding: PaddingMode;\n  readonly dataFormat: DataFormat;\n  readonly dilationRate: number[];\n\n  constructor(args: ConvLSTM2DCellArgs) {\n    const {\n      filters,\n      kernelSize,\n      strides,\n      padding,\n      dataFormat,\n      dilationRate,\n    } = args;\n\n    super({...args, units: filters});\n\n    this.filters = filters;\n    assertPositiveInteger(this.filters, 'filters');\n\n    this.kernelSize = normalizeArray(kernelSize, 2, 'kernelSize');\n    this.kernelSize.forEach(size => assertPositiveInteger(size, 'kernelSize'));\n\n    this.strides = normalizeArray(strides || 1, 2, 'strides');\n    this.strides.forEach(stride => assertPositiveInteger(stride, 'strides'));\n\n    this.padding = padding || 'valid';\n    checkPaddingMode(this.padding);\n\n    this.dataFormat = dataFormat || 'channelsLast';\n    checkDataFormat(this.dataFormat);\n\n    this.dilationRate = normalizeArray(dilationRate || 1, 2, 'dilationRate');\n    this.dilationRate.forEach(\n        rate => assertPositiveInteger(rate, 'dilationRate'));\n  }\n\n  public build(inputShape: Shape|Shape[]): void {\n    inputShape = getExactlyOneShape(inputShape);\n\n    const channelAxis =\n        this.dataFormat === 'channelsFirst' ? 1 : inputShape.length - 1;\n\n    if (inputShape[channelAxis] == null) {\n      throw new ValueError(\n          `The channel dimension of the input should be defined. ` +\n          `Found ${inputShape[channelAxis]}`);\n    }\n\n    const inputDim = inputShape[channelAxis];\n\n    const numOfKernels = 4;\n\n    const kernelShape =\n        this.kernelSize.concat([inputDim, this.filters * numOfKernels]);\n\n    this.kernel = this.addWeight(\n        'kernel', kernelShape, null, this.kernelInitializer,\n        this.kernelRegularizer, true, this.kernelConstraint);\n\n    const recurrentKernelShape =\n        this.kernelSize.concat([this.filters, this.filters * numOfKernels]);\n\n    this.recurrentKernel = this.addWeight(\n        'recurrent_kernel', recurrentKernelShape, null,\n        this.recurrentInitializer, this.recurrentRegularizer, true,\n        this.recurrentConstraint);\n\n    if (this.useBias) {\n      let biasInitializer: Initializer;\n\n      if (this.unitForgetBias) {\n        const init = this.biasInitializer;\n\n        const filters = this.filters;\n\n        biasInitializer = new (class CustomInit extends Initializer {\n          /** @nocollapse */\n          static className = 'CustomInit';\n\n          apply(shape: Shape, dtype?: DataType): tfc.Tensor {\n            const biasI = init.apply([filters]);\n            const biasF = tfc.ones([filters]);\n            const biasCAndO = init.apply([filters * 2]);\n            return K.concatenate([biasI, biasF, biasCAndO]);\n          }\n        })();\n      } else {\n        biasInitializer = this.biasInitializer;\n      }\n\n      this.bias = this.addWeight(\n          'bias', [this.filters * numOfKernels], null, biasInitializer,\n          this.biasRegularizer, true, this.biasConstraint);\n    }\n\n    this.built = true;\n  }\n\n  call(inputs: tfc.Tensor[], kwargs: Kwargs): tfc.Tensor[] {\n    return tfc.tidy(() => {\n      if (inputs.length !== 3) {\n        throw new ValueError(\n            `ConvLSTM2DCell expects 3 input Tensors (inputs, h, c), got ` +\n            `${inputs.length}.`);\n      }\n\n      const training = kwargs['training'] || false;\n\n      const x = inputs[0];         // Current input\n      const hTMinus1 = inputs[1];  // Previous memory state.\n      const cTMinus1 = inputs[2];  // Previous carry state.\n\n      const numOfKernels = 4;\n\n      type DropoutMasks = [tfc.Tensor, tfc.Tensor, tfc.Tensor, tfc.Tensor];\n\n      if (0 < this.dropout && this.dropout < 1 && this.dropoutMask == null) {\n        this.dropoutMask = generateDropoutMask({\n                             ones: () => tfc.onesLike(x),\n                             rate: this.dropout,\n                             training,\n                             count: numOfKernels,\n                             dropoutFunc: this.dropoutFunc\n                           }) as tfc.Tensor[];\n      }\n\n      const dropoutMask = this.dropoutMask as DropoutMasks;\n\n      const applyDropout =\n          (x: tfc.Tensor, mask: tfc.Tensor[], index: number) => {\n            if (!mask || !mask[index]) {\n              return x;\n            }\n\n            return tfc.mul(mask[index], x);\n          };\n\n      let xI = applyDropout(x, dropoutMask, 0);\n      let xF = applyDropout(x, dropoutMask, 1);\n      let xC = applyDropout(x, dropoutMask, 2);\n      let xO = applyDropout(x, dropoutMask, 3);\n\n      if (0 < this.recurrentDropout && this.recurrentDropout < 1 &&\n          this.recurrentDropoutMask == null) {\n        this.recurrentDropoutMask = generateDropoutMask({\n                                      ones: () => tfc.onesLike(hTMinus1),\n                                      rate: this.recurrentDropout,\n                                      training,\n                                      count: numOfKernels,\n                                      dropoutFunc: this.dropoutFunc\n                                    }) as tfc.Tensor[];\n      }\n\n      const recDropoutMask = this.recurrentDropoutMask as DropoutMasks;\n\n      let hI = applyDropout(hTMinus1, recDropoutMask, 0);\n      let hF = applyDropout(hTMinus1, recDropoutMask, 1);\n      let hC = applyDropout(hTMinus1, recDropoutMask, 2);\n      let hO = applyDropout(hTMinus1, recDropoutMask, 3);\n\n      const kernelChannelAxis = 3;\n\n      const [kernelI, kernelF, kernelC, kernelO]: tfc.Tensor[] =\n          tfc.split(this.kernel.read(), numOfKernels, kernelChannelAxis);\n\n      const [biasI, biasF, biasC, biasO]: tfc.Tensor[] = this.useBias ?\n          tfc.split(this.bias.read(), numOfKernels) :\n          [null, null, null, null];\n\n      xI = this.inputConv(xI, kernelI, biasI, this.padding);\n      xF = this.inputConv(xF, kernelF, biasF, this.padding);\n      xC = this.inputConv(xC, kernelC, biasC, this.padding);\n      xO = this.inputConv(xO, kernelO, biasO, this.padding);\n\n      const [recKernelI, recKernelF, recKernelC, recKernelO]: tfc.Tensor[] =\n          tfc.split(\n              this.recurrentKernel.read(), numOfKernels, kernelChannelAxis);\n\n      hI = this.recurrentConv(hI, recKernelI);\n      hF = this.recurrentConv(hF, recKernelF);\n      hC = this.recurrentConv(hC, recKernelC);\n      hO = this.recurrentConv(hO, recKernelO);\n\n      const i = this.recurrentActivation.apply(tfc.add(xI, hI));\n      const f = this.recurrentActivation.apply(tfc.add(xF, hF));\n      const c = tfc.add(\n          tfc.mul(f, cTMinus1),\n          tfc.mul(i, this.activation.apply(tfc.add(xC, hC))));\n      const h = tfc.mul(\n          this.recurrentActivation.apply(tfc.add(xO, hO)),\n          this.activation.apply(c));\n\n      return [h, h, c];\n    });\n  }\n\n  getConfig(): tfc.serialization.ConfigDict {\n    const {'units': _, ...baseConfig} = super.getConfig();\n\n    const config: tfc.serialization.ConfigDict = {\n      filters: this.filters,\n      kernelSize: this.kernelSize,\n      padding: this.padding,\n      dataFormat: this.dataFormat,\n      dilationRate: this.dilationRate,\n      strides: this.strides,\n    };\n\n    return {...baseConfig, ...config};\n  }\n\n  inputConv(x: Tensor, w: Tensor, b?: Tensor, padding?: PaddingMode) {\n    const out = tfc.conv2d(\n        x as tfc.Tensor3D, w as tfc.Tensor4D, this.strides as [number, number],\n        (padding || 'valid') as 'same' | 'valid',\n        this.dataFormat === 'channelsFirst' ? 'NCHW' : 'NHWC',\n        this.dilationRate as [number, number]);\n\n    if (b) {\n      return K.biasAdd(out, b, this.dataFormat) as tfc.Tensor3D;\n    }\n\n    return out;\n  }\n\n  recurrentConv(x: Tensor, w: Tensor) {\n    const strides = 1;\n\n    return tfc.conv2d(\n        x as tfc.Tensor3D, w as tfc.Tensor4D, strides, 'same',\n        this.dataFormat === 'channelsFirst' ? 'NCHW' : 'NHWC');\n  }\n}\n\ntfc.serialization.registerClass(ConvLSTM2DCell);\n\nexport declare interface ConvLSTM2DArgs extends\n    Omit<LSTMLayerArgs, 'units'|'cell'>, ConvRNN2DLayerArgs {}\n\nexport class ConvLSTM2D extends ConvRNN2D {\n  /** @nocollapse */\n  static className = 'ConvLSTM2D';\n\n  constructor(args: ConvLSTM2DArgs) {\n    const cell = new ConvLSTM2DCell(args);\n\n    super({...args, cell} as ConvRNN2DLayerArgs);\n  }\n\n  /** @nocollapse */\n  static fromConfig<T extends tfc.serialization.Serializable>(\n      cls: tfc.serialization.SerializableConstructor<T>,\n      config: tfc.serialization.ConfigDict): T {\n    return new cls(config);\n  }\n}\n\ntfc.serialization.registerClass(ConvLSTM2D);\n"]},"metadata":{},"sourceType":"module"}