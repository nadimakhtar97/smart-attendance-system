{"ast":null,"code":"/**\n * @license\n * Copyright 2017 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { getGlobal } from './global_util';\nimport { tensorToString } from './tensor_format';\nimport * as util from './util';\nimport { computeStrides, toNestedArray } from './util';\n/**\n * A mutable object, similar to `tf.Tensor`, that allows users to set values\n * at locations before converting to an immutable `tf.Tensor`.\n *\n * See `tf.buffer` for creating a tensor buffer.\n *\n * @doc {heading: 'Tensors', subheading: 'Classes'}\n */\n\nexport class TensorBuffer {\n  constructor(shape, dtype, values) {\n    this.dtype = dtype;\n    this.shape = shape.slice();\n    this.size = util.sizeFromShape(shape);\n\n    if (values != null) {\n      const n = values.length;\n      util.assert(n === this.size, () => `Length of values '${n}' does not match the size ` + `inferred by the shape '${this.size}'.`);\n    }\n\n    if (dtype === 'complex64') {\n      throw new Error(`complex64 dtype TensorBuffers are not supported. Please create ` + `a TensorBuffer for the real and imaginary parts separately and ` + `call tf.complex(real, imag).`);\n    }\n\n    this.values = values || util.getArrayFromDType(dtype, this.size);\n    this.strides = computeStrides(shape);\n  }\n  /**\n   * Sets a value in the buffer at a given location.\n   *\n   * @param value The value to set.\n   * @param locs  The location indices.\n   *\n   * @doc {heading: 'Tensors', subheading: 'Creation'}\n   */\n\n\n  set(value) {\n    for (var _len = arguments.length, locs = new Array(_len > 1 ? _len - 1 : 0), _key = 1; _key < _len; _key++) {\n      locs[_key - 1] = arguments[_key];\n    }\n\n    if (locs.length === 0) {\n      locs = [0];\n    }\n\n    util.assert(locs.length === this.rank, () => `The number of provided coordinates (${locs.length}) must ` + `match the rank (${this.rank})`);\n    const index = this.locToIndex(locs);\n    this.values[index] = value;\n  }\n  /**\n   * Returns the value in the buffer at the provided location.\n   *\n   * @param locs The location indices.\n   *\n   * @doc {heading: 'Tensors', subheading: 'Creation'}\n   */\n\n\n  get() {\n    for (var _len2 = arguments.length, locs = new Array(_len2), _key2 = 0; _key2 < _len2; _key2++) {\n      locs[_key2] = arguments[_key2];\n    }\n\n    if (locs.length === 0) {\n      locs = [0];\n    }\n\n    let i = 0;\n\n    for (const loc of locs) {\n      if (loc < 0 || loc >= this.shape[i]) {\n        const msg = `Requested out of range element at ${locs}. ` + `  Buffer shape=${this.shape}`;\n        throw new Error(msg);\n      }\n\n      i++;\n    }\n\n    let index = locs[locs.length - 1];\n\n    for (let i = 0; i < locs.length - 1; ++i) {\n      index += this.strides[i] * locs[i];\n    }\n\n    return this.values[index];\n  }\n\n  locToIndex(locs) {\n    if (this.rank === 0) {\n      return 0;\n    } else if (this.rank === 1) {\n      return locs[0];\n    }\n\n    let index = locs[locs.length - 1];\n\n    for (let i = 0; i < locs.length - 1; ++i) {\n      index += this.strides[i] * locs[i];\n    }\n\n    return index;\n  }\n\n  indexToLoc(index) {\n    if (this.rank === 0) {\n      return [];\n    } else if (this.rank === 1) {\n      return [index];\n    }\n\n    const locs = new Array(this.shape.length);\n\n    for (let i = 0; i < locs.length - 1; ++i) {\n      locs[i] = Math.floor(index / this.strides[i]);\n      index -= locs[i] * this.strides[i];\n    }\n\n    locs[locs.length - 1] = index;\n    return locs;\n  }\n\n  get rank() {\n    return this.shape.length;\n  }\n  /**\n   * Creates an immutable `tf.Tensor` object from the buffer.\n   *\n   * @doc {heading: 'Tensors', subheading: 'Creation'}\n   */\n\n\n  toTensor() {\n    return trackerFn().makeTensor(this.values, this.shape, this.dtype);\n  }\n\n} // For tracking tensor creation and disposal.\n\nlet trackerFn = null; // Used by chaining methods to call into ops.\n\nlet opHandler = null; // Used to warn about deprecated methods.\n\nlet deprecationWarningFn = null; // This here so that we can use this method on dev branches and keep the\n// functionality at master.\n// tslint:disable-next-line:no-unused-expression\n\n[deprecationWarningFn];\n/**\n * An external consumer can register itself as the tensor tracker. This way\n * the Tensor class can notify the tracker for every tensor created and\n * disposed.\n */\n\nexport function setTensorTracker(fn) {\n  trackerFn = fn;\n}\n/**\n * An external consumer can register itself as the op handler. This way the\n * Tensor class can have chaining methods that call into ops via the op\n * handler.\n */\n\nexport function setOpHandler(handler) {\n  opHandler = handler;\n}\n/**\n * Sets the deprecation warning function to be used by this file. This way the\n * Tensor class can be a leaf but still use the environment.\n */\n\nexport function setDeprecationWarningFn(fn) {\n  deprecationWarningFn = fn;\n}\n/**\n * A `tf.Tensor` object represents an immutable, multidimensional array of\n * numbers that has a shape and a data type.\n *\n * For performance reasons, functions that create tensors do not necessarily\n * perform a copy of the data passed to them (e.g. if the data is passed as a\n * `Float32Array`), and changes to the data will change the tensor. This is not\n * a feature and is not supported. To avoid this behavior, use the tensor before\n * changing the input data or create a copy with `copy = tf.add(yourTensor, 0)`.\n *\n * See `tf.tensor` for details on how to create a `tf.Tensor`.\n *\n * @doc {heading: 'Tensors', subheading: 'Classes'}\n */\n\nexport class Tensor {\n  constructor(shape, dtype, dataId, id) {\n    /** Whether this tensor has been globally kept. */\n    this.kept = false;\n    this.isDisposedInternal = false;\n    this.shape = shape.slice();\n    this.dtype = dtype || 'float32';\n    this.size = util.sizeFromShape(shape);\n    this.strides = computeStrides(shape);\n    this.dataId = dataId;\n    this.id = id;\n    this.rankType = this.rank < 5 ? this.rank.toString() : 'higher';\n  }\n\n  get rank() {\n    return this.shape.length;\n  }\n  /**\n   * Returns a promise of `tf.TensorBuffer` that holds the underlying data.\n   *\n   * @doc {heading: 'Tensors', subheading: 'Classes'}\n   */\n\n\n  async buffer() {\n    const vals = await this.data();\n    return opHandler.buffer(this.shape, this.dtype, vals);\n  }\n  /**\n   * Returns a `tf.TensorBuffer` that holds the underlying data.\n   * @doc {heading: 'Tensors', subheading: 'Classes'}\n   */\n\n\n  bufferSync() {\n    return opHandler.buffer(this.shape, this.dtype, this.dataSync());\n  }\n  /**\n   * Returns the tensor data as a nested array. The transfer of data is done\n   * asynchronously.\n   *\n   * @doc {heading: 'Tensors', subheading: 'Classes'}\n   */\n\n\n  async array() {\n    const vals = await this.data();\n    return toNestedArray(this.shape, vals, this.dtype === 'complex64');\n  }\n  /**\n   * Returns the tensor data as a nested array. The transfer of data is done\n   * synchronously.\n   *\n   * @doc {heading: 'Tensors', subheading: 'Classes'}\n   */\n\n\n  arraySync() {\n    return toNestedArray(this.shape, this.dataSync(), this.dtype === 'complex64');\n  }\n  /**\n   * Asynchronously downloads the values from the `tf.Tensor`. Returns a\n   * promise of `TypedArray` that resolves when the computation has finished.\n   *\n   * @doc {heading: 'Tensors', subheading: 'Classes'}\n   */\n\n\n  async data() {\n    this.throwIfDisposed();\n    const data = trackerFn().read(this.dataId);\n\n    if (this.dtype === 'string') {\n      const bytes = await data;\n\n      try {\n        return bytes.map(b => util.decodeString(b));\n      } catch (_a) {\n        throw new Error('Failed to decode the string bytes into utf-8. ' + 'To get the original bytes, call tensor.bytes().');\n      }\n    }\n\n    return data;\n  }\n  /**\n   * Copy the tensor's data to a new GPU resource. Comparing to the `dataSync()`\n   * and `data()`, this method prevents data from being downloaded to CPU.\n   *\n   * For WebGL backend, the data will be stored on a densely packed texture.\n   * This means that the texture will use the RGBA channels to store value.\n   *\n   * @param options:\n   *     For WebGL,\n   *         - customTexShape: Optional. If set, will use the user defined\n   *     texture shape to create the texture.\n   *\n   * @returns For WebGL backend, a GPUData contains the new texture and\n   *     its information.\n   *     {\n   *        tensorRef: The tensor that is associated with this texture,\n   *        texture: WebGLTexture,\n   *        texShape: [number, number] // [height, width]\n   *     }\n   *     Remember to dispose the GPUData after it is used by\n   *     `res.tensorRef.dispose()`.\n   *\n   * @doc {heading: 'Tensors', subheading: 'Classes'}\n   */\n\n\n  dataToGPU(options) {\n    this.throwIfDisposed();\n    return trackerFn().readToGPU(this.dataId, options);\n  }\n  /**\n   * Synchronously downloads the values from the `tf.Tensor`. This blocks the\n   * UI thread until the values are ready, which can cause performance issues.\n   *\n   * @doc {heading: 'Tensors', subheading: 'Classes'}\n   */\n\n\n  dataSync() {\n    this.throwIfDisposed();\n    const data = trackerFn().readSync(this.dataId);\n\n    if (this.dtype === 'string') {\n      try {\n        return data.map(b => util.decodeString(b));\n      } catch (_a) {\n        throw new Error('Failed to decode the string bytes into utf-8. ' + 'To get the original bytes, call tensor.bytes().');\n      }\n    }\n\n    return data;\n  }\n  /** Returns the underlying bytes of the tensor's data. */\n\n\n  async bytes() {\n    this.throwIfDisposed();\n    const data = await trackerFn().read(this.dataId);\n\n    if (this.dtype === 'string') {\n      return data;\n    } else {\n      return new Uint8Array(data.buffer);\n    }\n  }\n  /**\n   * Disposes `tf.Tensor` from memory.\n   *\n   * @doc {heading: 'Tensors', subheading: 'Classes'}\n   */\n\n\n  dispose() {\n    if (this.isDisposed) {\n      return;\n    }\n\n    trackerFn().disposeTensor(this);\n    this.isDisposedInternal = true;\n  }\n\n  get isDisposed() {\n    return this.isDisposedInternal;\n  }\n\n  throwIfDisposed() {\n    if (this.isDisposed) {\n      throw new Error(`Tensor is disposed.`);\n    }\n  }\n  /**\n   * Prints the `tf.Tensor`. See `tf.print` for details.\n   *\n   * @param verbose Whether to print verbose information about the tensor,\n   *    including dtype and size.\n   *\n   * @doc {heading: 'Tensors', subheading: 'Classes'}\n   */\n\n\n  print() {\n    let verbose = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : false;\n    return opHandler.print(this, verbose);\n  }\n  /**\n   * Returns a copy of the tensor. See `tf.clone` for details.\n   * @doc {heading: 'Tensors', subheading: 'Classes'}\n   */\n\n\n  clone() {\n    this.throwIfDisposed();\n    return opHandler.clone(this);\n  }\n  /**\n   * Returns a human-readable description of the tensor. Useful for logging.\n   *\n   * @doc {heading: 'Tensors', subheading: 'Classes'}\n   */\n\n\n  toString() {\n    let verbose = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : false;\n    const vals = this.dataSync();\n    return tensorToString(vals, this.shape, this.dtype, verbose);\n  }\n\n  cast(dtype) {\n    this.throwIfDisposed();\n    return opHandler.cast(this, dtype);\n  }\n\n  variable() {\n    let trainable = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : true;\n    let name = arguments.length > 1 ? arguments[1] : undefined;\n    let dtype = arguments.length > 2 ? arguments[2] : undefined;\n    this.throwIfDisposed();\n    return trackerFn().makeVariable(this, trainable, name, dtype);\n  }\n\n}\nObject.defineProperty(Tensor, Symbol.hasInstance, {\n  value: instance => {\n    // Implementation note: we should use properties of the object that will be\n    // defined before the constructor body has finished executing (methods).\n    // This is because when this code is transpiled by babel, babel will call\n    // classCallCheck before the constructor body is run.\n    // See https://github.com/tensorflow/tfjs/issues/3384 for backstory.\n    return !!instance && instance.data != null && instance.dataSync != null && instance.throwIfDisposed != null;\n  }\n});\nexport function getGlobalTensorClass() {\n  // Use getGlobal so that we can augment the Tensor class across package\n  // boundaries becase the node resolution alg may result in different modules\n  // being returned for this file depending on the path they are loaded from.\n  return getGlobal('Tensor', () => {\n    return Tensor;\n  });\n} // Global side effect. Cache global reference to Tensor class\n\ngetGlobalTensorClass();\n/**\n * A mutable `tf.Tensor`, useful for persisting state, e.g. for training.\n *\n * @doc {heading: 'Tensors', subheading: 'Classes'}\n */\n\nexport class Variable extends Tensor {\n  constructor(initialValue, trainable, name, tensorId) {\n    super(initialValue.shape, initialValue.dtype, initialValue.dataId, tensorId);\n    this.trainable = trainable;\n    this.name = name;\n  }\n  /**\n   * Assign a new `tf.Tensor` to this variable. The new `tf.Tensor` must have\n   * the same shape and dtype as the old `tf.Tensor`.\n   *\n   * @param newValue New tensor to be assigned to this variable.\n   *\n   * @doc {heading: 'Tensors', subheading: 'Classes'}\n   */\n\n\n  assign(newValue) {\n    if (newValue.dtype !== this.dtype) {\n      throw new Error(`dtype of the new value (${newValue.dtype}) and ` + `previous value (${this.dtype}) must match`);\n    }\n\n    if (!util.arraysEqual(newValue.shape, this.shape)) {\n      throw new Error(`shape of the new value (${newValue.shape}) and ` + `previous value (${this.shape}) must match`);\n    }\n\n    trackerFn().disposeTensor(this);\n    this.dataId = newValue.dataId;\n    trackerFn().incRef(this, null\n    /* backend */\n    );\n  }\n\n  dispose() {\n    trackerFn().disposeVariable(this);\n    this.isDisposedInternal = true;\n  }\n\n}\nObject.defineProperty(Variable, Symbol.hasInstance, {\n  value: instance => {\n    return instance instanceof Tensor && instance.assign != null && instance.assign instanceof Function;\n  }\n});","map":{"version":3,"mappings":"AAAA;;;;;;;;;;;;;;;;AAiBA,SAAQA,SAAR,QAAwB,eAAxB;AACA,SAAQC,cAAR,QAA6B,iBAA7B;AAEA,OAAO,KAAKC,IAAZ,MAAsB,QAAtB;AACA,SAAQC,cAAR,EAAwBC,aAAxB,QAA4C,QAA5C;AAWA;;;;;;;;;AAQA,OAAM,MAAOC,YAAP,CAAmB;AAMvBC,cAAYC,KAAZ,EAAuCC,KAAvC,EAAiDC,MAAjD,EAAwE;AAAjC;AACrC,SAAKF,KAAL,GAAaA,KAAK,CAACG,KAAN,EAAb;AACA,SAAKC,IAAL,GAAYT,IAAI,CAACU,aAAL,CAAmBL,KAAnB,CAAZ;;AAEA,QAAIE,MAAM,IAAI,IAAd,EAAoB;AAClB,YAAMI,CAAC,GAAGJ,MAAM,CAACK,MAAjB;AACAZ,UAAI,CAACa,MAAL,CACIF,CAAC,KAAK,KAAKF,IADf,EAEI,MAAM,qBAAqBE,CAAC,4BAAtB,GACF,0BAA0B,KAAKF,IAAI,IAH3C;AAID;;AACD,QAAIH,KAAK,KAAK,WAAd,EAA2B;AACzB,YAAM,IAAIQ,KAAJ,CACF,oEACA,iEADA,GAEA,8BAHE,CAAN;AAID;;AACD,SAAKP,MAAL,GAAcA,MAAM,IAAIP,IAAI,CAACe,iBAAL,CAAuBT,KAAvB,EAA8B,KAAKG,IAAnC,CAAxB;AACA,SAAKO,OAAL,GAAef,cAAc,CAACI,KAAD,CAA7B;AACD;AAED;;;;;;;;;;AAQAY,KAAG,CAACC,KAAD,EAA4C;AAAA,sCAAdC,IAAc;AAAdA,UAAc;AAAA;;AAC7C,QAAIA,IAAI,CAACP,MAAL,KAAgB,CAApB,EAAuB;AACrBO,UAAI,GAAG,CAAC,CAAD,CAAP;AACD;;AACDnB,QAAI,CAACa,MAAL,CACIM,IAAI,CAACP,MAAL,KAAgB,KAAKQ,IADzB,EAEI,MAAM,uCAAuCD,IAAI,CAACP,MAAM,SAAlD,GACF,mBAAmB,KAAKQ,IAAI,GAHpC;AAKA,UAAMC,KAAK,GAAG,KAAKC,UAAL,CAAgBH,IAAhB,CAAd;AACA,SAAKZ,MAAL,CAAYc,KAAZ,IAAqBH,KAArB;AACD;AAED;;;;;;;;;AAOAK,KAAG,GAAkB;AAAA,uCAAdJ,IAAc;AAAdA,UAAc;AAAA;;AACnB,QAAIA,IAAI,CAACP,MAAL,KAAgB,CAApB,EAAuB;AACrBO,UAAI,GAAG,CAAC,CAAD,CAAP;AACD;;AACD,QAAIK,CAAC,GAAG,CAAR;;AACA,SAAK,MAAMC,GAAX,IAAkBN,IAAlB,EAAwB;AACtB,UAAIM,GAAG,GAAG,CAAN,IAAWA,GAAG,IAAI,KAAKpB,KAAL,CAAWmB,CAAX,CAAtB,EAAqC;AACnC,cAAME,GAAG,GAAG,qCAAqCP,IAAI,IAAzC,GACR,kBAAkB,KAAKd,KAAK,EADhC;AAEA,cAAM,IAAIS,KAAJ,CAAUY,GAAV,CAAN;AACD;;AACDF,OAAC;AACF;;AACD,QAAIH,KAAK,GAAGF,IAAI,CAACA,IAAI,CAACP,MAAL,GAAc,CAAf,CAAhB;;AACA,SAAK,IAAIY,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAGL,IAAI,CAACP,MAAL,GAAc,CAAlC,EAAqC,EAAEY,CAAvC,EAA0C;AACxCH,WAAK,IAAI,KAAKL,OAAL,CAAaQ,CAAb,IAAkBL,IAAI,CAACK,CAAD,CAA/B;AACD;;AACD,WAAO,KAAKjB,MAAL,CAAYc,KAAZ,CAAP;AACD;;AAEDC,YAAU,CAACH,IAAD,EAAe;AACvB,QAAI,KAAKC,IAAL,KAAc,CAAlB,EAAqB;AACnB,aAAO,CAAP;AACD,KAFD,MAEO,IAAI,KAAKA,IAAL,KAAc,CAAlB,EAAqB;AAC1B,aAAOD,IAAI,CAAC,CAAD,CAAX;AACD;;AACD,QAAIE,KAAK,GAAGF,IAAI,CAACA,IAAI,CAACP,MAAL,GAAc,CAAf,CAAhB;;AACA,SAAK,IAAIY,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAGL,IAAI,CAACP,MAAL,GAAc,CAAlC,EAAqC,EAAEY,CAAvC,EAA0C;AACxCH,WAAK,IAAI,KAAKL,OAAL,CAAaQ,CAAb,IAAkBL,IAAI,CAACK,CAAD,CAA/B;AACD;;AACD,WAAOH,KAAP;AACD;;AAEDM,YAAU,CAACN,KAAD,EAAc;AACtB,QAAI,KAAKD,IAAL,KAAc,CAAlB,EAAqB;AACnB,aAAO,EAAP;AACD,KAFD,MAEO,IAAI,KAAKA,IAAL,KAAc,CAAlB,EAAqB;AAC1B,aAAO,CAACC,KAAD,CAAP;AACD;;AACD,UAAMF,IAAI,GAAa,IAAIS,KAAJ,CAAU,KAAKvB,KAAL,CAAWO,MAArB,CAAvB;;AACA,SAAK,IAAIY,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAGL,IAAI,CAACP,MAAL,GAAc,CAAlC,EAAqC,EAAEY,CAAvC,EAA0C;AACxCL,UAAI,CAACK,CAAD,CAAJ,GAAUK,IAAI,CAACC,KAAL,CAAWT,KAAK,GAAG,KAAKL,OAAL,CAAaQ,CAAb,CAAnB,CAAV;AACAH,WAAK,IAAIF,IAAI,CAACK,CAAD,CAAJ,GAAU,KAAKR,OAAL,CAAaQ,CAAb,CAAnB;AACD;;AACDL,QAAI,CAACA,IAAI,CAACP,MAAL,GAAc,CAAf,CAAJ,GAAwBS,KAAxB;AACA,WAAOF,IAAP;AACD;;AAEO,MAAJC,IAAI;AACN,WAAO,KAAKf,KAAL,CAAWO,MAAlB;AACD;AAED;;;;;;;AAKAmB,UAAQ;AACN,WAAOC,SAAS,GAAGC,UAAZ,CAAuB,KAAK1B,MAA5B,EAAoC,KAAKF,KAAzC,EAAgD,KAAKC,KAArD,CAAP;AAED;;AAnHsB,C,CA6JzB;;AACA,IAAI0B,SAAS,GAAwB,IAArC,C,CACA;;AACA,IAAIE,SAAS,GAAc,IAA3B,C,CACA;;AACA,IAAIC,oBAAoB,GAA0B,IAAlD,C,CACA;AACA;AACA;;AACA,CAACA,oBAAD;AAEA;;;;;;AAKA,OAAM,SAAUC,gBAAV,CAA2BC,EAA3B,EAAkD;AACtDL,WAAS,GAAGK,EAAZ;AACD;AAED;;;;;;AAKA,OAAM,SAAUC,YAAV,CAAuBC,OAAvB,EAAyC;AAC7CL,WAAS,GAAGK,OAAZ;AACD;AAED;;;;;AAIA,OAAM,SAAUC,uBAAV,CAAkCH,EAAlC,EAA2D;AAC/DF,sBAAoB,GAAGE,EAAvB;AACD;AAcD;;;;;;;;;;;;;;;AAcA,OAAM,MAAOI,MAAP,CAAa;AA6BjBrC,cAAYC,KAAZ,EAAgCC,KAAhC,EAAiDoC,MAAjD,EAAiEC,EAAjE,EAA2E;AAZ3E;AACA,gBAAO,KAAP;AAoKU,8BAAqB,KAArB;AAxJR,SAAKtC,KAAL,GAAaA,KAAK,CAACG,KAAN,EAAb;AACA,SAAKF,KAAL,GAAaA,KAAK,IAAI,SAAtB;AACA,SAAKG,IAAL,GAAYT,IAAI,CAACU,aAAL,CAAmBL,KAAnB,CAAZ;AACA,SAAKW,OAAL,GAAef,cAAc,CAACI,KAAD,CAA7B;AACA,SAAKqC,MAAL,GAAcA,MAAd;AACA,SAAKC,EAAL,GAAUA,EAAV;AACA,SAAKC,QAAL,GAAiB,KAAKxB,IAAL,GAAY,CAAZ,GAAgB,KAAKA,IAAL,CAAUyB,QAAV,EAAhB,GAAuC,QAAxD;AACD;;AAEO,MAAJzB,IAAI;AACN,WAAO,KAAKf,KAAL,CAAWO,MAAlB;AACD;AAED;;;;;;;AAKY,QAANkC,MAAM;AACV,UAAMC,IAAI,GAAG,MAAM,KAAKC,IAAL,EAAnB;AACA,WAAOd,SAAS,CAACY,MAAV,CAAiB,KAAKzC,KAAtB,EAA6B,KAAKC,KAAlC,EAA8CyC,IAA9C,CAAP;AACD;AAED;;;;;;AAIAE,YAAU;AACR,WAAOf,SAAS,CAACY,MAAV,CAAiB,KAAKzC,KAAtB,EAA6B,KAAKC,KAAlC,EAA8C,KAAK4C,QAAL,EAA9C,CAAP;AACD;AAED;;;;;;;;AAMW,QAALC,KAAK;AACT,UAAMJ,IAAI,GAAG,MAAM,KAAKC,IAAL,EAAnB;AACA,WAAO9C,aAAa,CAAC,KAAKG,KAAN,EAAa0C,IAAb,EAAmB,KAAKzC,KAAL,KAAe,WAAlC,CAApB;AAED;AAED;;;;;;;;AAMA8C,WAAS;AACP,WAAOlD,aAAa,CACT,KAAKG,KADI,EACG,KAAK6C,QAAL,EADH,EACoB,KAAK5C,KAAL,KAAe,WADnC,CAApB;AAGD;AAED;;;;;;;;AAMU,QAAJ0C,IAAI;AACR,SAAKK,eAAL;AACA,UAAML,IAAI,GAAGhB,SAAS,GAAGsB,IAAZ,CAAiB,KAAKZ,MAAtB,CAAb;;AACA,QAAI,KAAKpC,KAAL,KAAe,QAAnB,EAA6B;AAC3B,YAAMiD,KAAK,GAAG,MAAMP,IAApB;;AACA,UAAI;AACF,eAAOO,KAAK,CAACC,GAAN,CAAUC,CAAC,IAAIzD,IAAI,CAAC0D,YAAL,CAAkBD,CAAlB,CAAf,CAAP;AACD,OAFD,CAEE,WAAM;AACN,cAAM,IAAI3C,KAAJ,CACF,mDACA,iDAFE,CAAN;AAGD;AACF;;AACD,WAAOkC,IAAP;AACD;AAED;;;;;;;;;;;;;;;;;;;;;;;;;;AAwBAW,WAAS,CAACC,OAAD,EAA2B;AAClC,SAAKP,eAAL;AACA,WAAOrB,SAAS,GAAG6B,SAAZ,CAAsB,KAAKnB,MAA3B,EAAmCkB,OAAnC,CAAP;AACD;AAED;;;;;;;;AAMAV,UAAQ;AACN,SAAKG,eAAL;AACA,UAAML,IAAI,GAAGhB,SAAS,GAAG8B,QAAZ,CAAqB,KAAKpB,MAA1B,CAAb;;AACA,QAAI,KAAKpC,KAAL,KAAe,QAAnB,EAA6B;AAC3B,UAAI;AACF,eAAQ0C,IAAqB,CAACQ,GAAtB,CAA0BC,CAAC,IAAIzD,IAAI,CAAC0D,YAAL,CAAkBD,CAAlB,CAA/B,CAAR;AAED,OAHD,CAGE,WAAM;AACN,cAAM,IAAI3C,KAAJ,CACF,mDACA,iDAFE,CAAN;AAGD;AACF;;AACD,WAAOkC,IAAP;AACD;AAED;;;AACW,QAALO,KAAK;AACT,SAAKF,eAAL;AACA,UAAML,IAAI,GAAG,MAAMhB,SAAS,GAAGsB,IAAZ,CAAiB,KAAKZ,MAAtB,CAAnB;;AACA,QAAI,KAAKpC,KAAL,KAAe,QAAnB,EAA6B;AAC3B,aAAO0C,IAAP;AACD,KAFD,MAEO;AACL,aAAO,IAAIe,UAAJ,CAAgBf,IAAmB,CAACF,MAApC,CAAP;AACD;AACF;AAED;;;;;;;AAKAkB,SAAO;AACL,QAAI,KAAKC,UAAT,EAAqB;AACnB;AACD;;AACDjC,aAAS,GAAGkC,aAAZ,CAA0B,IAA1B;AACA,SAAKC,kBAAL,GAA0B,IAA1B;AACD;;AAGa,MAAVF,UAAU;AACZ,WAAO,KAAKE,kBAAZ;AACD;;AAEDd,iBAAe;AACb,QAAI,KAAKY,UAAT,EAAqB;AACnB,YAAM,IAAInD,KAAJ,CAAU,qBAAV,CAAN;AACD;AACF;AAED;;;;;;;;;;AAQAsD,OAAK,GAAgB;AAAA,QAAfC,OAAe,uEAAL,KAAK;AACnB,WAAOnC,SAAS,CAACkC,KAAV,CAAgB,IAAhB,EAAsBC,OAAtB,CAAP;AACD;AAED;;;;;;AAIAC,OAAK;AACH,SAAKjB,eAAL;AACA,WAAOnB,SAAS,CAACoC,KAAV,CAAgB,IAAhB,CAAP;AACD;AAED;;;;;;;AAKAzB,UAAQ,GAAgB;AAAA,QAAfwB,OAAe,uEAAL,KAAK;AACtB,UAAMtB,IAAI,GAAG,KAAKG,QAAL,EAAb;AACA,WAAOnD,cAAc,CAACgD,IAAD,EAAO,KAAK1C,KAAZ,EAAmB,KAAKC,KAAxB,EAA+B+D,OAA/B,CAArB;AACD;;AAEDE,MAAI,CAAiBjE,KAAjB,EAAgC;AAClC,SAAK+C,eAAL;AACA,WAAOnB,SAAS,CAACqC,IAAV,CAAe,IAAf,EAA0BjE,KAA1B,CAAP;AACD;;AACDkE,UAAQ,GAAkD;AAAA,QAAjDC,SAAiD,uEAArC,IAAqC;AAAA,QAA/BC,IAA+B;AAAA,QAAhBpE,KAAgB;AACxD,SAAK+C,eAAL;AACA,WAAOrB,SAAS,GAAG2C,YAAZ,CAAyB,IAAzB,EAA+BF,SAA/B,EAA0CC,IAA1C,EAAgDpE,KAAhD,CAAP;AAED;;AAxOgB;AA2OnBsE,MAAM,CAACC,cAAP,CAAsBpC,MAAtB,EAA8BqC,MAAM,CAACC,WAArC,EAAkD;AAChD7D,OAAK,EAAG8D,QAAD,IAAqB;AAC1B;AACA;AACA;AACA;AACA;AACA,WAAO,CAAC,CAACA,QAAF,IAAcA,QAAQ,CAAChC,IAAT,IAAiB,IAA/B,IAAuCgC,QAAQ,CAAC9B,QAAT,IAAqB,IAA5D,IACH8B,QAAQ,CAAC3B,eAAT,IAA4B,IADhC;AAED;AAT+C,CAAlD;AAYA,OAAM,SAAU4B,oBAAV,GAA8B;AAClC;AACA;AACA;AACA,SAAOnF,SAAS,CAAC,QAAD,EAAW,MAAK;AAC9B,WAAO2C,MAAP;AACD,GAFe,CAAhB;AAGD,C,CAED;;AACAwC,oBAAoB;AA8BpB;;;;;;AAKA,OAAM,MAAOC,QAAP,SAA+CzC,MAA/C,CAAwD;AAG5DrC,cACI+E,YADJ,EACoCV,SADpC,EACwDC,IADxD,EAEIU,QAFJ,EAEoB;AAClB,UACID,YAAY,CAAC9E,KADjB,EACwB8E,YAAY,CAAC7E,KADrC,EAC4C6E,YAAY,CAACzC,MADzD,EACiE0C,QADjE;AAFkC;AAIlC,SAAKV,IAAL,GAAYA,IAAZ;AACD;AAED;;;;;;;;;;AAQAW,QAAM,CAACC,QAAD,EAAoB;AACxB,QAAIA,QAAQ,CAAChF,KAAT,KAAmB,KAAKA,KAA5B,EAAmC;AACjC,YAAM,IAAIQ,KAAJ,CACF,2BAA2BwE,QAAQ,CAAChF,KAAK,QAAzC,GACA,mBAAmB,KAAKA,KAAK,cAF3B,CAAN;AAGD;;AACD,QAAI,CAACN,IAAI,CAACuF,WAAL,CAAiBD,QAAQ,CAACjF,KAA1B,EAAiC,KAAKA,KAAtC,CAAL,EAAmD;AACjD,YAAM,IAAIS,KAAJ,CACF,2BAA2BwE,QAAQ,CAACjF,KAAK,QAAzC,GACA,mBAAmB,KAAKA,KAAK,cAF3B,CAAN;AAGD;;AACD2B,aAAS,GAAGkC,aAAZ,CAA0B,IAA1B;AACA,SAAKxB,MAAL,GAAc4C,QAAQ,CAAC5C,MAAvB;AACAV,aAAS,GAAGwD,MAAZ,CAAmB,IAAnB,EAAyB;AAAK;AAA9B;AACD;;AAEDxB,SAAO;AACLhC,aAAS,GAAGyD,eAAZ,CAA4B,IAA5B;AACA,SAAKtB,kBAAL,GAA0B,IAA1B;AACD;;AAtC2D;AAyC9DS,MAAM,CAACC,cAAP,CAAsBK,QAAtB,EAAgCJ,MAAM,CAACC,WAAvC,EAAoD;AAClD7D,OAAK,EAAG8D,QAAD,IAAuB;AAC5B,WAAOA,QAAQ,YAAYvC,MAApB,IAA8BuC,QAAQ,CAACK,MAAT,IAAmB,IAAjD,IACHL,QAAQ,CAACK,MAAT,YAA2BK,QAD/B;AAED;AAJiD,CAApD","names":["getGlobal","tensorToString","util","computeStrides","toNestedArray","TensorBuffer","constructor","shape","dtype","values","slice","size","sizeFromShape","n","length","assert","Error","getArrayFromDType","strides","set","value","locs","rank","index","locToIndex","get","i","loc","msg","indexToLoc","Array","Math","floor","toTensor","trackerFn","makeTensor","opHandler","deprecationWarningFn","setTensorTracker","fn","setOpHandler","handler","setDeprecationWarningFn","Tensor","dataId","id","rankType","toString","buffer","vals","data","bufferSync","dataSync","array","arraySync","throwIfDisposed","read","bytes","map","b","decodeString","dataToGPU","options","readToGPU","readSync","Uint8Array","dispose","isDisposed","disposeTensor","isDisposedInternal","print","verbose","clone","cast","variable","trainable","name","makeVariable","Object","defineProperty","Symbol","hasInstance","instance","getGlobalTensorClass","Variable","initialValue","tensorId","assign","newValue","arraysEqual","incRef","disposeVariable","Function"],"sources":["/home/nadimakhtar97/smart-attendance-system/tfjs-core/src/tensor.ts"],"sourcesContent":["/**\n * @license\n * Copyright 2017 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {getGlobal} from './global_util';\nimport {tensorToString} from './tensor_format';\nimport {ArrayMap, BackendValues, DataType, DataTypeMap, DataValues, NumericDataType, Rank, ShapeMap, SingleValueMap, TypedArray} from './types';\nimport * as util from './util';\nimport {computeStrides, toNestedArray} from './util';\n\nexport interface TensorData<D extends DataType> {\n  dataId?: DataId;\n  values?: DataTypeMap[D];\n}\n\n// This interface mimics KernelBackend (in backend.ts), which would create a\n// circular dependency if imported.\nexport interface Backend {}\n\n/**\n * A mutable object, similar to `tf.Tensor`, that allows users to set values\n * at locations before converting to an immutable `tf.Tensor`.\n *\n * See `tf.buffer` for creating a tensor buffer.\n *\n * @doc {heading: 'Tensors', subheading: 'Classes'}\n */\nexport class TensorBuffer<R extends Rank, D extends DataType = 'float32'> {\n  size: number;\n  shape: ShapeMap[R];\n  strides: number[];\n  values: DataTypeMap[D];\n\n  constructor(shape: ShapeMap[R], public dtype: D, values?: DataTypeMap[D]) {\n    this.shape = shape.slice() as ShapeMap[R];\n    this.size = util.sizeFromShape(shape);\n\n    if (values != null) {\n      const n = values.length;\n      util.assert(\n          n === this.size,\n          () => `Length of values '${n}' does not match the size ` +\n              `inferred by the shape '${this.size}'.`);\n    }\n    if (dtype === 'complex64') {\n      throw new Error(\n          `complex64 dtype TensorBuffers are not supported. Please create ` +\n          `a TensorBuffer for the real and imaginary parts separately and ` +\n          `call tf.complex(real, imag).`);\n    }\n    this.values = values || util.getArrayFromDType(dtype, this.size);\n    this.strides = computeStrides(shape);\n  }\n\n  /**\n   * Sets a value in the buffer at a given location.\n   *\n   * @param value The value to set.\n   * @param locs  The location indices.\n   *\n   * @doc {heading: 'Tensors', subheading: 'Creation'}\n   */\n  set(value: SingleValueMap[D], ...locs: number[]): void {\n    if (locs.length === 0) {\n      locs = [0];\n    }\n    util.assert(\n        locs.length === this.rank,\n        () => `The number of provided coordinates (${locs.length}) must ` +\n            `match the rank (${this.rank})`);\n\n    const index = this.locToIndex(locs);\n    this.values[index] = value as number;\n  }\n\n  /**\n   * Returns the value in the buffer at the provided location.\n   *\n   * @param locs The location indices.\n   *\n   * @doc {heading: 'Tensors', subheading: 'Creation'}\n   */\n  get(...locs: number[]): SingleValueMap[D] {\n    if (locs.length === 0) {\n      locs = [0];\n    }\n    let i = 0;\n    for (const loc of locs) {\n      if (loc < 0 || loc >= this.shape[i]) {\n        const msg = `Requested out of range element at ${locs}. ` +\n            `  Buffer shape=${this.shape}`;\n        throw new Error(msg);\n      }\n      i++;\n    }\n    let index = locs[locs.length - 1];\n    for (let i = 0; i < locs.length - 1; ++i) {\n      index += this.strides[i] * locs[i];\n    }\n    return this.values[index] as SingleValueMap[D];\n  }\n\n  locToIndex(locs: number[]): number {\n    if (this.rank === 0) {\n      return 0;\n    } else if (this.rank === 1) {\n      return locs[0];\n    }\n    let index = locs[locs.length - 1];\n    for (let i = 0; i < locs.length - 1; ++i) {\n      index += this.strides[i] * locs[i];\n    }\n    return index;\n  }\n\n  indexToLoc(index: number): number[] {\n    if (this.rank === 0) {\n      return [];\n    } else if (this.rank === 1) {\n      return [index];\n    }\n    const locs: number[] = new Array(this.shape.length);\n    for (let i = 0; i < locs.length - 1; ++i) {\n      locs[i] = Math.floor(index / this.strides[i]);\n      index -= locs[i] * this.strides[i];\n    }\n    locs[locs.length - 1] = index;\n    return locs;\n  }\n\n  get rank() {\n    return this.shape.length;\n  }\n\n  /**\n   * Creates an immutable `tf.Tensor` object from the buffer.\n   *\n   * @doc {heading: 'Tensors', subheading: 'Creation'}\n   */\n  toTensor(): Tensor<R> {\n    return trackerFn().makeTensor(this.values, this.shape, this.dtype) as\n        Tensor<R>;\n  }\n}\n\nexport interface DataToGPUWebGLOption {\n  customTexShape?: [number, number];\n}\n\nexport type DataToGPUOptions = DataToGPUWebGLOption;\n\nexport interface GPUData {\n  tensorRef: Tensor;\n  texture?: WebGLTexture;\n  texShape?: [number, number];\n}\nexport interface TensorTracker {\n  makeTensor(\n      values: DataValues, shape: number[], dtype: DataType,\n      backend?: Backend): Tensor;\n  makeVariable(\n      initialValue: Tensor, trainable?: boolean, name?: string,\n      dtype?: DataType): Variable;\n  incRef(a: Tensor, backend: Backend): void;\n  disposeTensor(t: Tensor): void;\n  disposeVariable(v: Variable): void;\n  read(dataId: DataId): Promise<BackendValues>;\n  readSync(dataId: DataId): BackendValues;\n  readToGPU(dataId: DataId, options?: DataToGPUOptions): GPUData;\n}\n\n/**\n * The Tensor class calls into this handler to delegate chaining operations.\n */\nexport interface OpHandler {\n  cast<T extends Tensor>(x: T, dtype: DataType): T;\n  buffer<R extends Rank, D extends DataType>(\n      shape: ShapeMap[R], dtype: D,\n      values?: DataTypeMap[D]): TensorBuffer<R, D>;\n  print<T extends Tensor>(x: T, verbose: boolean): void;\n  clone<T extends Tensor>(x: T): T;\n  // TODO(yassogba) bring reshape back?\n}\n\n// For tracking tensor creation and disposal.\nlet trackerFn: () => TensorTracker = null;\n// Used by chaining methods to call into ops.\nlet opHandler: OpHandler = null;\n// Used to warn about deprecated methods.\nlet deprecationWarningFn: (msg: string) => void = null;\n// This here so that we can use this method on dev branches and keep the\n// functionality at master.\n// tslint:disable-next-line:no-unused-expression\n[deprecationWarningFn];\n\n/**\n * An external consumer can register itself as the tensor tracker. This way\n * the Tensor class can notify the tracker for every tensor created and\n * disposed.\n */\nexport function setTensorTracker(fn: () => TensorTracker) {\n  trackerFn = fn;\n}\n\n/**\n * An external consumer can register itself as the op handler. This way the\n * Tensor class can have chaining methods that call into ops via the op\n * handler.\n */\nexport function setOpHandler(handler: OpHandler) {\n  opHandler = handler;\n}\n\n/**\n * Sets the deprecation warning function to be used by this file. This way the\n * Tensor class can be a leaf but still use the environment.\n */\nexport function setDeprecationWarningFn(fn: (msg: string) => void) {\n  deprecationWarningFn = fn;\n}\n\n/**\n * We wrap data id since we use weak map to avoid memory leaks.\n * Since we have our own memory management, we have a reference counter\n * mapping a tensor to its data, so there is always a pointer (even if that\n * data is otherwise garbage collectable).\n * See https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/\n * Global_Objects/WeakMap\n */\nexport type DataId = object;  // object instead of {} to force non-primitive.\n\n// Declare this namespace to make Tensor class augmentation work in google3.\nexport declare namespace Tensor {}\n/**\n * A `tf.Tensor` object represents an immutable, multidimensional array of\n * numbers that has a shape and a data type.\n *\n * For performance reasons, functions that create tensors do not necessarily\n * perform a copy of the data passed to them (e.g. if the data is passed as a\n * `Float32Array`), and changes to the data will change the tensor. This is not\n * a feature and is not supported. To avoid this behavior, use the tensor before\n * changing the input data or create a copy with `copy = tf.add(yourTensor, 0)`.\n *\n * See `tf.tensor` for details on how to create a `tf.Tensor`.\n *\n * @doc {heading: 'Tensors', subheading: 'Classes'}\n */\nexport class Tensor<R extends Rank = Rank> {\n  /** Unique id of this tensor. */\n  readonly id: number;\n  /**\n   * Id of the bucket holding the data for this tensor. Multiple arrays can\n   * point to the same bucket (e.g. when calling array.reshape()).\n   */\n  dataId: DataId;\n  /** The shape of the tensor. */\n  readonly shape: ShapeMap[R];\n  /** Number of elements in the tensor. */\n  readonly size: number;\n  /** The data type for the array. */\n  readonly dtype: DataType;\n  /** The rank type for the array (see `Rank` enum). */\n  readonly rankType: R;\n\n  /** Whether this tensor has been globally kept. */\n  kept = false;\n  /** The id of the scope this tensor is being tracked in. */\n  scopeId: number;\n\n  /**\n   * Number of elements to skip in each dimension when indexing. See\n   * https://docs.scipy.org/doc/numpy/reference/generated/\\\n   * numpy.ndarray.strides.html\n   */\n  readonly strides: number[];\n\n  constructor(shape: ShapeMap[R], dtype: DataType, dataId: DataId, id: number) {\n    this.shape = shape.slice() as ShapeMap[R];\n    this.dtype = dtype || 'float32';\n    this.size = util.sizeFromShape(shape);\n    this.strides = computeStrides(shape);\n    this.dataId = dataId;\n    this.id = id;\n    this.rankType = (this.rank < 5 ? this.rank.toString() : 'higher') as R;\n  }\n\n  get rank(): number {\n    return this.shape.length;\n  }\n\n  /**\n   * Returns a promise of `tf.TensorBuffer` that holds the underlying data.\n   *\n   * @doc {heading: 'Tensors', subheading: 'Classes'}\n   */\n  async buffer<D extends DataType = 'float32'>(): Promise<TensorBuffer<R, D>> {\n    const vals = await this.data<D>();\n    return opHandler.buffer(this.shape, this.dtype as D, vals);\n  }\n\n  /**\n   * Returns a `tf.TensorBuffer` that holds the underlying data.\n   * @doc {heading: 'Tensors', subheading: 'Classes'}\n   */\n  bufferSync<D extends DataType = 'float32'>(): TensorBuffer<R, D> {\n    return opHandler.buffer(this.shape, this.dtype as D, this.dataSync());\n  }\n\n  /**\n   * Returns the tensor data as a nested array. The transfer of data is done\n   * asynchronously.\n   *\n   * @doc {heading: 'Tensors', subheading: 'Classes'}\n   */\n  async array(): Promise<ArrayMap[R]> {\n    const vals = await this.data();\n    return toNestedArray(this.shape, vals, this.dtype === 'complex64') as\n        ArrayMap[R];\n  }\n\n  /**\n   * Returns the tensor data as a nested array. The transfer of data is done\n   * synchronously.\n   *\n   * @doc {heading: 'Tensors', subheading: 'Classes'}\n   */\n  arraySync(): ArrayMap[R] {\n    return toNestedArray(\n               this.shape, this.dataSync(), this.dtype === 'complex64') as\n        ArrayMap[R];\n  }\n\n  /**\n   * Asynchronously downloads the values from the `tf.Tensor`. Returns a\n   * promise of `TypedArray` that resolves when the computation has finished.\n   *\n   * @doc {heading: 'Tensors', subheading: 'Classes'}\n   */\n  async data<D extends DataType = NumericDataType>(): Promise<DataTypeMap[D]> {\n    this.throwIfDisposed();\n    const data = trackerFn().read(this.dataId);\n    if (this.dtype === 'string') {\n      const bytes = await data as Uint8Array[];\n      try {\n        return bytes.map(b => util.decodeString(b)) as DataTypeMap[D];\n      } catch {\n        throw new Error(\n            'Failed to decode the string bytes into utf-8. ' +\n            'To get the original bytes, call tensor.bytes().');\n      }\n    }\n    return data as Promise<DataTypeMap[D]>;\n  }\n\n  /**\n   * Copy the tensor's data to a new GPU resource. Comparing to the `dataSync()`\n   * and `data()`, this method prevents data from being downloaded to CPU.\n   *\n   * For WebGL backend, the data will be stored on a densely packed texture.\n   * This means that the texture will use the RGBA channels to store value.\n   *\n   * @param options:\n   *     For WebGL,\n   *         - customTexShape: Optional. If set, will use the user defined\n   *     texture shape to create the texture.\n   *\n   * @returns For WebGL backend, a GPUData contains the new texture and\n   *     its information.\n   *     {\n   *        tensorRef: The tensor that is associated with this texture,\n   *        texture: WebGLTexture,\n   *        texShape: [number, number] // [height, width]\n   *     }\n   *     Remember to dispose the GPUData after it is used by\n   *     `res.tensorRef.dispose()`.\n   *\n   * @doc {heading: 'Tensors', subheading: 'Classes'}\n   */\n  dataToGPU(options?: DataToGPUOptions): GPUData {\n    this.throwIfDisposed();\n    return trackerFn().readToGPU(this.dataId, options);\n  }\n\n  /**\n   * Synchronously downloads the values from the `tf.Tensor`. This blocks the\n   * UI thread until the values are ready, which can cause performance issues.\n   *\n   * @doc {heading: 'Tensors', subheading: 'Classes'}\n   */\n  dataSync<D extends DataType = NumericDataType>(): DataTypeMap[D] {\n    this.throwIfDisposed();\n    const data = trackerFn().readSync(this.dataId);\n    if (this.dtype === 'string') {\n      try {\n        return (data as Uint8Array[]).map(b => util.decodeString(b)) as\n            DataTypeMap[D];\n      } catch {\n        throw new Error(\n            'Failed to decode the string bytes into utf-8. ' +\n            'To get the original bytes, call tensor.bytes().');\n      }\n    }\n    return data as DataTypeMap[D];\n  }\n\n  /** Returns the underlying bytes of the tensor's data. */\n  async bytes(): Promise<Uint8Array[]|Uint8Array> {\n    this.throwIfDisposed();\n    const data = await trackerFn().read(this.dataId);\n    if (this.dtype === 'string') {\n      return data as Uint8Array[];\n    } else {\n      return new Uint8Array((data as TypedArray).buffer);\n    }\n  }\n\n  /**\n   * Disposes `tf.Tensor` from memory.\n   *\n   * @doc {heading: 'Tensors', subheading: 'Classes'}\n   */\n  dispose(): void {\n    if (this.isDisposed) {\n      return;\n    }\n    trackerFn().disposeTensor(this);\n    this.isDisposedInternal = true;\n  }\n\n  protected isDisposedInternal = false;\n  get isDisposed(): boolean {\n    return this.isDisposedInternal;\n  }\n\n  throwIfDisposed() {\n    if (this.isDisposed) {\n      throw new Error(`Tensor is disposed.`);\n    }\n  }\n\n  /**\n   * Prints the `tf.Tensor`. See `tf.print` for details.\n   *\n   * @param verbose Whether to print verbose information about the tensor,\n   *    including dtype and size.\n   *\n   * @doc {heading: 'Tensors', subheading: 'Classes'}\n   */\n  print(verbose = false): void {\n    return opHandler.print(this, verbose);\n  }\n\n  /**\n   * Returns a copy of the tensor. See `tf.clone` for details.\n   * @doc {heading: 'Tensors', subheading: 'Classes'}\n   */\n  clone<T extends Tensor>(this: T): T {\n    this.throwIfDisposed();\n    return opHandler.clone(this);\n  }\n\n  /**\n   * Returns a human-readable description of the tensor. Useful for logging.\n   *\n   * @doc {heading: 'Tensors', subheading: 'Classes'}\n   */\n  toString(verbose = false): string {\n    const vals = this.dataSync();\n    return tensorToString(vals, this.shape, this.dtype, verbose);\n  }\n\n  cast<T extends this>(dtype: DataType): T {\n    this.throwIfDisposed();\n    return opHandler.cast(this as T, dtype);\n  }\n  variable(trainable = true, name?: string, dtype?: DataType): Variable<R> {\n    this.throwIfDisposed();\n    return trackerFn().makeVariable(this, trainable, name, dtype) as\n        Variable<R>;\n  }\n}\n\nObject.defineProperty(Tensor, Symbol.hasInstance, {\n  value: (instance: Tensor) => {\n    // Implementation note: we should use properties of the object that will be\n    // defined before the constructor body has finished executing (methods).\n    // This is because when this code is transpiled by babel, babel will call\n    // classCallCheck before the constructor body is run.\n    // See https://github.com/tensorflow/tfjs/issues/3384 for backstory.\n    return !!instance && instance.data != null && instance.dataSync != null &&\n        instance.throwIfDisposed != null;\n  }\n});\n\nexport function getGlobalTensorClass() {\n  // Use getGlobal so that we can augment the Tensor class across package\n  // boundaries becase the node resolution alg may result in different modules\n  // being returned for this file depending on the path they are loaded from.\n  return getGlobal('Tensor', () => {\n    return Tensor;\n  });\n}\n\n// Global side effect. Cache global reference to Tensor class\ngetGlobalTensorClass();\n\nexport interface NumericTensor<R extends Rank = Rank> extends Tensor<R> {\n  dtype: NumericDataType;\n  dataSync<D extends DataType = NumericDataType>(): DataTypeMap[D];\n  data<D extends DataType = NumericDataType>(): Promise<DataTypeMap[D]>;\n  dataToGPU(options?: DataToGPUOptions): GPUData;\n}\n\nexport interface StringTensor<R extends Rank = Rank> extends Tensor<R> {\n  dtype: 'string';\n  dataSync<D extends DataType = 'string'>(): DataTypeMap[D];\n  data<D extends DataType = 'string'>(): Promise<DataTypeMap[D]>;\n}\n\n/** @doclink Tensor */\nexport type Scalar = Tensor<Rank.R0>;\n/** @doclink Tensor */\nexport type Tensor1D = Tensor<Rank.R1>;\n/** @doclink Tensor */\nexport type Tensor2D = Tensor<Rank.R2>;\n/** @doclink Tensor */\nexport type Tensor3D = Tensor<Rank.R3>;\n/** @doclink Tensor */\nexport type Tensor4D = Tensor<Rank.R4>;\n/** @doclink Tensor */\nexport type Tensor5D = Tensor<Rank.R5>;\n/** @doclink Tensor */\nexport type Tensor6D = Tensor<Rank.R6>;\n\n/**\n * A mutable `tf.Tensor`, useful for persisting state, e.g. for training.\n *\n * @doc {heading: 'Tensors', subheading: 'Classes'}\n */\nexport class Variable<R extends Rank = Rank> extends Tensor<R> {\n  name: string;\n\n  constructor(\n      initialValue: Tensor<R>, public trainable: boolean, name: string,\n      tensorId: number) {\n    super(\n        initialValue.shape, initialValue.dtype, initialValue.dataId, tensorId);\n    this.name = name;\n  }\n\n  /**\n   * Assign a new `tf.Tensor` to this variable. The new `tf.Tensor` must have\n   * the same shape and dtype as the old `tf.Tensor`.\n   *\n   * @param newValue New tensor to be assigned to this variable.\n   *\n   * @doc {heading: 'Tensors', subheading: 'Classes'}\n   */\n  assign(newValue: Tensor<R>): void {\n    if (newValue.dtype !== this.dtype) {\n      throw new Error(\n          `dtype of the new value (${newValue.dtype}) and ` +\n          `previous value (${this.dtype}) must match`);\n    }\n    if (!util.arraysEqual(newValue.shape, this.shape)) {\n      throw new Error(\n          `shape of the new value (${newValue.shape}) and ` +\n          `previous value (${this.shape}) must match`);\n    }\n    trackerFn().disposeTensor(this);\n    this.dataId = newValue.dataId;\n    trackerFn().incRef(this, null /* backend */);\n  }\n\n  dispose(): void {\n    trackerFn().disposeVariable(this);\n    this.isDisposedInternal = true;\n  }\n}\n\nObject.defineProperty(Variable, Symbol.hasInstance, {\n  value: (instance: Variable) => {\n    return instance instanceof Tensor && instance.assign != null &&\n        instance.assign instanceof Function;\n  }\n});\n"]},"metadata":{},"sourceType":"module"}