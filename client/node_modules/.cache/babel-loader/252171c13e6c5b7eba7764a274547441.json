{"ast":null,"code":"/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { env } from '../environment';\nimport * as util from '../util';\nimport { decodeWeights } from './io_utils';\nimport { monitorPromisesProgress } from './progress';\nimport { DTYPE_VALUE_SIZE_MAP } from './types';\n/**\n * Reads binary weights data from a number of URLs.\n *\n * @param fetchURLs URLs to send the HTTP requests at, using `fetch` calls.\n * @param requestOptions RequestInit (options) for the HTTP requests.\n * @param fetchFunc Optional overriding value for the `window.fetch` function.\n * @param onProgress Optional, progress callback function, fired periodically\n *   before the load is completed.\n * @returns A `Promise` of an Array of `ArrayBuffer`. The Array has the same\n *   length as `fetchURLs`.\n */\n\nexport async function loadWeightsAsArrayBuffer(fetchURLs, loadOptions) {\n  if (loadOptions == null) {\n    loadOptions = {};\n  }\n\n  const fetchFunc = loadOptions.fetchFunc == null ? env().platform.fetch : loadOptions.fetchFunc; // Create the requests for all of the weights in parallel.\n\n  const requests = fetchURLs.map(fetchURL => fetchFunc(fetchURL, loadOptions.requestInit, {\n    isBinary: true\n  }));\n  const fetchStartFraction = 0;\n  const fetchEndFraction = 0.5;\n  const responses = loadOptions.onProgress == null ? await Promise.all(requests) : await monitorPromisesProgress(requests, loadOptions.onProgress, fetchStartFraction, fetchEndFraction);\n  const bufferPromises = responses.map(response => response.arrayBuffer());\n  const bufferStartFraction = 0.5;\n  const bufferEndFraction = 1;\n  const buffers = loadOptions.onProgress == null ? await Promise.all(bufferPromises) : await monitorPromisesProgress(bufferPromises, loadOptions.onProgress, bufferStartFraction, bufferEndFraction);\n  return buffers;\n}\n/**\n * Reads a weights manifest JSON configuration, fetches the weights and\n * returns them as `Tensor`s.\n *\n * @param manifest The weights manifest JSON.\n * @param filePathPrefix The path prefix for filenames given in the manifest.\n *     Defaults to the empty string.\n * @param weightNames The names of the weights to be fetched.\n */\n\nexport async function loadWeights(manifest) {\n  let filePathPrefix = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : '';\n  let weightNames = arguments.length > 2 ? arguments[2] : undefined;\n  let requestInit = arguments.length > 3 ? arguments[3] : undefined;\n\n  // TODO(nsthorat): Groups are currently fetched atomically. If you need a\n  // single weight from a group, the whole group will be fetched. At a future\n  // date, we should support fetching only the individual shards within a\n  // group that are needed to reconstruct the requested weight.\n  // TODO(cais): Use `decodeWeights` for implementation.\n  const fetchWeights = fetchUrls => loadWeightsAsArrayBuffer(fetchUrls, {\n    requestInit\n  });\n\n  const loadWeights = weightsLoaderFactory(fetchWeights);\n  return loadWeights(manifest, filePathPrefix, weightNames);\n}\n/**\n * Creates a function, which reads a weights manifest JSON configuration,\n * fetches the weight files using the specified function and returns them as\n * `Tensor`s.\n *\n * ```js\n * // example for creating a nodejs weight loader, which reads the weight files\n * // from disk using fs.readFileSync\n *\n * import * as fs from 'fs'\n *\n * const fetchWeightsFromDisk = (filePaths: string[]) =>\n *   filePaths.map(filePath => fs.readFileSync(filePath).buffer)\n *\n * const loadWeights = tf.io.weightsLoaderFactory(fetchWeightsFromDisk)\n *\n * const manifest = JSON.parse(\n *   fs.readFileSync('./my_model-weights_manifest').toString()\n * )\n * const weightMap = await loadWeights(manifest, './')\n * ```\n * @param fetchWeightsFunction The function used for fetching the weight files.\n * @returns Weight loading function.\n */\n\nexport function weightsLoaderFactory(fetchWeightsFunction) {\n  return async function (manifest) {\n    let filePathPrefix = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : '';\n    let weightNames = arguments.length > 2 ? arguments[2] : undefined;\n    // Collect all the groups, weights, and their relative offsets to be\n    // fetched.\n    const groupIndicesToFetchMap = manifest.map(() => false);\n    const groupWeightsToFetch = {};\n    const weightsFound = weightNames != null ? weightNames.map(() => false) : [];\n    const allManifestWeightNames = [];\n    manifest.forEach((manifestGroupConfig, groupIndex) => {\n      let groupOffset = 0;\n      manifestGroupConfig.weights.forEach(weightsEntry => {\n        const rawDtype = 'quantization' in weightsEntry ? weightsEntry.quantization.dtype : weightsEntry.dtype;\n        const weightsBytes = DTYPE_VALUE_SIZE_MAP[rawDtype] * util.sizeFromShape(weightsEntry.shape);\n\n        const enqueueWeightsForFetchingFn = () => {\n          groupIndicesToFetchMap[groupIndex] = true;\n\n          if (groupWeightsToFetch[groupIndex] == null) {\n            groupWeightsToFetch[groupIndex] = [];\n          }\n\n          groupWeightsToFetch[groupIndex].push({\n            manifestEntry: weightsEntry,\n            groupOffset,\n            sizeBytes: weightsBytes\n          });\n        };\n\n        if (weightNames != null) {\n          weightNames.forEach((weightName, weightIndex) => {\n            if (weightName === weightsEntry.name) {\n              enqueueWeightsForFetchingFn();\n              weightsFound[weightIndex] = true;\n            }\n          });\n        } else {\n          enqueueWeightsForFetchingFn();\n        }\n\n        allManifestWeightNames.push(weightsEntry.name);\n        groupOffset += weightsBytes;\n      });\n    });\n\n    if (!weightsFound.every(found => found)) {\n      const weightsNotFound = weightNames.filter((_, i) => !weightsFound[i]);\n      throw new Error(`Could not find weights in manifest with names: ` + `${weightsNotFound.join(', ')}. \\n` + `Manifest JSON has weights with names: ` + `${allManifestWeightNames.join(', ')}.`);\n    } // Convert the one-hot boolean groupId => shouldFetch map to a list of group\n    // IDs.\n\n\n    const groupIndicesToFetch = groupIndicesToFetchMap.reduce((accumulator, shouldFetch, i) => {\n      if (shouldFetch) {\n        accumulator.push(i);\n      }\n\n      return accumulator;\n    }, []);\n    const fetchUrls = [];\n    groupIndicesToFetch.forEach(i => {\n      manifest[i].paths.forEach(filepath => {\n        const fetchUrl = filePathPrefix + (!filePathPrefix.endsWith('/') ? '/' : '') + filepath;\n        fetchUrls.push(fetchUrl);\n      });\n    });\n    const buffers = await fetchWeightsFunction(fetchUrls);\n    const weightsTensorMap = {};\n    let bufferIndexOffset = 0;\n    groupIndicesToFetch.forEach(i => {\n      const numBuffers = manifest[i].paths.length;\n      let groupBytes = 0;\n\n      for (let i = 0; i < numBuffers; i++) {\n        groupBytes += buffers[bufferIndexOffset + i].byteLength;\n      } // Create a buffer for the whole group.\n\n\n      const groupBuffer = new ArrayBuffer(groupBytes);\n      const groupByteBuffer = new Uint8Array(groupBuffer);\n      let groupBufferOffset = 0;\n\n      for (let i = 0; i < numBuffers; i++) {\n        const buffer = new Uint8Array(buffers[bufferIndexOffset + i]);\n        groupByteBuffer.set(buffer, groupBufferOffset);\n        groupBufferOffset += buffer.byteLength;\n      }\n\n      const weightsEntries = groupWeightsToFetch[i];\n      weightsEntries.forEach(weightsEntry => {\n        const byteBuffer = groupBuffer.slice(weightsEntry.groupOffset, weightsEntry.groupOffset + weightsEntry.sizeBytes);\n        const nameToTensorMap = decodeWeights(byteBuffer, [weightsEntry.manifestEntry]);\n\n        for (const name in nameToTensorMap) {\n          weightsTensorMap[name] = nameToTensorMap[name];\n        }\n      });\n      bufferIndexOffset += numBuffers;\n    });\n    return weightsTensorMap;\n  };\n}","map":{"version":3,"mappings":"AAAA;;;;;;;;;;;;;;;;AAiBA,SAAQA,GAAR,QAAkB,gBAAlB;AAGA,OAAO,KAAKC,IAAZ,MAAsB,SAAtB;AACA,SAAQC,aAAR,QAA4B,YAA5B;AACA,SAAQC,uBAAR,QAAsC,YAAtC;AACA,SAAQC,oBAAR,QAA6F,SAA7F;AAEA;;;;;;;;;;;;AAWA,OAAO,eAAeC,wBAAf,CACHC,SADG,EACkBC,WADlB,EAC2C;AAChD,MAAIA,WAAW,IAAI,IAAnB,EAAyB;AACvBA,eAAW,GAAG,EAAd;AACD;;AAED,QAAMC,SAAS,GAAGD,WAAW,CAACC,SAAZ,IAAyB,IAAzB,GAAgCR,GAAG,GAAGS,QAAN,CAAeC,KAA/C,GACgCH,WAAW,CAACC,SAD9D,CALgD,CAQhD;;AACA,QAAMG,QAAQ,GAAGL,SAAS,CAACM,GAAV,CACbC,QAAQ,IACJL,SAAS,CAACK,QAAD,EAAWN,WAAW,CAACO,WAAvB,EAAoC;AAACC,YAAQ,EAAE;AAAX,GAApC,CAFA,CAAjB;AAIA,QAAMC,kBAAkB,GAAG,CAA3B;AACA,QAAMC,gBAAgB,GAAG,GAAzB;AAEA,QAAMC,SAAS,GAAGX,WAAW,CAACY,UAAZ,IAA0B,IAA1B,GACd,MAAMC,OAAO,CAACC,GAAR,CAAYV,QAAZ,CADQ,GAEd,MAAMR,uBAAuB,CACzBQ,QADyB,EACfJ,WAAW,CAACY,UADG,EACSH,kBADT,EAEzBC,gBAFyB,CAFjC;AAMA,QAAMK,cAAc,GAAGJ,SAAS,CAACN,GAAV,CAAcW,QAAQ,IAAIA,QAAQ,CAACC,WAAT,EAA1B,CAAvB;AAEA,QAAMC,mBAAmB,GAAG,GAA5B;AACA,QAAMC,iBAAiB,GAAG,CAA1B;AAEA,QAAMC,OAAO,GAAGpB,WAAW,CAACY,UAAZ,IAA0B,IAA1B,GACZ,MAAMC,OAAO,CAACC,GAAR,CAAYC,cAAZ,CADM,GAEZ,MAAMnB,uBAAuB,CACzBmB,cADyB,EACTf,WAAW,CAACY,UADH,EACeM,mBADf,EAEzBC,iBAFyB,CAFjC;AAKA,SAAOC,OAAP;AACD;AAED;;;;;;;;;;AASA,OAAO,eAAeC,WAAf,CACHC,QADG,EAGsB;AAAA,MAFQC,cAER,uEAFyB,EAEzB;AAAA,MADzBC,WACyB;AAAA,MAAzBjB,WAAyB;;AAC3B;AACA;AACA;AACA;AACA;AAEA,QAAMkB,YAAY,GAAIC,SAAD,IACjB5B,wBAAwB,CAAC4B,SAAD,EAAY;AAACnB;AAAD,GAAZ,CAD5B;;AAEA,QAAMc,WAAW,GAAGM,oBAAoB,CAACF,YAAD,CAAxC;AAEA,SAAOJ,WAAW,CAACC,QAAD,EAAWC,cAAX,EAA2BC,WAA3B,CAAlB;AACD;AAED;;;;;;;;;;;;;;;;;;;;;;;;;AAwBA,OAAM,SAAUG,oBAAV,CACFC,oBADE,EACmE;AAGvE,SAAO,gBACIN,QADJ,EAEuD;AAAA,QADlBC,cACkB,uEADD,EACC;AAAA,QAAnDC,WAAmD;AAC5D;AACA;AACA,UAAMK,sBAAsB,GAAGP,QAAQ,CAACjB,GAAT,CAAa,MAAM,KAAnB,CAA/B;AACA,UAAMyB,mBAAmB,GAKrB,EALJ;AAMA,UAAMC,YAAY,GACdP,WAAW,IAAI,IAAf,GAAsBA,WAAW,CAACnB,GAAZ,CAAgB,MAAM,KAAtB,CAAtB,GAAqD,EADzD;AAEA,UAAM2B,sBAAsB,GAAa,EAAzC;AACAV,YAAQ,CAACW,OAAT,CAAiB,CAACC,mBAAD,EAAsBC,UAAtB,KAAoC;AACnD,UAAIC,WAAW,GAAG,CAAlB;AACAF,yBAAmB,CAACG,OAApB,CAA4BJ,OAA5B,CAAoCK,YAAY,IAAG;AACjD,cAAMC,QAAQ,GAAI,kBAAkBD,YAAnB,GACbA,YAAY,CAACE,YAAb,CAA0BC,KADb,GAEbH,YAAY,CAACG,KAFjB;AAIA,cAAMC,YAAY,GAAG7C,oBAAoB,CAAC0C,QAAD,CAApB,GACjB7C,IAAI,CAACiD,aAAL,CAAmBL,YAAY,CAACM,KAAhC,CADJ;;AAGA,cAAMC,2BAA2B,GAAG,MAAK;AACvChB,gCAAsB,CAACM,UAAD,CAAtB,GAAqC,IAArC;;AACA,cAAIL,mBAAmB,CAACK,UAAD,CAAnB,IAAmC,IAAvC,EAA6C;AAC3CL,+BAAmB,CAACK,UAAD,CAAnB,GAAkC,EAAlC;AACD;;AAEDL,6BAAmB,CAACK,UAAD,CAAnB,CAAgCW,IAAhC,CAAqC;AACnCC,yBAAa,EAAET,YADoB;AAEnCF,uBAFmC;AAGnCY,qBAAS,EAAEN;AAHwB,WAArC;AAKD,SAXD;;AAaA,YAAIlB,WAAW,IAAI,IAAnB,EAAyB;AACvBA,qBAAW,CAACS,OAAZ,CAAoB,CAACgB,UAAD,EAAaC,WAAb,KAA4B;AAC9C,gBAAID,UAAU,KAAKX,YAAY,CAACa,IAAhC,EAAsC;AACpCN,yCAA2B;AAC3Bd,0BAAY,CAACmB,WAAD,CAAZ,GAA4B,IAA5B;AACD;AACF,WALD;AAMD,SAPD,MAOO;AACLL,qCAA2B;AAC5B;;AAEDb,8BAAsB,CAACc,IAAvB,CAA4BR,YAAY,CAACa,IAAzC;AACAf,mBAAW,IAAIM,YAAf;AACD,OAlCD;AAmCD,KArCD;;AAuCA,QAAI,CAACX,YAAY,CAACqB,KAAb,CAAmBC,KAAK,IAAIA,KAA5B,CAAL,EAAyC;AACvC,YAAMC,eAAe,GAAG9B,WAAW,CAAC+B,MAAZ,CAAmB,CAACC,CAAD,EAAIC,CAAJ,KAAU,CAAC1B,YAAY,CAAC0B,CAAD,CAA1C,CAAxB;AACA,YAAM,IAAIC,KAAJ,CACF,oDACA,GAAGJ,eAAe,CAACK,IAAhB,CAAqB,IAArB,CAA0B,MAD7B,GAEA,wCAFA,GAGA,GAAG3B,sBAAsB,CAAC2B,IAAvB,CAA4B,IAA5B,CAAiC,GAJlC,CAAN;AAKD,KA3D2D,CA6D5D;AACA;;;AACA,UAAMC,mBAAmB,GACrB/B,sBAAsB,CAACgC,MAAvB,CAA8B,CAACC,WAAD,EAAcC,WAAd,EAA2BN,CAA3B,KAAgC;AAC5D,UAAIM,WAAJ,EAAiB;AACfD,mBAAW,CAAChB,IAAZ,CAAiBW,CAAjB;AACD;;AACD,aAAOK,WAAP;AACD,KALD,EAKG,EALH,CADJ;AAQA,UAAMpC,SAAS,GAAa,EAA5B;AACAkC,uBAAmB,CAAC3B,OAApB,CAA4BwB,CAAC,IAAG;AAC9BnC,cAAQ,CAACmC,CAAD,CAAR,CAAYO,KAAZ,CAAkB/B,OAAlB,CAA0BgC,QAAQ,IAAG;AACnC,cAAMC,QAAQ,GAAG3C,cAAc,IAC1B,CAACA,cAAc,CAAC4C,QAAf,CAAwB,GAAxB,CAAD,GAAgC,GAAhC,GAAsC,EADZ,CAAd,GACgCF,QADjD;AAEAvC,iBAAS,CAACoB,IAAV,CAAeoB,QAAf;AACD,OAJD;AAKD,KAND;AAOA,UAAM9C,OAAO,GAAG,MAAMQ,oBAAoB,CAACF,SAAD,CAA1C;AAEA,UAAM0C,gBAAgB,GAAmB,EAAzC;AACA,QAAIC,iBAAiB,GAAG,CAAxB;AACAT,uBAAmB,CAAC3B,OAApB,CAA4BwB,CAAC,IAAG;AAC9B,YAAMa,UAAU,GAAGhD,QAAQ,CAACmC,CAAD,CAAR,CAAYO,KAAZ,CAAkBO,MAArC;AAEA,UAAIC,UAAU,GAAG,CAAjB;;AACA,WAAK,IAAIf,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAGa,UAApB,EAAgCb,CAAC,EAAjC,EAAqC;AACnCe,kBAAU,IAAIpD,OAAO,CAACiD,iBAAiB,GAAGZ,CAArB,CAAP,CAA+BgB,UAA7C;AACD,OAN6B,CAQ9B;;;AACA,YAAMC,WAAW,GAAG,IAAIC,WAAJ,CAAgBH,UAAhB,CAApB;AACA,YAAMI,eAAe,GAAG,IAAIC,UAAJ,CAAeH,WAAf,CAAxB;AACA,UAAII,iBAAiB,GAAG,CAAxB;;AACA,WAAK,IAAIrB,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAGa,UAApB,EAAgCb,CAAC,EAAjC,EAAqC;AACnC,cAAMsB,MAAM,GAAG,IAAIF,UAAJ,CAAezD,OAAO,CAACiD,iBAAiB,GAAGZ,CAArB,CAAtB,CAAf;AACAmB,uBAAe,CAACI,GAAhB,CAAoBD,MAApB,EAA4BD,iBAA5B;AACAA,yBAAiB,IAAIC,MAAM,CAACN,UAA5B;AACD;;AAED,YAAMQ,cAAc,GAAGnD,mBAAmB,CAAC2B,CAAD,CAA1C;AACAwB,oBAAc,CAAChD,OAAf,CAAuBK,YAAY,IAAG;AACpC,cAAM4C,UAAU,GAAGR,WAAW,CAACS,KAAZ,CACf7C,YAAY,CAACF,WADE,EAEfE,YAAY,CAACF,WAAb,GAA2BE,YAAY,CAACU,SAFzB,CAAnB;AAGA,cAAMoC,eAAe,GACjBzF,aAAa,CAACuF,UAAD,EAAa,CAAC5C,YAAY,CAACS,aAAd,CAAb,CADjB;;AAEA,aAAK,MAAMI,IAAX,IAAmBiC,eAAnB,EAAoC;AAClChB,0BAAgB,CAACjB,IAAD,CAAhB,GAAyBiC,eAAe,CAACjC,IAAD,CAAxC;AACD;AACF,OATD;AAWAkB,uBAAiB,IAAIC,UAArB;AACD,KA/BD;AAiCA,WAAOF,gBAAP;AACD,GAvHD;AAwHD","names":["env","util","decodeWeights","monitorPromisesProgress","DTYPE_VALUE_SIZE_MAP","loadWeightsAsArrayBuffer","fetchURLs","loadOptions","fetchFunc","platform","fetch","requests","map","fetchURL","requestInit","isBinary","fetchStartFraction","fetchEndFraction","responses","onProgress","Promise","all","bufferPromises","response","arrayBuffer","bufferStartFraction","bufferEndFraction","buffers","loadWeights","manifest","filePathPrefix","weightNames","fetchWeights","fetchUrls","weightsLoaderFactory","fetchWeightsFunction","groupIndicesToFetchMap","groupWeightsToFetch","weightsFound","allManifestWeightNames","forEach","manifestGroupConfig","groupIndex","groupOffset","weights","weightsEntry","rawDtype","quantization","dtype","weightsBytes","sizeFromShape","shape","enqueueWeightsForFetchingFn","push","manifestEntry","sizeBytes","weightName","weightIndex","name","every","found","weightsNotFound","filter","_","i","Error","join","groupIndicesToFetch","reduce","accumulator","shouldFetch","paths","filepath","fetchUrl","endsWith","weightsTensorMap","bufferIndexOffset","numBuffers","length","groupBytes","byteLength","groupBuffer","ArrayBuffer","groupByteBuffer","Uint8Array","groupBufferOffset","buffer","set","weightsEntries","byteBuffer","slice","nameToTensorMap"],"sources":["/home/nadimakhtar97/smart-attendance-system/tfjs-core/src/io/weights_loader.ts"],"sourcesContent":["/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {env} from '../environment';\n\nimport {NamedTensorMap} from '../tensor_types';\nimport * as util from '../util';\nimport {decodeWeights} from './io_utils';\nimport {monitorPromisesProgress} from './progress';\nimport {DTYPE_VALUE_SIZE_MAP, LoadOptions, WeightsManifestConfig, WeightsManifestEntry} from './types';\n\n/**\n * Reads binary weights data from a number of URLs.\n *\n * @param fetchURLs URLs to send the HTTP requests at, using `fetch` calls.\n * @param requestOptions RequestInit (options) for the HTTP requests.\n * @param fetchFunc Optional overriding value for the `window.fetch` function.\n * @param onProgress Optional, progress callback function, fired periodically\n *   before the load is completed.\n * @returns A `Promise` of an Array of `ArrayBuffer`. The Array has the same\n *   length as `fetchURLs`.\n */\nexport async function loadWeightsAsArrayBuffer(\n    fetchURLs: string[], loadOptions?: LoadOptions): Promise<ArrayBuffer[]> {\n  if (loadOptions == null) {\n    loadOptions = {};\n  }\n\n  const fetchFunc = loadOptions.fetchFunc == null ? env().platform.fetch :\n                                                    loadOptions.fetchFunc;\n\n  // Create the requests for all of the weights in parallel.\n  const requests = fetchURLs.map(\n      fetchURL =>\n          fetchFunc(fetchURL, loadOptions.requestInit, {isBinary: true}));\n\n  const fetchStartFraction = 0;\n  const fetchEndFraction = 0.5;\n\n  const responses = loadOptions.onProgress == null ?\n      await Promise.all(requests) :\n      await monitorPromisesProgress(\n          requests, loadOptions.onProgress, fetchStartFraction,\n          fetchEndFraction);\n\n  const bufferPromises = responses.map(response => response.arrayBuffer());\n\n  const bufferStartFraction = 0.5;\n  const bufferEndFraction = 1;\n\n  const buffers = loadOptions.onProgress == null ?\n      await Promise.all(bufferPromises) :\n      await monitorPromisesProgress(\n          bufferPromises, loadOptions.onProgress, bufferStartFraction,\n          bufferEndFraction);\n  return buffers;\n}\n\n/**\n * Reads a weights manifest JSON configuration, fetches the weights and\n * returns them as `Tensor`s.\n *\n * @param manifest The weights manifest JSON.\n * @param filePathPrefix The path prefix for filenames given in the manifest.\n *     Defaults to the empty string.\n * @param weightNames The names of the weights to be fetched.\n */\nexport async function loadWeights(\n    manifest: WeightsManifestConfig, filePathPrefix = '',\n    weightNames?: string[],\n    requestInit?: RequestInit): Promise<NamedTensorMap> {\n  // TODO(nsthorat): Groups are currently fetched atomically. If you need a\n  // single weight from a group, the whole group will be fetched. At a future\n  // date, we should support fetching only the individual shards within a\n  // group that are needed to reconstruct the requested weight.\n  // TODO(cais): Use `decodeWeights` for implementation.\n\n  const fetchWeights = (fetchUrls: string[]) =>\n      loadWeightsAsArrayBuffer(fetchUrls, {requestInit});\n  const loadWeights = weightsLoaderFactory(fetchWeights);\n\n  return loadWeights(manifest, filePathPrefix, weightNames);\n}\n\n/**\n * Creates a function, which reads a weights manifest JSON configuration,\n * fetches the weight files using the specified function and returns them as\n * `Tensor`s.\n *\n * ```js\n * // example for creating a nodejs weight loader, which reads the weight files\n * // from disk using fs.readFileSync\n *\n * import * as fs from 'fs'\n *\n * const fetchWeightsFromDisk = (filePaths: string[]) =>\n *   filePaths.map(filePath => fs.readFileSync(filePath).buffer)\n *\n * const loadWeights = tf.io.weightsLoaderFactory(fetchWeightsFromDisk)\n *\n * const manifest = JSON.parse(\n *   fs.readFileSync('./my_model-weights_manifest').toString()\n * )\n * const weightMap = await loadWeights(manifest, './')\n * ```\n * @param fetchWeightsFunction The function used for fetching the weight files.\n * @returns Weight loading function.\n */\nexport function weightsLoaderFactory(\n    fetchWeightsFunction: (fetchUrls: string[]) => Promise<ArrayBuffer[]>):\n    (manifest: WeightsManifestConfig, filePathPrefix?: string,\n     weightNames?: string[]) => Promise<NamedTensorMap> {\n  return async(\n             manifest: WeightsManifestConfig, filePathPrefix = '',\n             weightNames?: string[]): Promise<NamedTensorMap> => {\n    // Collect all the groups, weights, and their relative offsets to be\n    // fetched.\n    const groupIndicesToFetchMap = manifest.map(() => false);\n    const groupWeightsToFetch: {\n      [group: number]: Array<{\n        manifestEntry: WeightsManifestEntry; groupOffset: number;\n        sizeBytes: number;\n      }>\n    } = {};\n    const weightsFound =\n        weightNames != null ? weightNames.map(() => false) : [];\n    const allManifestWeightNames: string[] = [];\n    manifest.forEach((manifestGroupConfig, groupIndex) => {\n      let groupOffset = 0;\n      manifestGroupConfig.weights.forEach(weightsEntry => {\n        const rawDtype = ('quantization' in weightsEntry) ?\n            weightsEntry.quantization.dtype :\n            weightsEntry.dtype;\n\n        const weightsBytes = DTYPE_VALUE_SIZE_MAP[rawDtype] *\n            util.sizeFromShape(weightsEntry.shape);\n\n        const enqueueWeightsForFetchingFn = () => {\n          groupIndicesToFetchMap[groupIndex] = true;\n          if (groupWeightsToFetch[groupIndex] == null) {\n            groupWeightsToFetch[groupIndex] = [];\n          }\n\n          groupWeightsToFetch[groupIndex].push({\n            manifestEntry: weightsEntry,\n            groupOffset,\n            sizeBytes: weightsBytes\n          });\n        };\n\n        if (weightNames != null) {\n          weightNames.forEach((weightName, weightIndex) => {\n            if (weightName === weightsEntry.name) {\n              enqueueWeightsForFetchingFn();\n              weightsFound[weightIndex] = true;\n            }\n          });\n        } else {\n          enqueueWeightsForFetchingFn();\n        }\n\n        allManifestWeightNames.push(weightsEntry.name);\n        groupOffset += weightsBytes;\n      });\n    });\n\n    if (!weightsFound.every(found => found)) {\n      const weightsNotFound = weightNames.filter((_, i) => !weightsFound[i]);\n      throw new Error(\n          `Could not find weights in manifest with names: ` +\n          `${weightsNotFound.join(', ')}. \\n` +\n          `Manifest JSON has weights with names: ` +\n          `${allManifestWeightNames.join(', ')}.`);\n    }\n\n    // Convert the one-hot boolean groupId => shouldFetch map to a list of group\n    // IDs.\n    const groupIndicesToFetch =\n        groupIndicesToFetchMap.reduce((accumulator, shouldFetch, i) => {\n          if (shouldFetch) {\n            accumulator.push(i);\n          }\n          return accumulator;\n        }, []);\n\n    const fetchUrls: string[] = [];\n    groupIndicesToFetch.forEach(i => {\n      manifest[i].paths.forEach(filepath => {\n        const fetchUrl = filePathPrefix +\n            (!filePathPrefix.endsWith('/') ? '/' : '') + filepath;\n        fetchUrls.push(fetchUrl);\n      });\n    });\n    const buffers = await fetchWeightsFunction(fetchUrls);\n\n    const weightsTensorMap: NamedTensorMap = {};\n    let bufferIndexOffset = 0;\n    groupIndicesToFetch.forEach(i => {\n      const numBuffers = manifest[i].paths.length;\n\n      let groupBytes = 0;\n      for (let i = 0; i < numBuffers; i++) {\n        groupBytes += buffers[bufferIndexOffset + i].byteLength;\n      }\n\n      // Create a buffer for the whole group.\n      const groupBuffer = new ArrayBuffer(groupBytes);\n      const groupByteBuffer = new Uint8Array(groupBuffer);\n      let groupBufferOffset = 0;\n      for (let i = 0; i < numBuffers; i++) {\n        const buffer = new Uint8Array(buffers[bufferIndexOffset + i]);\n        groupByteBuffer.set(buffer, groupBufferOffset);\n        groupBufferOffset += buffer.byteLength;\n      }\n\n      const weightsEntries = groupWeightsToFetch[i];\n      weightsEntries.forEach(weightsEntry => {\n        const byteBuffer = groupBuffer.slice(\n            weightsEntry.groupOffset,\n            weightsEntry.groupOffset + weightsEntry.sizeBytes);\n        const nameToTensorMap =\n            decodeWeights(byteBuffer, [weightsEntry.manifestEntry]);\n        for (const name in nameToTensorMap) {\n          weightsTensorMap[name] = nameToTensorMap[name];\n        }\n      });\n\n      bufferIndexOffset += numBuffers;\n    });\n\n    return weightsTensorMap;\n  };\n}\n"]},"metadata":{},"sourceType":"module"}