{"ast":null,"code":"/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Maximum } from '../kernel_names';\nimport { makeTypesMatch } from '../tensor_util';\nimport { convertToTensor } from '../tensor_util_env';\nimport { assertAndGetBroadcastShape } from './broadcast_util';\nimport { cast } from './cast';\nimport { op } from './operation';\n/**\n * Returns the max of a and b (`a > b ? a : b`) element-wise.\n * Supports broadcasting.\n *\n * We also expose `tf.maximumStrict` which has the same signature as this op and\n * asserts that `a` and `b` are the same shape (does not broadcast).\n *\n * ```js\n * const a = tf.tensor1d([1, 4, 3, 16]);\n * const b = tf.tensor1d([1, 2, 9, 4]);\n *\n * a.maximum(b).print();  // or tf.maximum(a, b)\n * ```\n *\n * ```js\n * // Broadcast maximum a with b.\n * const a = tf.tensor1d([2, 4, 6, 8]);\n * const b = tf.scalar(5);\n *\n * a.maximum(b).print();  // or tf.maximum(a, b)\n * ```\n *\n * @param a The first tensor.\n * @param b The second tensor. Must have the same type as `a`.\n *\n * @doc {heading: 'Operations', subheading: 'Arithmetic'}\n */\n\nfunction maximum_(a, b) {\n  let $a = convertToTensor(a, 'a', 'maximum');\n  let $b = convertToTensor(b, 'b', 'maximum');\n  [$a, $b] = makeTypesMatch($a, $b);\n\n  if ($a.dtype === 'bool') {\n    $a = cast($a, 'int32');\n    $b = cast($b, 'int32');\n  }\n\n  assertAndGetBroadcastShape($a.shape, $b.shape);\n  const inputs = {\n    a: $a,\n    b: $b\n  };\n  return ENGINE.runKernel(Maximum, inputs);\n}\n\nexport const maximum = op({\n  maximum_\n});","map":{"version":3,"mappings":"AAAA;;;;;;;;;;;;;;;;AAiBA,SAAQA,MAAR,QAAqB,WAArB;AACA,SAAQC,OAAR,QAAqC,iBAArC;AAGA,SAAQC,cAAR,QAA6B,gBAA7B;AACA,SAAQC,eAAR,QAA8B,oBAA9B;AAGA,SAAQC,0BAAR,QAAyC,kBAAzC;AACA,SAAQC,IAAR,QAAmB,QAAnB;AACA,SAAQC,EAAR,QAAiB,aAAjB;AAEA;;;;;;;;;;;;;;;;;;;;;;;;;;;;AA2BA,SAASC,QAAT,CACIC,CADJ,EAC0BC,CAD1B,EAC8C;AAC5C,MAAIC,EAAE,GAAGP,eAAe,CAACK,CAAD,EAAI,GAAJ,EAAS,SAAT,CAAxB;AACA,MAAIG,EAAE,GAAGR,eAAe,CAACM,CAAD,EAAI,GAAJ,EAAS,SAAT,CAAxB;AACA,GAACC,EAAD,EAAKC,EAAL,IAAWT,cAAc,CAACQ,EAAD,EAAKC,EAAL,CAAzB;;AAEA,MAAID,EAAE,CAACE,KAAH,KAAa,MAAjB,EAAyB;AACvBF,MAAE,GAAGL,IAAI,CAACK,EAAD,EAAK,OAAL,CAAT;AACAC,MAAE,GAAGN,IAAI,CAACM,EAAD,EAAK,OAAL,CAAT;AACD;;AACDP,4BAA0B,CAACM,EAAE,CAACG,KAAJ,EAAWF,EAAE,CAACE,KAAd,CAA1B;AAEA,QAAMC,MAAM,GAAkB;AAACN,KAAC,EAAEE,EAAJ;AAAQD,KAAC,EAAEE;AAAX,GAA9B;AAEA,SAAOX,MAAM,CAACe,SAAP,CAAiBd,OAAjB,EAA0Ba,MAA1B,CAAP;AACD;;AAED,OAAO,MAAME,OAAO,GAAGV,EAAE,CAAC;AAACC;AAAD,CAAD,CAAlB","names":["ENGINE","Maximum","makeTypesMatch","convertToTensor","assertAndGetBroadcastShape","cast","op","maximum_","a","b","$a","$b","dtype","shape","inputs","runKernel","maximum"],"sources":["/home/nadimakhtar97/smart-attendance-system/tfjs-core/src/ops/maximum.ts"],"sourcesContent":["/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ENGINE} from '../engine';\nimport {Maximum, MaximumInputs} from '../kernel_names';\nimport {Tensor} from '../tensor';\nimport {NamedTensorMap} from '../tensor_types';\nimport {makeTypesMatch} from '../tensor_util';\nimport {convertToTensor} from '../tensor_util_env';\nimport {TensorLike} from '../types';\n\nimport {assertAndGetBroadcastShape} from './broadcast_util';\nimport {cast} from './cast';\nimport {op} from './operation';\n\n/**\n * Returns the max of a and b (`a > b ? a : b`) element-wise.\n * Supports broadcasting.\n *\n * We also expose `tf.maximumStrict` which has the same signature as this op and\n * asserts that `a` and `b` are the same shape (does not broadcast).\n *\n * ```js\n * const a = tf.tensor1d([1, 4, 3, 16]);\n * const b = tf.tensor1d([1, 2, 9, 4]);\n *\n * a.maximum(b).print();  // or tf.maximum(a, b)\n * ```\n *\n * ```js\n * // Broadcast maximum a with b.\n * const a = tf.tensor1d([2, 4, 6, 8]);\n * const b = tf.scalar(5);\n *\n * a.maximum(b).print();  // or tf.maximum(a, b)\n * ```\n *\n * @param a The first tensor.\n * @param b The second tensor. Must have the same type as `a`.\n *\n * @doc {heading: 'Operations', subheading: 'Arithmetic'}\n */\nfunction maximum_<T extends Tensor>(\n    a: Tensor|TensorLike, b: Tensor|TensorLike): T {\n  let $a = convertToTensor(a, 'a', 'maximum');\n  let $b = convertToTensor(b, 'b', 'maximum');\n  [$a, $b] = makeTypesMatch($a, $b);\n\n  if ($a.dtype === 'bool') {\n    $a = cast($a, 'int32');\n    $b = cast($b, 'int32');\n  }\n  assertAndGetBroadcastShape($a.shape, $b.shape);\n\n  const inputs: MaximumInputs = {a: $a, b: $b};\n\n  return ENGINE.runKernel(Maximum, inputs as {} as NamedTensorMap);\n}\n\nexport const maximum = op({maximum_});\n"]},"metadata":{},"sourceType":"module"}