{"ast":null,"code":"/**\n * @license\n * Copyright 2018 Google LLC\n *\n * Use of this source code is governed by an MIT-style\n * license that can be found in the LICENSE file or at\n * https://opensource.org/licenses/MIT.\n * =============================================================================\n */\n\n/**\n * TensorFlow.js Layers: Embedding Layer.\n *\n * Original source: keras/constraints.py\n */\nimport { notEqual, reshape, serialization, tidy, zerosLike } from '@tensorflow/tfjs-core';\nimport * as K from '../backend/tfjs_backend';\nimport { getConstraint, serializeConstraint } from '../constraints';\nimport { Layer } from '../engine/topology';\nimport { ValueError } from '../errors';\nimport { getInitializer, serializeInitializer } from '../initializers';\nimport { getRegularizer, serializeRegularizer } from '../regularizers';\nimport * as generic_utils from '../utils/generic_utils';\nimport { getExactlyOneShape, getExactlyOneTensor } from '../utils/types_utils';\nexport class Embedding extends Layer {\n  constructor(args) {\n    super(args);\n    this.embeddings = null;\n    this.DEFAULT_EMBEDDINGS_INITIALIZER = 'randomUniform';\n\n    if (args.batchInputShape == null && args.inputShape == null) {\n      // Porting Note: This logic is copied from Layer's constructor, since we\n      // can't do exactly what the Python constructor does for Embedding().\n      // Specifically, the super constructor can not be called after the\n      // mutation of the `config` argument.\n      let batchSize = null;\n\n      if (args.batchSize != null) {\n        batchSize = args.batchSize;\n      }\n\n      if (args.inputLength == null) {\n        // Fix super-constructor to what it would have done if\n        // 'config.inputShape' were (None, )\n        this.batchInputShape = [batchSize, null];\n      } else {\n        // Fix super-constructor to what it would have done if\n        // 'config.inputShape' were (config.inputLength, )\n        this.batchInputShape = [batchSize].concat(generic_utils.toList(args.inputLength));\n      }\n    }\n\n    this.inputDim = args.inputDim;\n    generic_utils.assertPositiveInteger(this.inputDim, 'inputDim');\n    this.outputDim = args.outputDim;\n    generic_utils.assertPositiveInteger(this.outputDim, 'outputDim');\n    this.embeddingsInitializer = getInitializer(args.embeddingsInitializer || this.DEFAULT_EMBEDDINGS_INITIALIZER);\n    this.embeddingsRegularizer = getRegularizer(args.embeddingsRegularizer);\n    this.activityRegularizer = getRegularizer(args.activityRegularizer);\n    this.embeddingsConstraint = getConstraint(args.embeddingsConstraint);\n    this.maskZero = args.maskZero;\n    this.supportsMasking = args.maskZero;\n    this.inputLength = args.inputLength;\n  }\n\n  build(inputShape) {\n    this.embeddings = this.addWeight('embeddings', [this.inputDim, this.outputDim], this.dtype, this.embeddingsInitializer, this.embeddingsRegularizer, true, this.embeddingsConstraint);\n    this.built = true;\n  } // Override warnOnIncompatibleInputShape because an embedding layer allows\n  // the input to have varying ranks.\n\n\n  warnOnIncompatibleInputShape(inputShape) {}\n\n  computeMask(inputs, mask) {\n    return tidy(() => {\n      if (!this.maskZero) {\n        return null;\n      } else {\n        inputs = getExactlyOneTensor(inputs);\n        return notEqual(inputs, zerosLike(inputs));\n      }\n    });\n  }\n\n  computeOutputShape(inputShape) {\n    inputShape = getExactlyOneShape(inputShape);\n\n    if (this.inputLength == null) {\n      return [...inputShape, this.outputDim];\n    } // inputLength can be an array if input is 3D or higher.\n\n\n    const inLens = generic_utils.toList(this.inputLength);\n\n    if (inLens.length !== inputShape.length - 1) {\n      throw new ValueError(`\"inputLength\" is ${this.inputLength}, but received ` + `input shape has shape ${inputShape}`);\n    } else {\n      let i = 0;\n\n      for (let k = 0; k < inLens.length; ++k) {\n        const s1 = inLens[k];\n        const s2 = inputShape[k + 1];\n\n        if (s1 != null && s2 != null && s1 !== s2) {\n          throw new ValueError(`\"inputLength\" is ${this.inputLength}, but received ` + `input shape has shape ${inputShape}`);\n        } else if (s1 == null) {\n          inLens[i] = s2;\n        }\n\n        i++;\n      }\n    }\n\n    return [inputShape[0], ...inLens, this.outputDim];\n  }\n\n  call(inputs, kwargs) {\n    return tidy(() => {\n      this.invokeCallHook(inputs, kwargs); // Embedding layer accepts only a single input.\n\n      let input = getExactlyOneTensor(inputs);\n\n      if (input.dtype !== 'int32') {\n        input = K.cast(input, 'int32');\n      }\n\n      const output = K.gather(this.embeddings.read(), reshape(input, [input.size]));\n      return reshape(output, getExactlyOneShape(this.computeOutputShape(input.shape)));\n    });\n  }\n\n  getConfig() {\n    const config = {\n      inputDim: this.inputDim,\n      outputDim: this.outputDim,\n      embeddingsInitializer: serializeInitializer(this.embeddingsInitializer),\n      embeddingsRegularizer: serializeRegularizer(this.embeddingsRegularizer),\n      activityRegularizer: serializeRegularizer(this.activityRegularizer),\n      embeddingsConstraint: serializeConstraint(this.embeddingsConstraint),\n      maskZero: this.maskZero,\n      inputLength: this.inputLength\n    };\n    const baseConfig = super.getConfig();\n    Object.assign(config, baseConfig);\n    return config;\n  }\n\n}\n/** @nocollapse */\n\nEmbedding.className = 'Embedding';\nserialization.registerClass(Embedding);","map":{"version":3,"mappings":"AAAA;;;;;;;;;;AAUA;;;;;AAKA,SAAQA,QAAR,EAAkBC,OAAlB,EAA2BC,aAA3B,EAAkDC,IAAlD,EAAwDC,SAAxD,QAAwE,uBAAxE;AAEA,OAAO,KAAKC,CAAZ,MAAmB,yBAAnB;AACA,SAA0CC,aAA1C,EAAyDC,mBAAzD,QAAmF,gBAAnF;AACA,SAAQC,KAAR,QAA+B,oBAA/B;AACA,SAAQC,UAAR,QAAyB,WAAzB;AACA,SAAQC,cAAR,EAA4DC,oBAA5D,QAAuF,iBAAvF;AAEA,SAAQC,cAAR,EAA4DC,oBAA5D,QAAuF,iBAAvF;AAEA,OAAO,KAAKC,aAAZ,MAA+B,wBAA/B;AACA,SAAQC,kBAAR,EAA4BC,mBAA5B,QAAsD,sBAAtD;AAiDA,OAAM,MAAOC,SAAP,SAAyBT,KAAzB,CAA8B;AAgBlCU,cAAYC,IAAZ,EAAoC;AAClC,UAAMA,IAAN;AARM,sBAA4B,IAA5B;AAEC,0CACL,eADK;;AAOP,QAAIA,IAAI,CAACC,eAAL,IAAwB,IAAxB,IAAgCD,IAAI,CAACE,UAAL,IAAmB,IAAvD,EAA6D;AAC3D;AACA;AACA;AACA;AACA,UAAIC,SAAS,GAAW,IAAxB;;AACA,UAAIH,IAAI,CAACG,SAAL,IAAkB,IAAtB,EAA4B;AAC1BA,iBAAS,GAAGH,IAAI,CAACG,SAAjB;AACD;;AACD,UAAIH,IAAI,CAACI,WAAL,IAAoB,IAAxB,EAA8B;AAC5B;AACA;AACA,aAAKH,eAAL,GAAuB,CAACE,SAAD,EAAY,IAAZ,CAAvB;AACD,OAJD,MAIO;AACL;AACA;AACA,aAAKF,eAAL,GACI,CAACE,SAAD,EAAYE,MAAZ,CAAmBV,aAAa,CAACW,MAAd,CAAqBN,IAAI,CAACI,WAA1B,CAAnB,CADJ;AAED;AACF;;AACD,SAAKG,QAAL,GAAgBP,IAAI,CAACO,QAArB;AACAZ,iBAAa,CAACa,qBAAd,CAAoC,KAAKD,QAAzC,EAAmD,UAAnD;AACA,SAAKE,SAAL,GAAiBT,IAAI,CAACS,SAAtB;AACAd,iBAAa,CAACa,qBAAd,CAAoC,KAAKC,SAAzC,EAAoD,WAApD;AACA,SAAKC,qBAAL,GAA6BnB,cAAc,CACvCS,IAAI,CAACU,qBAAL,IAA8B,KAAKC,8BADI,CAA3C;AAEA,SAAKC,qBAAL,GAA6BnB,cAAc,CAACO,IAAI,CAACY,qBAAN,CAA3C;AACA,SAAKC,mBAAL,GAA2BpB,cAAc,CAACO,IAAI,CAACa,mBAAN,CAAzC;AACA,SAAKC,oBAAL,GAA4B3B,aAAa,CAACa,IAAI,CAACc,oBAAN,CAAzC;AACA,SAAKC,QAAL,GAAgBf,IAAI,CAACe,QAArB;AACA,SAAKC,eAAL,GAAuBhB,IAAI,CAACe,QAA5B;AACA,SAAKX,WAAL,GAAmBJ,IAAI,CAACI,WAAxB;AACD;;AAEMa,OAAK,CAACf,UAAD,EAA0B;AACpC,SAAKgB,UAAL,GAAkB,KAAKC,SAAL,CACd,YADc,EACA,CAAC,KAAKZ,QAAN,EAAgB,KAAKE,SAArB,CADA,EACiC,KAAKW,KADtC,EAEd,KAAKV,qBAFS,EAEc,KAAKE,qBAFnB,EAE0C,IAF1C,EAGd,KAAKE,oBAHS,CAAlB;AAIA,SAAKO,KAAL,GAAa,IAAb;AACD,GA1DiC,CA4DlC;AACA;;;AACUC,8BAA4B,CAACpB,UAAD,EAAkB,CAAI;;AAE5DqB,aAAW,CAACC,MAAD,EAA0BC,IAA1B,EAAgD;AACzD,WAAOzC,IAAI,CAAC,MAAK;AACf,UAAI,CAAC,KAAK+B,QAAV,EAAoB;AAClB,eAAO,IAAP;AACD,OAFD,MAEO;AACLS,cAAM,GAAG3B,mBAAmB,CAAC2B,MAAD,CAA5B;AACA,eAAO3C,QAAQ,CAAC2C,MAAD,EAASvC,SAAS,CAACuC,MAAD,CAAlB,CAAf;AACD;AACF,KAPU,CAAX;AAQD;;AAEDE,oBAAkB,CAACxB,UAAD,EAA0B;AAC1CA,cAAU,GAAGN,kBAAkB,CAACM,UAAD,CAA/B;;AACA,QAAI,KAAKE,WAAL,IAAoB,IAAxB,EAA8B;AAC5B,aAAO,CAAC,GAAGF,UAAJ,EAAgB,KAAKO,SAArB,CAAP;AACD,KAJyC,CAK1C;;;AACA,UAAMkB,MAAM,GAAahC,aAAa,CAACW,MAAd,CAAqB,KAAKF,WAA1B,CAAzB;;AACA,QAAIuB,MAAM,CAACC,MAAP,KAAkB1B,UAAU,CAAC0B,MAAX,GAAoB,CAA1C,EAA6C;AAC3C,YAAM,IAAItC,UAAJ,CACF,oBAAoB,KAAKc,WAAW,iBAApC,GACA,yBAAyBF,UAAU,EAFjC,CAAN;AAGD,KAJD,MAIO;AACL,UAAI2B,CAAC,GAAG,CAAR;;AACA,WAAK,IAAIC,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAGH,MAAM,CAACC,MAA3B,EAAmC,EAAEE,CAArC,EAAwC;AACtC,cAAMC,EAAE,GAAGJ,MAAM,CAACG,CAAD,CAAjB;AACA,cAAME,EAAE,GAAG9B,UAAU,CAAC4B,CAAC,GAAG,CAAL,CAArB;;AACA,YAAKC,EAAE,IAAI,IAAP,IAAiBC,EAAE,IAAI,IAAvB,IAAiCD,EAAE,KAAKC,EAA5C,EAAiD;AAC/C,gBAAM,IAAI1C,UAAJ,CACF,oBAAoB,KAAKc,WAAW,iBAApC,GACA,yBAAyBF,UAAU,EAFjC,CAAN;AAGD,SAJD,MAIO,IAAI6B,EAAE,IAAI,IAAV,EAAgB;AACrBJ,gBAAM,CAACE,CAAD,CAAN,GAAYG,EAAZ;AACD;;AACDH,SAAC;AACF;AACF;;AACD,WAAO,CAAC3B,UAAU,CAAC,CAAD,CAAX,EAAgB,GAAGyB,MAAnB,EAA2B,KAAKlB,SAAhC,CAAP;AACD;;AAEDwB,MAAI,CAACT,MAAD,EAA0BU,MAA1B,EAAwC;AAC1C,WAAOlD,IAAI,CAAC,MAAK;AACf,WAAKmD,cAAL,CAAoBX,MAApB,EAA4BU,MAA5B,EADe,CAEf;;AACA,UAAIE,KAAK,GAAGvC,mBAAmB,CAAC2B,MAAD,CAA/B;;AACA,UAAIY,KAAK,CAAChB,KAAN,KAAgB,OAApB,EAA6B;AAC3BgB,aAAK,GAAGlD,CAAC,CAACmD,IAAF,CAAOD,KAAP,EAAc,OAAd,CAAR;AACD;;AACD,YAAME,MAAM,GACRpD,CAAC,CAACqD,MAAF,CAAS,KAAKrB,UAAL,CAAgBsB,IAAhB,EAAT,EAAiC1D,OAAO,CAACsD,KAAD,EAAQ,CAACA,KAAK,CAACK,IAAP,CAAR,CAAxC,CADJ;AAEA,aAAO3D,OAAO,CACVwD,MADU,EACF1C,kBAAkB,CAAC,KAAK8B,kBAAL,CAAwBU,KAAK,CAACM,KAA9B,CAAD,CADhB,CAAd;AAED,KAXU,CAAX;AAYD;;AAEDC,WAAS;AACP,UAAMC,MAAM,GAAG;AACbrC,cAAQ,EAAE,KAAKA,QADF;AAEbE,eAAS,EAAE,KAAKA,SAFH;AAGbC,2BAAqB,EAAElB,oBAAoB,CAAC,KAAKkB,qBAAN,CAH9B;AAIbE,2BAAqB,EAAElB,oBAAoB,CAAC,KAAKkB,qBAAN,CAJ9B;AAKbC,yBAAmB,EAAEnB,oBAAoB,CAAC,KAAKmB,mBAAN,CAL5B;AAMbC,0BAAoB,EAAE1B,mBAAmB,CAAC,KAAK0B,oBAAN,CAN5B;AAObC,cAAQ,EAAE,KAAKA,QAPF;AAQbX,iBAAW,EAAE,KAAKA;AARL,KAAf;AAUA,UAAMyC,UAAU,GAAG,MAAMF,SAAN,EAAnB;AACAG,UAAM,CAACC,MAAP,CAAcH,MAAd,EAAsBC,UAAtB;AACA,WAAOD,MAAP;AACD;;AArIiC;AAClC;;AACO9C,sBAAY,WAAZ;AAqITf,aAAa,CAACiE,aAAd,CAA4BlD,SAA5B","names":["notEqual","reshape","serialization","tidy","zerosLike","K","getConstraint","serializeConstraint","Layer","ValueError","getInitializer","serializeInitializer","getRegularizer","serializeRegularizer","generic_utils","getExactlyOneShape","getExactlyOneTensor","Embedding","constructor","args","batchInputShape","inputShape","batchSize","inputLength","concat","toList","inputDim","assertPositiveInteger","outputDim","embeddingsInitializer","DEFAULT_EMBEDDINGS_INITIALIZER","embeddingsRegularizer","activityRegularizer","embeddingsConstraint","maskZero","supportsMasking","build","embeddings","addWeight","dtype","built","warnOnIncompatibleInputShape","computeMask","inputs","mask","computeOutputShape","inLens","length","i","k","s1","s2","call","kwargs","invokeCallHook","input","cast","output","gather","read","size","shape","getConfig","config","baseConfig","Object","assign","registerClass"],"sources":["/home/nadimakhtar97/smart-attendance-system/tfjs-layers/src/layers/embeddings.ts"],"sourcesContent":["/**\n * @license\n * Copyright 2018 Google LLC\n *\n * Use of this source code is governed by an MIT-style\n * license that can be found in the LICENSE file or at\n * https://opensource.org/licenses/MIT.\n * =============================================================================\n */\n\n/**\n * TensorFlow.js Layers: Embedding Layer.\n *\n * Original source: keras/constraints.py\n */\nimport {notEqual, reshape, serialization, Tensor, tidy, zerosLike} from '@tensorflow/tfjs-core';\n\nimport * as K from '../backend/tfjs_backend';\nimport {Constraint, ConstraintIdentifier, getConstraint, serializeConstraint} from '../constraints';\nimport {Layer, LayerArgs} from '../engine/topology';\nimport {ValueError} from '../errors';\nimport {getInitializer, Initializer, InitializerIdentifier, serializeInitializer} from '../initializers';\nimport {Shape} from '../keras_format/common';\nimport {getRegularizer, Regularizer, RegularizerIdentifier, serializeRegularizer} from '../regularizers';\nimport {Kwargs} from '../types';\nimport * as generic_utils from '../utils/generic_utils';\nimport {getExactlyOneShape, getExactlyOneTensor} from '../utils/types_utils';\nimport {LayerVariable} from '../variables';\n\nexport declare interface EmbeddingLayerArgs extends LayerArgs {\n  /**\n   * Integer > 0. Size of the vocabulary, i.e. maximum integer index + 1.\n   */\n  inputDim: number;\n  /**\n   * Integer >= 0. Dimension of the dense embedding.\n   */\n  outputDim: number;\n  /**\n   * Initializer for the `embeddings` matrix.\n   */\n  embeddingsInitializer?: InitializerIdentifier|Initializer;\n  /**\n   * Regularizer function applied to the `embeddings` matrix.\n   */\n  embeddingsRegularizer?: RegularizerIdentifier|Regularizer;\n  /**\n   * Regularizer function applied to the activation.\n   */\n  activityRegularizer?: RegularizerIdentifier|Regularizer;\n  /**\n   * Constraint function applied to the `embeddings` matrix.\n   */\n  embeddingsConstraint?: ConstraintIdentifier|Constraint;\n  /**\n   * Whether the input value 0 is a special \"padding\" value that should be\n   * masked out. This is useful when using recurrent layers which may take\n   * variable length input.\n   *\n   * If this is `True` then all subsequent layers in the model need to support\n   * masking or an exception will be raised. If maskZero is set to `True`, as a\n   * consequence, index 0 cannot be used in the vocabulary (inputDim should\n   * equal size of vocabulary + 1).\n   */\n  maskZero?: boolean;\n  /**\n   * Length of input sequences, when it is constant.\n   *\n   * This argument is required if you are going to connect `flatten` then\n   * `dense` layers upstream (without it, the shape of the dense outputs cannot\n   * be computed).\n   */\n  inputLength?: number|number[];\n}\n\nexport class Embedding extends Layer {\n  /** @nocollapse */\n  static className = 'Embedding';\n  private inputDim: number;\n  private outputDim: number;\n  private embeddingsInitializer: Initializer;\n  private maskZero: boolean;\n  private inputLength: number|number[];\n\n  private embeddings: LayerVariable = null;\n\n  readonly DEFAULT_EMBEDDINGS_INITIALIZER: InitializerIdentifier =\n      'randomUniform';\n  private readonly embeddingsRegularizer?: Regularizer;\n  private readonly embeddingsConstraint?: Constraint;\n\n  constructor(args: EmbeddingLayerArgs) {\n    super(args);\n    if (args.batchInputShape == null && args.inputShape == null) {\n      // Porting Note: This logic is copied from Layer's constructor, since we\n      // can't do exactly what the Python constructor does for Embedding().\n      // Specifically, the super constructor can not be called after the\n      // mutation of the `config` argument.\n      let batchSize: number = null;\n      if (args.batchSize != null) {\n        batchSize = args.batchSize;\n      }\n      if (args.inputLength == null) {\n        // Fix super-constructor to what it would have done if\n        // 'config.inputShape' were (None, )\n        this.batchInputShape = [batchSize, null];\n      } else {\n        // Fix super-constructor to what it would have done if\n        // 'config.inputShape' were (config.inputLength, )\n        this.batchInputShape =\n            [batchSize].concat(generic_utils.toList(args.inputLength));\n      }\n    }\n    this.inputDim = args.inputDim;\n    generic_utils.assertPositiveInteger(this.inputDim, 'inputDim');\n    this.outputDim = args.outputDim;\n    generic_utils.assertPositiveInteger(this.outputDim, 'outputDim');\n    this.embeddingsInitializer = getInitializer(\n        args.embeddingsInitializer || this.DEFAULT_EMBEDDINGS_INITIALIZER);\n    this.embeddingsRegularizer = getRegularizer(args.embeddingsRegularizer);\n    this.activityRegularizer = getRegularizer(args.activityRegularizer);\n    this.embeddingsConstraint = getConstraint(args.embeddingsConstraint);\n    this.maskZero = args.maskZero;\n    this.supportsMasking = args.maskZero;\n    this.inputLength = args.inputLength;\n  }\n\n  public build(inputShape: Shape|Shape[]): void {\n    this.embeddings = this.addWeight(\n        'embeddings', [this.inputDim, this.outputDim], this.dtype,\n        this.embeddingsInitializer, this.embeddingsRegularizer, true,\n        this.embeddingsConstraint);\n    this.built = true;\n  }\n\n  // Override warnOnIncompatibleInputShape because an embedding layer allows\n  // the input to have varying ranks.\n  protected warnOnIncompatibleInputShape(inputShape: Shape) {}\n\n  computeMask(inputs: Tensor|Tensor[], mask?: Tensor|Tensor[]): Tensor {\n    return tidy(() => {\n      if (!this.maskZero) {\n        return null;\n      } else {\n        inputs = getExactlyOneTensor(inputs);\n        return notEqual(inputs, zerosLike(inputs));\n      }\n    });\n  }\n\n  computeOutputShape(inputShape: Shape|Shape[]): Shape|Shape[] {\n    inputShape = getExactlyOneShape(inputShape);\n    if (this.inputLength == null) {\n      return [...inputShape, this.outputDim];\n    }\n    // inputLength can be an array if input is 3D or higher.\n    const inLens: number[] = generic_utils.toList(this.inputLength);\n    if (inLens.length !== inputShape.length - 1) {\n      throw new ValueError(\n          `\"inputLength\" is ${this.inputLength}, but received ` +\n          `input shape has shape ${inputShape}`);\n    } else {\n      let i = 0;\n      for (let k = 0; k < inLens.length; ++k) {\n        const s1 = inLens[k];\n        const s2 = inputShape[k + 1];\n        if ((s1 != null) && (s2 != null) && (s1 !== s2)) {\n          throw new ValueError(\n              `\"inputLength\" is ${this.inputLength}, but received ` +\n              `input shape has shape ${inputShape}`);\n        } else if (s1 == null) {\n          inLens[i] = s2;\n        }\n        i++;\n      }\n    }\n    return [inputShape[0], ...inLens, this.outputDim];\n  }\n\n  call(inputs: Tensor|Tensor[], kwargs: Kwargs): Tensor|Tensor[] {\n    return tidy(() => {\n      this.invokeCallHook(inputs, kwargs);\n      // Embedding layer accepts only a single input.\n      let input = getExactlyOneTensor(inputs);\n      if (input.dtype !== 'int32') {\n        input = K.cast(input, 'int32');\n      }\n      const output =\n          K.gather(this.embeddings.read(), reshape(input, [input.size]));\n      return reshape(\n          output, getExactlyOneShape(this.computeOutputShape(input.shape)));\n    });\n  }\n\n  getConfig(): serialization.ConfigDict {\n    const config = {\n      inputDim: this.inputDim,\n      outputDim: this.outputDim,\n      embeddingsInitializer: serializeInitializer(this.embeddingsInitializer),\n      embeddingsRegularizer: serializeRegularizer(this.embeddingsRegularizer),\n      activityRegularizer: serializeRegularizer(this.activityRegularizer),\n      embeddingsConstraint: serializeConstraint(this.embeddingsConstraint),\n      maskZero: this.maskZero,\n      inputLength: this.inputLength\n    };\n    const baseConfig = super.getConfig();\n    Object.assign(config, baseConfig);\n    return config;\n  }\n}\nserialization.registerClass(Embedding);\n"]},"metadata":{},"sourceType":"module"}