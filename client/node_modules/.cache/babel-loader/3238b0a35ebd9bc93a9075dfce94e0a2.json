{"ast":null,"code":"/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { Max } from '@tensorflow/tfjs-core';\nimport { backend_util } from '@tensorflow/tfjs-core';\nimport { util } from '@tensorflow/tfjs-core';\nimport { assertNotComplex } from '../cpu_util';\nimport { maxImpl } from './Max_impl';\nimport { transposeImpl } from './Transpose_impl';\nexport function max(args) {\n  const {\n    inputs,\n    backend,\n    attrs\n  } = args;\n  const {\n    x\n  } = inputs;\n  const {\n    reductionIndices,\n    keepDims\n  } = attrs;\n  const cpuBackend = backend;\n  let xShape = x.shape;\n  const xRank = xShape.length;\n  const origAxes = util.parseAxisParam(reductionIndices, xShape);\n  let axes = origAxes;\n  const permutedAxes = backend_util.getAxesPermutation(axes, xRank);\n  let xVals = cpuBackend.data.get(x.dataId).values;\n\n  if (permutedAxes != null) {\n    const newShape = new Array(xRank);\n\n    for (let i = 0; i < newShape.length; i++) {\n      newShape[i] = xShape[permutedAxes[i]];\n    }\n\n    xVals = transposeImpl(xVals, xShape, x.dtype, permutedAxes, newShape);\n    axes = backend_util.getInnerMostAxes(axes.length, xRank);\n    xShape = newShape;\n  }\n\n  assertNotComplex(x, 'max');\n  backend_util.assertAxesAreInnerMostDims('max', axes, xRank);\n  const [maxOutShape, reduceShape] = backend_util.computeOutAndReduceShapes(xShape, axes);\n  const reduceSize = util.sizeFromShape(reduceShape);\n  const result = maxImpl(xVals, reduceSize, maxOutShape, x.dtype);\n  const dataId = cpuBackend.write(result, maxOutShape, x.dtype);\n  let outShape = maxOutShape;\n\n  if (keepDims) {\n    // reshape\n    const newShape = backend_util.expandShapeToKeepDim(maxOutShape, origAxes);\n    outShape = newShape;\n  }\n\n  return {\n    dataId,\n    shape: outShape,\n    dtype: x.dtype\n  };\n}\nexport const maxConfig = {\n  kernelName: Max,\n  backendName: 'cpu',\n  kernelFunc: max\n};","map":{"version":3,"mappings":"AAAA;;;;;;;;;;;;;;;;AAiBA,SAAoBA,GAApB,QAA+D,uBAA/D;AACA,SAAQC,YAAR,QAAyC,uBAAzC;AACA,SAAoBC,IAApB,QAA+B,uBAA/B;AAGA,SAAQC,gBAAR,QAA+B,aAA/B;AAEA,SAAQC,OAAR,QAAsB,YAAtB;AACA,SAAQC,aAAR,QAA4B,kBAA5B;AAEA,OAAM,SAAUC,GAAV,CACFC,IADE,EACiE;AAErE,QAAM;AAACC,UAAD;AAASC,WAAT;AAAkBC;AAAlB,MAA2BH,IAAjC;AACA,QAAM;AAACI;AAAD,MAAMH,MAAZ;AACA,QAAM;AAACI,oBAAD;AAAmBC;AAAnB,MAA+BH,KAArC;AACA,QAAMI,UAAU,GAAGL,OAAnB;AACA,MAAIM,MAAM,GAAGJ,CAAC,CAACK,KAAf;AACA,QAAMC,KAAK,GAAGF,MAAM,CAACG,MAArB;AAEA,QAAMC,QAAQ,GAAGjB,IAAI,CAACkB,cAAL,CAAoBR,gBAApB,EAAsCG,MAAtC,CAAjB;AACA,MAAIM,IAAI,GAAGF,QAAX;AACA,QAAMG,YAAY,GAAGrB,YAAY,CAACsB,kBAAb,CAAgCF,IAAhC,EAAsCJ,KAAtC,CAArB;AACA,MAAIO,KAAK,GAAGV,UAAU,CAACW,IAAX,CAAgBC,GAAhB,CAAoBf,CAAC,CAACgB,MAAtB,EAA8BC,MAA1C;;AACA,MAAIN,YAAY,IAAI,IAApB,EAA0B;AACxB,UAAMO,QAAQ,GAAa,IAAIC,KAAJ,CAAUb,KAAV,CAA3B;;AACA,SAAK,IAAIc,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAGF,QAAQ,CAACX,MAA7B,EAAqCa,CAAC,EAAtC,EAA0C;AACxCF,cAAQ,CAACE,CAAD,CAAR,GAAchB,MAAM,CAACO,YAAY,CAACS,CAAD,CAAb,CAApB;AACD;;AAEDP,SAAK,GAAGnB,aAAa,CAACmB,KAAD,EAAQT,MAAR,EAAgBJ,CAAC,CAACqB,KAAlB,EAAyBV,YAAzB,EAAuCO,QAAvC,CAArB;AACAR,QAAI,GAAGpB,YAAY,CAACgC,gBAAb,CAA8BZ,IAAI,CAACH,MAAnC,EAA2CD,KAA3C,CAAP;AAEAF,UAAM,GAAGc,QAAT;AACD;;AAED1B,kBAAgB,CAACQ,CAAD,EAAI,KAAJ,CAAhB;AACAV,cAAY,CAACiC,0BAAb,CAAwC,KAAxC,EAA+Cb,IAA/C,EAAqDJ,KAArD;AACA,QAAM,CAACkB,WAAD,EAAcC,WAAd,IACFnC,YAAY,CAACoC,yBAAb,CAAuCtB,MAAvC,EAA+CM,IAA/C,CADJ;AAGA,QAAMiB,UAAU,GAAGpC,IAAI,CAACqC,aAAL,CAAmBH,WAAnB,CAAnB;AAEA,QAAMI,MAAM,GAAGpC,OAAO,CAACoB,KAAD,EAAQc,UAAR,EAAoBH,WAApB,EAAiCxB,CAAC,CAACqB,KAAnC,CAAtB;AACA,QAAML,MAAM,GAAGb,UAAU,CAAC2B,KAAX,CAAiBD,MAAjB,EAAyBL,WAAzB,EAAsCxB,CAAC,CAACqB,KAAxC,CAAf;AAEA,MAAIU,QAAQ,GAAGP,WAAf;;AACA,MAAItB,QAAJ,EAAc;AACZ;AACA,UAAMgB,QAAQ,GAAG5B,YAAY,CAAC0C,oBAAb,CAAkCR,WAAlC,EAA+ChB,QAA/C,CAAjB;AACAuB,YAAQ,GAAGb,QAAX;AACD;;AAED,SAAO;AAACF,UAAD;AAASX,SAAK,EAAE0B,QAAhB;AAA0BV,SAAK,EAAErB,CAAC,CAACqB;AAAnC,GAAP;AACD;AAED,OAAO,MAAMY,SAAS,GAAiB;AACrCC,YAAU,EAAE7C,GADyB;AAErC8C,aAAW,EAAE,KAFwB;AAGrCC,YAAU,EAAEzC;AAHyB,CAAhC","names":["Max","backend_util","util","assertNotComplex","maxImpl","transposeImpl","max","args","inputs","backend","attrs","x","reductionIndices","keepDims","cpuBackend","xShape","shape","xRank","length","origAxes","parseAxisParam","axes","permutedAxes","getAxesPermutation","xVals","data","get","dataId","values","newShape","Array","i","dtype","getInnerMostAxes","assertAxesAreInnerMostDims","maxOutShape","reduceShape","computeOutAndReduceShapes","reduceSize","sizeFromShape","result","write","outShape","expandShapeToKeepDim","maxConfig","kernelName","backendName","kernelFunc"],"sources":["/home/nadimakhtar97/smart-attendance-system/tfjs-backend-cpu/src/kernels/Max.ts"],"sourcesContent":["/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelFunc, Max, MaxAttrs, MaxInputs, TensorInfo} from '@tensorflow/tfjs-core';\nimport {backend_util, KernelConfig} from '@tensorflow/tfjs-core';\nimport {TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nimport {maxImpl} from './Max_impl';\nimport {transposeImpl} from './Transpose_impl';\n\nexport function max(\n    args: {inputs: MaxInputs, backend: MathBackendCPU, attrs: MaxAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {reductionIndices, keepDims} = attrs;\n  const cpuBackend = backend;\n  let xShape = x.shape;\n  const xRank = xShape.length;\n\n  const origAxes = util.parseAxisParam(reductionIndices, xShape);\n  let axes = origAxes;\n  const permutedAxes = backend_util.getAxesPermutation(axes, xRank);\n  let xVals = cpuBackend.data.get(x.dataId).values as TypedArray;\n  if (permutedAxes != null) {\n    const newShape: number[] = new Array(xRank);\n    for (let i = 0; i < newShape.length; i++) {\n      newShape[i] = xShape[permutedAxes[i]];\n    }\n\n    xVals = transposeImpl(xVals, xShape, x.dtype, permutedAxes, newShape);\n    axes = backend_util.getInnerMostAxes(axes.length, xRank);\n\n    xShape = newShape;\n  }\n\n  assertNotComplex(x, 'max');\n  backend_util.assertAxesAreInnerMostDims('max', axes, xRank);\n  const [maxOutShape, reduceShape] =\n      backend_util.computeOutAndReduceShapes(xShape, axes);\n\n  const reduceSize = util.sizeFromShape(reduceShape);\n\n  const result = maxImpl(xVals, reduceSize, maxOutShape, x.dtype);\n  const dataId = cpuBackend.write(result, maxOutShape, x.dtype);\n\n  let outShape = maxOutShape;\n  if (keepDims) {\n    // reshape\n    const newShape = backend_util.expandShapeToKeepDim(maxOutShape, origAxes);\n    outShape = newShape;\n  }\n\n  return {dataId, shape: outShape, dtype: x.dtype};\n}\n\nexport const maxConfig: KernelConfig = {\n  kernelName: Max,\n  backendName: 'cpu',\n  kernelFunc: max as {} as KernelFunc\n};\n"]},"metadata":{},"sourceType":"module"}