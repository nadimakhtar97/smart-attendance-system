{"ast":null,"code":"/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { util } from '@tensorflow/tfjs-core';\nimport { Im2ColPackedProgram } from '../im2col_packed_gpu';\nimport { mapActivationToShaderProgram } from '../kernel_utils/kernel_funcs_utils';\nimport { MatMulPackedProgram } from '../mulmat_packed_gpu';\nimport * as webgl_util from '../webgl_util';\nimport { batchMatMulImpl, MATMUL_SHARED_DIM_THRESHOLD } from './BatchMatMul_impl';\nimport { identity } from './Identity';\nimport { reshape } from './Reshape'; // For 1x1 kernels that iterate through every point in the input, convolution\n// can be expressed as matrix multiplication (without need for memory\n// remapping).\n\nexport function conv2dByMatMul(_ref) {\n  let {\n    x,\n    filter,\n    convInfo,\n    backend,\n    bias = null,\n    preluActivationWeights = null,\n    leakyreluAlpha = 0,\n    activation = null\n  } = _ref;\n  // Reshapes conv2D input to 2D tensors, uses matMul and then reshape the\n  // result from 2D to 4D.\n  const xShape = x.shape;\n  const xTexData = backend.texData.get(x.dataId);\n  const sharedMatMulDim = convInfo.inChannels;\n  const outerShapeX = xShape[0] * xShape[1] * xShape[2];\n  const outerShapeFilter = convInfo.outChannels;\n  const isChannelsLast = convInfo.dataFormat === 'channelsLast';\n  const transposeA = false;\n  const transposeB = false;\n  let out;\n  const intermediates = []; // TODO: Once reduction ops are packed, batchMatMul will always be packed\n  // and we can remove this condition.\n\n  const batchMatMulWillBeUnpacked = (outerShapeX === 1 || outerShapeFilter === 1) && sharedMatMulDim > MATMUL_SHARED_DIM_THRESHOLD; // The algorithm in the if condition assumes (1) the output will be packed,\n  // (2) x is packed, (3) x isChannelsLast, (4)  x's packed texture is already\n  // on GPU, (5) col is odd, (6) the width, height and inChannels are the same\n  // for xTexData.shape and xShape.\n\n  const canOptimize = !batchMatMulWillBeUnpacked && xTexData.isPacked && isChannelsLast && xTexData.texture != null && xShape[2] % 2 !== 0 && util.arraysEqual(xTexData.shape.slice(-3), xShape.slice(-3));\n\n  if (canOptimize) {\n    // We avoid expensive packed 2x2 reshape by padding col count to next,\n    // even number. When col is odd, the result of packed batchMatMul is\n    // the same (has the same texture layout and and values in the texture) as\n    // it is for next even col. We make the odd-cols tensor to look like\n    // even-cols tensor before the operation and, after the batchMatMul,\n    // fix the even-cols result to have odd number of cols.\n    const targetShape = xShape[0] * xShape[1] * (xShape[2] + 1);\n    const xReshaped = {\n      dataId: x.dataId,\n      shape: [1, targetShape, convInfo.inChannels],\n      dtype: x.dtype\n    }; // xTexData.shape gets referenced from GPGPUBinary.inShapeInfos.\n    // Decrementing col count, after batchMatMul->...->compileProgram leads to\n    // invalid col count within the reference in GPGPUBinary.inShapeInfos.\n    // Alternative fix would be to provide a copy to GPGPUBinary.inShapeInfos\n    // in compileProgram method, but that would affect compilation of all\n    // programs - instead, provide a copy here, with even col count, before\n    // calling batchMatMul->...->compileProgram and after that, the original\n    // xTexData.shape is restored.\n\n    const originalXTexDataShape = xTexData.shape;\n    xTexData.shape = xTexData.shape.slice();\n    xTexData.shape[xTexData.shape.length - 2]++;\n    util.assert(webgl_util.isReshapeFree(xTexData.shape, xReshaped.shape), () => `packed reshape ${xTexData.shape} to ${xReshaped.shape} isn't free`);\n    const filterReshaped = reshape({\n      inputs: {\n        x: filter\n      },\n      backend,\n      attrs: {\n        shape: [1, convInfo.inChannels, convInfo.outChannels]\n      }\n    });\n    intermediates.push(filterReshaped);\n    const pointwiseConv = batchMatMulImpl({\n      a: xReshaped,\n      b: filterReshaped,\n      backend,\n      transposeA,\n      transposeB,\n      bias,\n      activation,\n      preluActivationWeights,\n      leakyreluAlpha\n    });\n    const pointwiseConvTexData = backend.texData.get(pointwiseConv.dataId);\n    util.assert(pointwiseConvTexData.isPacked, () => 'batchMatMul result is expected to be packed'); // Restore the input shape to original.\n\n    xTexData.shape = originalXTexDataShape; // Set the output shape - there is no need for expensive reshape as data\n    // layout is already correct.\n\n    pointwiseConvTexData.shape = convInfo.outShape;\n    out = identity({\n      inputs: {\n        x: pointwiseConv\n      },\n      backend\n    });\n    out.shape = convInfo.outShape;\n    intermediates.push(pointwiseConv);\n  } else {\n    const targetShape = isChannelsLast ? xShape[0] * xShape[1] * xShape[2] : xShape[0] * xShape[2] * xShape[3];\n    const xReshaped = reshape({\n      inputs: {\n        x\n      },\n      backend,\n      attrs: {\n        shape: [1, targetShape, convInfo.inChannels]\n      }\n    });\n    const filterReshaped = reshape({\n      inputs: {\n        x: filter\n      },\n      backend,\n      attrs: {\n        shape: [1, convInfo.inChannels, convInfo.outChannels]\n      }\n    });\n    const result = batchMatMulImpl({\n      a: xReshaped,\n      b: filterReshaped,\n      transposeA,\n      transposeB,\n      backend,\n      bias,\n      activation,\n      preluActivationWeights,\n      leakyreluAlpha\n    });\n    out = reshape({\n      inputs: {\n        x: result\n      },\n      backend,\n      attrs: {\n        shape: convInfo.outShape\n      }\n    });\n    intermediates.push(xReshaped);\n    intermediates.push(filterReshaped);\n    intermediates.push(result);\n  }\n\n  for (const i of intermediates) {\n    backend.disposeIntermediateTensorInfo(i);\n  }\n\n  return out;\n} // Implements the im2row algorithm as outlined in \"High Performance\n// Convolutional Neural Networks for Document Processing\" (Suvisoft, 2006)\n\nexport function conv2dWithIm2Row(_ref2) {\n  let {\n    x,\n    filter,\n    convInfo,\n    backend,\n    bias = null,\n    preluActivationWeights = null,\n    leakyreluAlpha = 0,\n    activation = null\n  } = _ref2;\n  // Rearranges conv2d input so each block to be convolved over forms the\n  // column of a new matrix with shape [filterWidth * filterHeight *\n  // inChannels, outHeight * outWidth]. The filter is also rearranged so each\n  // output channel forms a row of a new matrix with shape [outChannels,\n  // filterWidth * filterHeight * inChannels]. The convolution is then\n  // computed by multiplying these matrices and reshaping the result.\n  const {\n    filterWidth,\n    filterHeight,\n    inChannels,\n    outWidth,\n    outHeight,\n    dataFormat\n  } = convInfo;\n  const isChannelsLast = dataFormat === 'channelsLast';\n  const sharedDim = filterWidth * filterHeight * inChannels;\n  const numCols = outHeight * outWidth;\n  const x2ColShape = [sharedDim, numCols];\n  const transposeA = true;\n  const transposeB = false;\n  const intermediates = [];\n  const xSqueezed = reshape({\n    inputs: {\n      x\n    },\n    backend,\n    attrs: {\n      shape: x.shape.slice(1)\n    }\n  });\n  const w2Row = reshape({\n    inputs: {\n      x: filter\n    },\n    backend,\n    attrs: {\n      shape: [1, sharedDim, util.sizeFromShape(filter.shape) / sharedDim]\n    }\n  });\n  intermediates.push(xSqueezed);\n  intermediates.push(w2Row);\n  const im2ColProgram = new Im2ColPackedProgram(x2ColShape, convInfo);\n  const customValues = [xSqueezed.shape, [convInfo.padInfo.top, convInfo.padInfo.left], [convInfo.strideHeight, convInfo.strideWidth], [convInfo.dilationHeight, convInfo.dilationWidth], [convInfo.inChannels], [convInfo.filterWidth * convInfo.inChannels], [convInfo.outWidth]];\n  const im2Col = backend.runWebGLProgram(im2ColProgram, [xSqueezed], 'float32', customValues);\n  const im2ColReshaped = reshape({\n    inputs: {\n      x: im2Col\n    },\n    backend,\n    attrs: {\n      shape: [1, x2ColShape[0], x2ColShape[1]]\n    }\n  });\n  intermediates.push(im2Col);\n  intermediates.push(im2ColReshaped);\n  const hasBias = bias != null;\n  const hasPreluActivationWeights = preluActivationWeights != null;\n  const hasLeakyreluAlpha = activation === 'leakyrelu';\n  const fusedActivation = activation ? mapActivationToShaderProgram(activation, true) : null;\n  const matmulProgram = new MatMulPackedProgram(im2ColReshaped.shape, w2Row.shape, [1, numCols, convInfo.outChannels], transposeA, transposeB, hasBias, fusedActivation, hasPreluActivationWeights, hasLeakyreluAlpha);\n  const inputs = [im2ColReshaped, w2Row];\n\n  if (bias) {\n    inputs.push(bias);\n  }\n\n  if (hasPreluActivationWeights) {\n    inputs.push(preluActivationWeights);\n  }\n\n  if (hasLeakyreluAlpha) {\n    const $leakyreluAlpha = backend.makeTensorInfo([], 'float32', util.createScalarValue(leakyreluAlpha, 'float32'));\n    inputs.push($leakyreluAlpha);\n    intermediates.push($leakyreluAlpha);\n  }\n\n  const product = backend.runWebGLProgram(matmulProgram, inputs, 'float32');\n  const outShape = isChannelsLast ? [1, outHeight, outWidth, convInfo.outChannels] : [1, convInfo.outChannels, outHeight, outWidth];\n  const out = reshape({\n    inputs: {\n      x: product\n    },\n    backend,\n    attrs: {\n      shape: outShape\n    }\n  });\n  intermediates.push(product);\n\n  for (const i of intermediates) {\n    backend.disposeIntermediateTensorInfo(i);\n  }\n\n  return out;\n}","map":{"version":3,"mappings":"AAAA;;;;;;;;;;;;;;;;AAiBA,SAAkCA,IAAlC,QAA6C,uBAA7C;AAGA,SAAQC,mBAAR,QAAkC,sBAAlC;AACA,SAAQC,4BAAR,QAA2C,oCAA3C;AACA,SAAQC,mBAAR,QAAkC,sBAAlC;AACA,OAAO,KAAKC,UAAZ,MAA4B,eAA5B;AAEA,SAAQC,eAAR,EAAyBC,2BAAzB,QAA2D,oBAA3D;AACA,SAAQC,QAAR,QAAuB,YAAvB;AACA,SAAQC,OAAR,QAAsB,WAAtB,C,CAaA;AACA;AACA;;AACA,OAAM,SAAUC,cAAV,OASS;AAAA,MATgB;AAC7BC,KAD6B;AAE7BC,UAF6B;AAG7BC,YAH6B;AAI7BC,WAJ6B;AAK7BC,QAAI,GAAG,IALsB;AAM7BC,0BAAsB,GAAG,IANI;AAO7BC,kBAAc,GAAG,CAPY;AAQ7BC,cAAU,GAAG;AARgB,GAShB;AACb;AACA;AACA,QAAMC,MAAM,GAAGR,CAAC,CAACS,KAAjB;AACA,QAAMC,QAAQ,GAAGP,OAAO,CAACQ,OAAR,CAAgBC,GAAhB,CAAoBZ,CAAC,CAACa,MAAtB,CAAjB;AACA,QAAMC,eAAe,GAAGZ,QAAQ,CAACa,UAAjC;AACA,QAAMC,WAAW,GAAGR,MAAM,CAAC,CAAD,CAAN,GAAYA,MAAM,CAAC,CAAD,CAAlB,GAAwBA,MAAM,CAAC,CAAD,CAAlD;AACA,QAAMS,gBAAgB,GAAGf,QAAQ,CAACgB,WAAlC;AACA,QAAMC,cAAc,GAAGjB,QAAQ,CAACkB,UAAT,KAAwB,cAA/C;AACA,QAAMC,UAAU,GAAG,KAAnB;AACA,QAAMC,UAAU,GAAG,KAAnB;AAEA,MAAIC,GAAJ;AACA,QAAMC,aAAa,GAAiB,EAApC,CAba,CAeb;AACA;;AACA,QAAMC,yBAAyB,GAC3B,CAACT,WAAW,KAAK,CAAhB,IAAqBC,gBAAgB,KAAK,CAA3C,KACAH,eAAe,GAAGlB,2BAFtB,CAjBa,CAqBb;AACA;AACA;AACA;;AACA,QAAM8B,WAAW,GAAG,CAACD,yBAAD,IAA8Bf,QAAQ,CAACiB,QAAvC,IAChBR,cADgB,IACET,QAAQ,CAACkB,OAAT,IAAoB,IADtB,IAC8BpB,MAAM,CAAC,CAAD,CAAN,GAAY,CAAZ,KAAkB,CADhD,IAEhBlB,IAAI,CAACuC,WAAL,CAAiBnB,QAAQ,CAACD,KAAT,CAAeqB,KAAf,CAAqB,CAAC,CAAtB,CAAjB,EAA2CtB,MAAM,CAACsB,KAAP,CAAa,CAAC,CAAd,CAA3C,CAFJ;;AAIA,MAAIJ,WAAJ,EAAiB;AACf;AACA;AACA;AACA;AACA;AACA;AACA,UAAMK,WAAW,GAAGvB,MAAM,CAAC,CAAD,CAAN,GAAYA,MAAM,CAAC,CAAD,CAAlB,IAAyBA,MAAM,CAAC,CAAD,CAAN,GAAY,CAArC,CAApB;AACA,UAAMwB,SAAS,GAAe;AAC5BnB,YAAM,EAAEb,CAAC,CAACa,MADkB;AAE5BJ,WAAK,EAAE,CAAC,CAAD,EAAIsB,WAAJ,EAAiB7B,QAAQ,CAACa,UAA1B,CAFqB;AAG5BkB,WAAK,EAAEjC,CAAC,CAACiC;AAHmB,KAA9B,CARe,CAaf;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AACA,UAAMC,qBAAqB,GAAGxB,QAAQ,CAACD,KAAvC;AACAC,YAAQ,CAACD,KAAT,GAAiBC,QAAQ,CAACD,KAAT,CAAeqB,KAAf,EAAjB;AACApB,YAAQ,CAACD,KAAT,CAAeC,QAAQ,CAACD,KAAT,CAAe0B,MAAf,GAAwB,CAAvC;AACA7C,QAAI,CAAC8C,MAAL,CACI1C,UAAU,CAAC2C,aAAX,CAAyB3B,QAAQ,CAACD,KAAlC,EAAyCuB,SAAS,CAACvB,KAAnD,CADJ,EAEI,MAAM,kBAAkBC,QAAQ,CAACD,KAAK,OAClCuB,SAAS,CAACvB,KAAK,aAHvB;AAIA,UAAM6B,cAAc,GAAGxC,OAAO,CAAC;AAC7ByC,YAAM,EAAE;AAACvC,SAAC,EAAEC;AAAJ,OADqB;AAE7BE,aAF6B;AAG7BqC,WAAK,EAAE;AAAC/B,aAAK,EAAE,CAAC,CAAD,EAAIP,QAAQ,CAACa,UAAb,EAAyBb,QAAQ,CAACgB,WAAlC;AAAR;AAHsB,KAAD,CAA9B;AAKAM,iBAAa,CAACiB,IAAd,CAAmBH,cAAnB;AACA,UAAMI,aAAa,GAAG/C,eAAe,CAAC;AACpCgD,OAAC,EAAEX,SADiC;AAEpCY,OAAC,EAAEN,cAFiC;AAGpCnC,aAHoC;AAIpCkB,gBAJoC;AAKpCC,gBALoC;AAMpClB,UANoC;AAOpCG,gBAPoC;AAQpCF,4BARoC;AASpCC;AAToC,KAAD,CAArC;AAYA,UAAMuC,oBAAoB,GAAG1C,OAAO,CAACQ,OAAR,CAAgBC,GAAhB,CAAoB8B,aAAa,CAAC7B,MAAlC,CAA7B;AACAvB,QAAI,CAAC8C,MAAL,CACIS,oBAAoB,CAAClB,QADzB,EAEI,MAAM,6CAFV,EA/Ce,CAkDf;;AACAjB,YAAQ,CAACD,KAAT,GAAiByB,qBAAjB,CAnDe,CAoDf;AACA;;AACAW,wBAAoB,CAACpC,KAArB,GAA6BP,QAAQ,CAAC4C,QAAtC;AAEAvB,OAAG,GAAG1B,QAAQ,CAAC;AAAC0C,YAAM,EAAE;AAACvC,SAAC,EAAE0C;AAAJ,OAAT;AAA6BvC;AAA7B,KAAD,CAAd;AACAoB,OAAG,CAACd,KAAJ,GAAYP,QAAQ,CAAC4C,QAArB;AAEAtB,iBAAa,CAACiB,IAAd,CAAmBC,aAAnB;AACD,GA5DD,MA4DO;AACL,UAAMX,WAAW,GAAGZ,cAAc,GAAGX,MAAM,CAAC,CAAD,CAAN,GAAYA,MAAM,CAAC,CAAD,CAAlB,GAAwBA,MAAM,CAAC,CAAD,CAAjC,GACGA,MAAM,CAAC,CAAD,CAAN,GAAYA,MAAM,CAAC,CAAD,CAAlB,GAAwBA,MAAM,CAAC,CAAD,CADnE;AAEA,UAAMwB,SAAS,GAAGlC,OAAO,CAAC;AACxByC,YAAM,EAAE;AAACvC;AAAD,OADgB;AAExBG,aAFwB;AAGxBqC,WAAK,EAAE;AAAC/B,aAAK,EAAE,CAAC,CAAD,EAAIsB,WAAJ,EAAiB7B,QAAQ,CAACa,UAA1B;AAAR;AAHiB,KAAD,CAAzB;AAKA,UAAMuB,cAAc,GAAGxC,OAAO,CAAC;AAC7ByC,YAAM,EAAE;AAACvC,SAAC,EAAEC;AAAJ,OADqB;AAE7BE,aAF6B;AAG7BqC,WAAK,EAAE;AAAC/B,aAAK,EAAE,CAAC,CAAD,EAAIP,QAAQ,CAACa,UAAb,EAAyBb,QAAQ,CAACgB,WAAlC;AAAR;AAHsB,KAAD,CAA9B;AAKA,UAAM6B,MAAM,GAAGpD,eAAe,CAAC;AAC7BgD,OAAC,EAAEX,SAD0B;AAE7BY,OAAC,EAAEN,cAF0B;AAG7BjB,gBAH6B;AAI7BC,gBAJ6B;AAK7BnB,aAL6B;AAM7BC,UAN6B;AAO7BG,gBAP6B;AAQ7BF,4BAR6B;AAS7BC;AAT6B,KAAD,CAA9B;AAYAiB,OAAG,GAAGzB,OAAO,CACT;AAACyC,YAAM,EAAE;AAACvC,SAAC,EAAE+C;AAAJ,OAAT;AAAsB5C,aAAtB;AAA+BqC,WAAK,EAAE;AAAC/B,aAAK,EAAEP,QAAQ,CAAC4C;AAAjB;AAAtC,KADS,CAAb;AAGAtB,iBAAa,CAACiB,IAAd,CAAmBT,SAAnB;AACAR,iBAAa,CAACiB,IAAd,CAAmBH,cAAnB;AACAd,iBAAa,CAACiB,IAAd,CAAmBM,MAAnB;AACD;;AAED,OAAK,MAAMC,CAAX,IAAgBxB,aAAhB,EAA+B;AAC7BrB,WAAO,CAAC8C,6BAAR,CAAsCD,CAAtC;AACD;;AAED,SAAOzB,GAAP;AACD,C,CAED;AACA;;AACA,OAAM,SAAU2B,gBAAV,QASS;AAAA,MATkB;AAC/BlD,KAD+B;AAE/BC,UAF+B;AAG/BC,YAH+B;AAI/BC,WAJ+B;AAK/BC,QAAI,GAAG,IALwB;AAM/BC,0BAAsB,GAAG,IANM;AAO/BC,kBAAc,GAAG,CAPc;AAQ/BC,cAAU,GAAG;AARkB,GASlB;AACb;AACA;AACA;AACA;AACA;AACA;AACA,QAAM;AACJ4C,eADI;AAEJC,gBAFI;AAGJrC,cAHI;AAIJsC,YAJI;AAKJC,aALI;AAMJlC;AANI,MAOFlB,QAPJ;AASA,QAAMiB,cAAc,GAAGC,UAAU,KAAK,cAAtC;AAEA,QAAMmC,SAAS,GAAGJ,WAAW,GAAGC,YAAd,GAA6BrC,UAA/C;AACA,QAAMyC,OAAO,GAAGF,SAAS,GAAGD,QAA5B;AACA,QAAMI,UAAU,GAAG,CAACF,SAAD,EAAYC,OAAZ,CAAnB;AACA,QAAMnC,UAAU,GAAG,IAAnB;AACA,QAAMC,UAAU,GAAG,KAAnB;AAEA,QAAME,aAAa,GAAiB,EAApC;AAEA,QAAMkC,SAAS,GACX5D,OAAO,CAAC;AAACyC,UAAM,EAAE;AAACvC;AAAD,KAAT;AAAcG,WAAd;AAAuBqC,SAAK,EAAE;AAAC/B,WAAK,EAAET,CAAC,CAACS,KAAF,CAAQqB,KAAR,CAAc,CAAd;AAAR;AAA9B,GAAD,CADX;AAEA,QAAM6B,KAAK,GAAG7D,OAAO,CAAC;AACpByC,UAAM,EAAE;AAACvC,OAAC,EAAEC;AAAJ,KADY;AAEpBE,WAFoB;AAGpBqC,SAAK,EAAE;AAAC/B,WAAK,EAAE,CAAC,CAAD,EAAI8C,SAAJ,EAAejE,IAAI,CAACsE,aAAL,CAAmB3D,MAAM,CAACQ,KAA1B,IAAmC8C,SAAlD;AAAR;AAHa,GAAD,CAArB;AAMA/B,eAAa,CAACiB,IAAd,CAAmBiB,SAAnB;AACAlC,eAAa,CAACiB,IAAd,CAAmBkB,KAAnB;AAEA,QAAME,aAAa,GAAG,IAAItE,mBAAJ,CAAwBkE,UAAxB,EAAoCvD,QAApC,CAAtB;AACA,QAAM4D,YAAY,GAAG,CACnBJ,SAAS,CAACjD,KADS,EACF,CAACP,QAAQ,CAAC6D,OAAT,CAAiBC,GAAlB,EAAuB9D,QAAQ,CAAC6D,OAAT,CAAiBE,IAAxC,CADE,EAEnB,CAAC/D,QAAQ,CAACgE,YAAV,EAAwBhE,QAAQ,CAACiE,WAAjC,CAFmB,EAGnB,CAACjE,QAAQ,CAACkE,cAAV,EAA0BlE,QAAQ,CAACmE,aAAnC,CAHmB,EAGgC,CAACnE,QAAQ,CAACa,UAAV,CAHhC,EAInB,CAACb,QAAQ,CAACiD,WAAT,GAAuBjD,QAAQ,CAACa,UAAjC,CAJmB,EAI2B,CAACb,QAAQ,CAACmD,QAAV,CAJ3B,CAArB;AAMA,QAAMiB,MAAM,GAAGnE,OAAO,CAACoE,eAAR,CACXV,aADW,EACI,CAACH,SAAD,CADJ,EACiB,SADjB,EAC4BI,YAD5B,CAAf;AAEA,QAAMU,cAAc,GAAG1E,OAAO,CAAC;AAC7ByC,UAAM,EAAE;AAACvC,OAAC,EAAEsE;AAAJ,KADqB;AAE7BnE,WAF6B;AAG7BqC,SAAK,EAAE;AAAC/B,WAAK,EAAE,CAAC,CAAD,EAAIgD,UAAU,CAAC,CAAD,CAAd,EAAmBA,UAAU,CAAC,CAAD,CAA7B;AAAR;AAHsB,GAAD,CAA9B;AAMAjC,eAAa,CAACiB,IAAd,CAAmB6B,MAAnB;AACA9C,eAAa,CAACiB,IAAd,CAAmB+B,cAAnB;AAEA,QAAMC,OAAO,GAAGrE,IAAI,IAAI,IAAxB;AACA,QAAMsE,yBAAyB,GAAGrE,sBAAsB,IAAI,IAA5D;AACA,QAAMsE,iBAAiB,GAAGpE,UAAU,KAAK,WAAzC;AACA,QAAMqE,eAAe,GACjBrE,UAAU,GAAGf,4BAA4B,CAACe,UAAD,EAAa,IAAb,CAA/B,GAAoD,IADlE;AAEA,QAAMsE,aAAa,GAAG,IAAIpF,mBAAJ,CAClB+E,cAAc,CAAC/D,KADG,EAElBkD,KAAK,CAAClD,KAFY,EAGlB,CAAC,CAAD,EAAI+C,OAAJ,EAAatD,QAAQ,CAACgB,WAAtB,CAHkB,EAGkBG,UAHlB,EAG8BC,UAH9B,EAG0CmD,OAH1C,EAIlBG,eAJkB,EAIDF,yBAJC,EAI0BC,iBAJ1B,CAAtB;AAKA,QAAMpC,MAAM,GAAiB,CAACiC,cAAD,EAAiBb,KAAjB,CAA7B;;AACA,MAAIvD,IAAJ,EAAU;AACRmC,UAAM,CAACE,IAAP,CAAYrC,IAAZ;AACD;;AACD,MAAIsE,yBAAJ,EAA+B;AAC7BnC,UAAM,CAACE,IAAP,CAAYpC,sBAAZ;AACD;;AACD,MAAIsE,iBAAJ,EAAuB;AACrB,UAAMG,eAAe,GAAG3E,OAAO,CAAC4E,cAAR,CACpB,EADoB,EAChB,SADgB,EAEpBzF,IAAI,CAAC0F,iBAAL,CAAuB1E,cAAvB,EAA0D,SAA1D,CAFoB,CAAxB;AAGAiC,UAAM,CAACE,IAAP,CAAYqC,eAAZ;AACAtD,iBAAa,CAACiB,IAAd,CAAmBqC,eAAnB;AACD;;AACD,QAAMG,OAAO,GAAG9E,OAAO,CAACoE,eAAR,CAAwBM,aAAxB,EAAuCtC,MAAvC,EAA+C,SAA/C,CAAhB;AAEA,QAAMO,QAAQ,GAAG3B,cAAc,GAC3B,CAAC,CAAD,EAAImC,SAAJ,EAAeD,QAAf,EAAyBnD,QAAQ,CAACgB,WAAlC,CAD2B,GAE3B,CAAC,CAAD,EAAIhB,QAAQ,CAACgB,WAAb,EAA0BoC,SAA1B,EAAqCD,QAArC,CAFJ;AAGA,QAAM9B,GAAG,GACLzB,OAAO,CAAC;AAACyC,UAAM,EAAE;AAACvC,OAAC,EAAEiF;AAAJ,KAAT;AAAuB9E,WAAvB;AAAgCqC,SAAK,EAAE;AAAC/B,WAAK,EAAEqC;AAAR;AAAvC,GAAD,CADX;AAGAtB,eAAa,CAACiB,IAAd,CAAmBwC,OAAnB;;AACA,OAAK,MAAMjC,CAAX,IAAgBxB,aAAhB,EAA+B;AAC7BrB,WAAO,CAAC8C,6BAAR,CAAsCD,CAAtC;AACD;;AAED,SAAOzB,GAAP;AACD","names":["util","Im2ColPackedProgram","mapActivationToShaderProgram","MatMulPackedProgram","webgl_util","batchMatMulImpl","MATMUL_SHARED_DIM_THRESHOLD","identity","reshape","conv2dByMatMul","x","filter","convInfo","backend","bias","preluActivationWeights","leakyreluAlpha","activation","xShape","shape","xTexData","texData","get","dataId","sharedMatMulDim","inChannels","outerShapeX","outerShapeFilter","outChannels","isChannelsLast","dataFormat","transposeA","transposeB","out","intermediates","batchMatMulWillBeUnpacked","canOptimize","isPacked","texture","arraysEqual","slice","targetShape","xReshaped","dtype","originalXTexDataShape","length","assert","isReshapeFree","filterReshaped","inputs","attrs","push","pointwiseConv","a","b","pointwiseConvTexData","outShape","result","i","disposeIntermediateTensorInfo","conv2dWithIm2Row","filterWidth","filterHeight","outWidth","outHeight","sharedDim","numCols","x2ColShape","xSqueezed","w2Row","sizeFromShape","im2ColProgram","customValues","padInfo","top","left","strideHeight","strideWidth","dilationHeight","dilationWidth","im2Col","runWebGLProgram","im2ColReshaped","hasBias","hasPreluActivationWeights","hasLeakyreluAlpha","fusedActivation","matmulProgram","$leakyreluAlpha","makeTensorInfo","createScalarValue","product"],"sources":["/home/nadimakhtar97/smart-attendance-system/tfjs-backend-webgl/src/kernels/Conv2D_impl.ts"],"sourcesContent":["/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendWebGL} from '../backend_webgl';\nimport {Im2ColPackedProgram} from '../im2col_packed_gpu';\nimport {mapActivationToShaderProgram} from '../kernel_utils/kernel_funcs_utils';\nimport {MatMulPackedProgram} from '../mulmat_packed_gpu';\nimport * as webgl_util from '../webgl_util';\n\nimport {batchMatMulImpl, MATMUL_SHARED_DIM_THRESHOLD} from './BatchMatMul_impl';\nimport {identity} from './Identity';\nimport {reshape} from './Reshape';\n\ntype Conv2DConfig = {\n  x: TensorInfo,\n  filter: TensorInfo,\n  convInfo: backend_util.Conv2DInfo,\n  backend: MathBackendWebGL,\n  bias?: TensorInfo,\n  preluActivationWeights?: TensorInfo,\n  leakyreluAlpha?: number,\n  activation?: backend_util.Activation\n};\n\n// For 1x1 kernels that iterate through every point in the input, convolution\n// can be expressed as matrix multiplication (without need for memory\n// remapping).\nexport function conv2dByMatMul({\n  x,\n  filter,\n  convInfo,\n  backend,\n  bias = null,\n  preluActivationWeights = null,\n  leakyreluAlpha = 0,\n  activation = null\n}: Conv2DConfig) {\n  // Reshapes conv2D input to 2D tensors, uses matMul and then reshape the\n  // result from 2D to 4D.\n  const xShape = x.shape;\n  const xTexData = backend.texData.get(x.dataId);\n  const sharedMatMulDim = convInfo.inChannels;\n  const outerShapeX = xShape[0] * xShape[1] * xShape[2];\n  const outerShapeFilter = convInfo.outChannels;\n  const isChannelsLast = convInfo.dataFormat === 'channelsLast';\n  const transposeA = false;\n  const transposeB = false;\n\n  let out: TensorInfo;\n  const intermediates: TensorInfo[] = [];\n\n  // TODO: Once reduction ops are packed, batchMatMul will always be packed\n  // and we can remove this condition.\n  const batchMatMulWillBeUnpacked =\n      (outerShapeX === 1 || outerShapeFilter === 1) &&\n      sharedMatMulDim > MATMUL_SHARED_DIM_THRESHOLD;\n\n  // The algorithm in the if condition assumes (1) the output will be packed,\n  // (2) x is packed, (3) x isChannelsLast, (4)  x's packed texture is already\n  // on GPU, (5) col is odd, (6) the width, height and inChannels are the same\n  // for xTexData.shape and xShape.\n  const canOptimize = !batchMatMulWillBeUnpacked && xTexData.isPacked &&\n      isChannelsLast && xTexData.texture != null && xShape[2] % 2 !== 0 &&\n      util.arraysEqual(xTexData.shape.slice(-3), xShape.slice(-3));\n\n  if (canOptimize) {\n    // We avoid expensive packed 2x2 reshape by padding col count to next,\n    // even number. When col is odd, the result of packed batchMatMul is\n    // the same (has the same texture layout and and values in the texture) as\n    // it is for next even col. We make the odd-cols tensor to look like\n    // even-cols tensor before the operation and, after the batchMatMul,\n    // fix the even-cols result to have odd number of cols.\n    const targetShape = xShape[0] * xShape[1] * (xShape[2] + 1);\n    const xReshaped: TensorInfo = {\n      dataId: x.dataId,\n      shape: [1, targetShape, convInfo.inChannels],\n      dtype: x.dtype\n    };\n    // xTexData.shape gets referenced from GPGPUBinary.inShapeInfos.\n    // Decrementing col count, after batchMatMul->...->compileProgram leads to\n    // invalid col count within the reference in GPGPUBinary.inShapeInfos.\n    // Alternative fix would be to provide a copy to GPGPUBinary.inShapeInfos\n    // in compileProgram method, but that would affect compilation of all\n    // programs - instead, provide a copy here, with even col count, before\n    // calling batchMatMul->...->compileProgram and after that, the original\n    // xTexData.shape is restored.\n    const originalXTexDataShape = xTexData.shape;\n    xTexData.shape = xTexData.shape.slice();\n    xTexData.shape[xTexData.shape.length - 2]++;\n    util.assert(\n        webgl_util.isReshapeFree(xTexData.shape, xReshaped.shape),\n        () => `packed reshape ${xTexData.shape} to ${\n            xReshaped.shape} isn't free`);\n    const filterReshaped = reshape({\n      inputs: {x: filter},\n      backend,\n      attrs: {shape: [1, convInfo.inChannels, convInfo.outChannels]}\n    });\n    intermediates.push(filterReshaped);\n    const pointwiseConv = batchMatMulImpl({\n      a: xReshaped,\n      b: filterReshaped,\n      backend,\n      transposeA,\n      transposeB,\n      bias,\n      activation,\n      preluActivationWeights,\n      leakyreluAlpha\n    });\n\n    const pointwiseConvTexData = backend.texData.get(pointwiseConv.dataId);\n    util.assert(\n        pointwiseConvTexData.isPacked,\n        () => 'batchMatMul result is expected to be packed');\n    // Restore the input shape to original.\n    xTexData.shape = originalXTexDataShape;\n    // Set the output shape - there is no need for expensive reshape as data\n    // layout is already correct.\n    pointwiseConvTexData.shape = convInfo.outShape;\n\n    out = identity({inputs: {x: pointwiseConv}, backend});\n    out.shape = convInfo.outShape;\n\n    intermediates.push(pointwiseConv);\n  } else {\n    const targetShape = isChannelsLast ? xShape[0] * xShape[1] * xShape[2] :\n                                         xShape[0] * xShape[2] * xShape[3];\n    const xReshaped = reshape({\n      inputs: {x},\n      backend,\n      attrs: {shape: [1, targetShape, convInfo.inChannels]}\n    });\n    const filterReshaped = reshape({\n      inputs: {x: filter},\n      backend,\n      attrs: {shape: [1, convInfo.inChannels, convInfo.outChannels]}\n    });\n    const result = batchMatMulImpl({\n      a: xReshaped,\n      b: filterReshaped,\n      transposeA,\n      transposeB,\n      backend,\n      bias,\n      activation,\n      preluActivationWeights,\n      leakyreluAlpha\n    });\n\n    out = reshape(\n        {inputs: {x: result}, backend, attrs: {shape: convInfo.outShape}});\n\n    intermediates.push(xReshaped);\n    intermediates.push(filterReshaped);\n    intermediates.push(result);\n  }\n\n  for (const i of intermediates) {\n    backend.disposeIntermediateTensorInfo(i);\n  }\n\n  return out;\n}\n\n// Implements the im2row algorithm as outlined in \"High Performance\n// Convolutional Neural Networks for Document Processing\" (Suvisoft, 2006)\nexport function conv2dWithIm2Row({\n  x,\n  filter,\n  convInfo,\n  backend,\n  bias = null,\n  preluActivationWeights = null,\n  leakyreluAlpha = 0,\n  activation = null\n}: Conv2DConfig) {\n  // Rearranges conv2d input so each block to be convolved over forms the\n  // column of a new matrix with shape [filterWidth * filterHeight *\n  // inChannels, outHeight * outWidth]. The filter is also rearranged so each\n  // output channel forms a row of a new matrix with shape [outChannels,\n  // filterWidth * filterHeight * inChannels]. The convolution is then\n  // computed by multiplying these matrices and reshaping the result.\n  const {\n    filterWidth,\n    filterHeight,\n    inChannels,\n    outWidth,\n    outHeight,\n    dataFormat\n  } = convInfo;\n\n  const isChannelsLast = dataFormat === 'channelsLast';\n\n  const sharedDim = filterWidth * filterHeight * inChannels;\n  const numCols = outHeight * outWidth;\n  const x2ColShape = [sharedDim, numCols];\n  const transposeA = true;\n  const transposeB = false;\n\n  const intermediates: TensorInfo[] = [];\n\n  const xSqueezed =\n      reshape({inputs: {x}, backend, attrs: {shape: x.shape.slice(1)}});\n  const w2Row = reshape({\n    inputs: {x: filter},\n    backend,\n    attrs: {shape: [1, sharedDim, util.sizeFromShape(filter.shape) / sharedDim]}\n  });\n\n  intermediates.push(xSqueezed);\n  intermediates.push(w2Row);\n\n  const im2ColProgram = new Im2ColPackedProgram(x2ColShape, convInfo);\n  const customValues = [\n    xSqueezed.shape, [convInfo.padInfo.top, convInfo.padInfo.left],\n    [convInfo.strideHeight, convInfo.strideWidth],\n    [convInfo.dilationHeight, convInfo.dilationWidth], [convInfo.inChannels],\n    [convInfo.filterWidth * convInfo.inChannels], [convInfo.outWidth]\n  ];\n  const im2Col = backend.runWebGLProgram(\n      im2ColProgram, [xSqueezed], 'float32', customValues);\n  const im2ColReshaped = reshape({\n    inputs: {x: im2Col},\n    backend,\n    attrs: {shape: [1, x2ColShape[0], x2ColShape[1]]}\n  });\n\n  intermediates.push(im2Col);\n  intermediates.push(im2ColReshaped);\n\n  const hasBias = bias != null;\n  const hasPreluActivationWeights = preluActivationWeights != null;\n  const hasLeakyreluAlpha = activation === 'leakyrelu';\n  const fusedActivation =\n      activation ? mapActivationToShaderProgram(activation, true) : null;\n  const matmulProgram = new MatMulPackedProgram(\n      im2ColReshaped.shape as [number, number, number],\n      w2Row.shape as [number, number, number],\n      [1, numCols, convInfo.outChannels], transposeA, transposeB, hasBias,\n      fusedActivation, hasPreluActivationWeights, hasLeakyreluAlpha);\n  const inputs: TensorInfo[] = [im2ColReshaped, w2Row];\n  if (bias) {\n    inputs.push(bias);\n  }\n  if (hasPreluActivationWeights) {\n    inputs.push(preluActivationWeights);\n  }\n  if (hasLeakyreluAlpha) {\n    const $leakyreluAlpha = backend.makeTensorInfo(\n        [], 'float32',\n        util.createScalarValue(leakyreluAlpha as {} as 'float32', 'float32'));\n    inputs.push($leakyreluAlpha);\n    intermediates.push($leakyreluAlpha);\n  }\n  const product = backend.runWebGLProgram(matmulProgram, inputs, 'float32');\n\n  const outShape = isChannelsLast ?\n      [1, outHeight, outWidth, convInfo.outChannels] :\n      [1, convInfo.outChannels, outHeight, outWidth];\n  const out =\n      reshape({inputs: {x: product}, backend, attrs: {shape: outShape}});\n\n  intermediates.push(product);\n  for (const i of intermediates) {\n    backend.disposeIntermediateTensorInfo(i);\n  }\n\n  return out;\n}\n"]},"metadata":{},"sourceType":"module"}