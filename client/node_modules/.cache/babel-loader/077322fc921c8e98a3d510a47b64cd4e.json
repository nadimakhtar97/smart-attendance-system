{"ast":null,"code":"/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { Max } from '@tensorflow/tfjs-core';\nimport { backend_util, util } from '@tensorflow/tfjs-core';\nimport { maxImplCPU } from '../kernel_utils/shared';\nimport { maxImpl } from './Max_impl';\nimport { transposeImpl, transposeImplCPU } from './Transpose_impl';\nexport function max(args) {\n  const {\n    inputs,\n    backend,\n    attrs\n  } = args;\n  const {\n    x\n  } = inputs;\n  const {\n    reductionIndices,\n    keepDims\n  } = attrs;\n  const xRank = x.shape.length;\n  const origAxes = util.parseAxisParam(reductionIndices, x.shape);\n  let axes = origAxes;\n  const permutedAxes = backend_util.getAxesPermutation(axes, xRank);\n  const maxInputIsTransposed = permutedAxes != null;\n  const shouldExecuteOnCPU = backend.shouldExecuteOnCPU([x]);\n  let maxInput = x;\n\n  if (maxInputIsTransposed) {\n    if (shouldExecuteOnCPU) {\n      const xTexData = backend.texData.get(maxInput.dataId);\n      const values = xTexData.values;\n      const newShape = new Array(xRank);\n\n      for (let i = 0; i < newShape.length; i++) {\n        newShape[i] = x.shape[permutedAxes[i]];\n      }\n\n      const maxInputValues = transposeImplCPU(values, x.shape, x.dtype, permutedAxes, newShape);\n      maxInput = backend.makeTensorInfo(newShape, x.dtype);\n      const maxInputData = backend.texData.get(maxInput.dataId);\n      maxInputData.values = maxInputValues;\n    } else {\n      maxInput = transposeImpl(x, permutedAxes, backend);\n    }\n\n    axes = backend_util.getInnerMostAxes(axes.length, xRank);\n  }\n\n  backend_util.assertAxesAreInnerMostDims('max', axes, xRank);\n  const [maxOutShape, reduceShape] = backend_util.computeOutAndReduceShapes(maxInput.shape, axes);\n  let outShape = maxOutShape;\n\n  if (keepDims) {\n    // rather than reshape at the end, set the target shape here.\n    outShape = backend_util.expandShapeToKeepDim(maxOutShape, origAxes);\n  }\n\n  let out;\n\n  if (shouldExecuteOnCPU) {\n    const xTexData = backend.texData.get(maxInput.dataId);\n    const values = xTexData.values;\n    const outValues = maxImplCPU(values, util.sizeFromShape(reduceShape), outShape, x.dtype);\n    out = backend.makeTensorInfo(outShape, x.dtype);\n    const outData = backend.texData.get(out.dataId);\n    outData.values = outValues;\n  } else {\n    out = maxImpl(maxInput, reduceShape, outShape, backend);\n  }\n\n  if (maxInputIsTransposed) {\n    backend.disposeIntermediateTensorInfo(maxInput);\n  }\n\n  return out;\n}\nexport const maxConfig = {\n  kernelName: Max,\n  backendName: 'webgl',\n  kernelFunc: max\n};","map":{"version":3,"mappings":"AAAA;;;;;;;;;;;;;;;;AAiBA,SAAoBA,GAApB,QAA+D,uBAA/D;AACA,SAAQC,YAAR,EAAgDC,IAAhD,QAA2D,uBAA3D;AAGA,SAAQC,UAAR,QAAyB,wBAAzB;AAEA,SAAQC,OAAR,QAAsB,YAAtB;AACA,SAAQC,aAAR,EAAuBC,gBAAvB,QAA8C,kBAA9C;AAEA,OAAM,SAAUC,GAAV,CACFC,IADE,EACmE;AAEvE,QAAM;AAACC,UAAD;AAASC,WAAT;AAAkBC;AAAlB,MAA2BH,IAAjC;AACA,QAAM;AAACI;AAAD,MAAMH,MAAZ;AACA,QAAM;AAACI,oBAAD;AAAmBC;AAAnB,MAA+BH,KAArC;AAEA,QAAMI,KAAK,GAAGH,CAAC,CAACI,KAAF,CAAQC,MAAtB;AAEA,QAAMC,QAAQ,GAAGhB,IAAI,CAACiB,cAAL,CAAoBN,gBAApB,EAAsCD,CAAC,CAACI,KAAxC,CAAjB;AACA,MAAII,IAAI,GAAGF,QAAX;AACA,QAAMG,YAAY,GAAGpB,YAAY,CAACqB,kBAAb,CAAgCF,IAAhC,EAAsCL,KAAtC,CAArB;AACA,QAAMQ,oBAAoB,GAAGF,YAAY,IAAI,IAA7C;AACA,QAAMG,kBAAkB,GAAGd,OAAO,CAACc,kBAAR,CAA2B,CAACZ,CAAD,CAA3B,CAA3B;AAEA,MAAIa,QAAQ,GAAGb,CAAf;;AACA,MAAIW,oBAAJ,EAA0B;AACxB,QAAIC,kBAAJ,EAAwB;AACtB,YAAME,QAAQ,GAAGhB,OAAO,CAACiB,OAAR,CAAgBC,GAAhB,CAAoBH,QAAQ,CAACI,MAA7B,CAAjB;AACA,YAAMC,MAAM,GAAGJ,QAAQ,CAACI,MAAxB;AAEA,YAAMC,QAAQ,GAAa,IAAIC,KAAJ,CAAUjB,KAAV,CAA3B;;AACA,WAAK,IAAIkB,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAGF,QAAQ,CAACd,MAA7B,EAAqCgB,CAAC,EAAtC,EAA0C;AACxCF,gBAAQ,CAACE,CAAD,CAAR,GAAcrB,CAAC,CAACI,KAAF,CAAQK,YAAY,CAACY,CAAD,CAApB,CAAd;AACD;;AACD,YAAMC,cAAc,GAChB5B,gBAAgB,CAACwB,MAAD,EAASlB,CAAC,CAACI,KAAX,EAAkBJ,CAAC,CAACuB,KAApB,EAA2Bd,YAA3B,EAAyCU,QAAzC,CADpB;AAGAN,cAAQ,GAAGf,OAAO,CAAC0B,cAAR,CAAuBL,QAAvB,EAAiCnB,CAAC,CAACuB,KAAnC,CAAX;AACA,YAAME,YAAY,GAAG3B,OAAO,CAACiB,OAAR,CAAgBC,GAAhB,CAAoBH,QAAQ,CAACI,MAA7B,CAArB;AACAQ,kBAAY,CAACP,MAAb,GAAsBI,cAAtB;AACD,KAdD,MAcO;AACLT,cAAQ,GAAGpB,aAAa,CAACO,CAAD,EAAIS,YAAJ,EAAkBX,OAAlB,CAAxB;AACD;;AAEDU,QAAI,GAAGnB,YAAY,CAACqC,gBAAb,CAA8BlB,IAAI,CAACH,MAAnC,EAA2CF,KAA3C,CAAP;AACD;;AAEDd,cAAY,CAACsC,0BAAb,CAAwC,KAAxC,EAA+CnB,IAA/C,EAAqDL,KAArD;AACA,QAAM,CAACyB,WAAD,EAAcC,WAAd,IACFxC,YAAY,CAACyC,yBAAb,CAAuCjB,QAAQ,CAACT,KAAhD,EAAuDI,IAAvD,CADJ;AAGA,MAAIuB,QAAQ,GAAGH,WAAf;;AACA,MAAI1B,QAAJ,EAAc;AACZ;AACA6B,YAAQ,GAAG1C,YAAY,CAAC2C,oBAAb,CAAkCJ,WAAlC,EAA+CtB,QAA/C,CAAX;AACD;;AAED,MAAI2B,GAAJ;;AACA,MAAIrB,kBAAJ,EAAwB;AACtB,UAAME,QAAQ,GAAGhB,OAAO,CAACiB,OAAR,CAAgBC,GAAhB,CAAoBH,QAAQ,CAACI,MAA7B,CAAjB;AACA,UAAMC,MAAM,GAAGJ,QAAQ,CAACI,MAAxB;AAEA,UAAMgB,SAAS,GACX3C,UAAU,CAAC2B,MAAD,EAAS5B,IAAI,CAAC6C,aAAL,CAAmBN,WAAnB,CAAT,EAA0CE,QAA1C,EAAoD/B,CAAC,CAACuB,KAAtD,CADd;AAGAU,OAAG,GAAGnC,OAAO,CAAC0B,cAAR,CAAuBO,QAAvB,EAAiC/B,CAAC,CAACuB,KAAnC,CAAN;AACA,UAAMa,OAAO,GAAGtC,OAAO,CAACiB,OAAR,CAAgBC,GAAhB,CAAoBiB,GAAG,CAAChB,MAAxB,CAAhB;AACAmB,WAAO,CAAClB,MAAR,GAAiBgB,SAAjB;AACD,GAVD,MAUO;AACLD,OAAG,GAAGzC,OAAO,CAACqB,QAAD,EAAWgB,WAAX,EAAwBE,QAAxB,EAAkCjC,OAAlC,CAAb;AACD;;AAED,MAAIa,oBAAJ,EAA0B;AACxBb,WAAO,CAACuC,6BAAR,CAAsCxB,QAAtC;AACD;;AAED,SAAOoB,GAAP;AACD;AAED,OAAO,MAAMK,SAAS,GAAiB;AACrCC,YAAU,EAAEnD,GADyB;AAErCoD,aAAW,EAAE,OAFwB;AAGrCC,YAAU,EAAE9C;AAHyB,CAAhC","names":["Max","backend_util","util","maxImplCPU","maxImpl","transposeImpl","transposeImplCPU","max","args","inputs","backend","attrs","x","reductionIndices","keepDims","xRank","shape","length","origAxes","parseAxisParam","axes","permutedAxes","getAxesPermutation","maxInputIsTransposed","shouldExecuteOnCPU","maxInput","xTexData","texData","get","dataId","values","newShape","Array","i","maxInputValues","dtype","makeTensorInfo","maxInputData","getInnerMostAxes","assertAxesAreInnerMostDims","maxOutShape","reduceShape","computeOutAndReduceShapes","outShape","expandShapeToKeepDim","out","outValues","sizeFromShape","outData","disposeIntermediateTensorInfo","maxConfig","kernelName","backendName","kernelFunc"],"sources":["/home/nadimakhtar97/smart-attendance-system/tfjs-backend-webgl/src/kernels/Max.ts"],"sourcesContent":["/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelFunc, Max, MaxAttrs, MaxInputs, TensorInfo} from '@tensorflow/tfjs-core';\nimport {backend_util, KernelConfig, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendWebGL} from '../backend_webgl';\nimport {maxImplCPU} from '../kernel_utils/shared';\n\nimport {maxImpl} from './Max_impl';\nimport {transposeImpl, transposeImplCPU} from './Transpose_impl';\n\nexport function max(\n    args: {inputs: MaxInputs, backend: MathBackendWebGL, attrs: MaxAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {reductionIndices, keepDims} = attrs;\n\n  const xRank = x.shape.length;\n\n  const origAxes = util.parseAxisParam(reductionIndices, x.shape);\n  let axes = origAxes;\n  const permutedAxes = backend_util.getAxesPermutation(axes, xRank);\n  const maxInputIsTransposed = permutedAxes != null;\n  const shouldExecuteOnCPU = backend.shouldExecuteOnCPU([x]);\n\n  let maxInput = x;\n  if (maxInputIsTransposed) {\n    if (shouldExecuteOnCPU) {\n      const xTexData = backend.texData.get(maxInput.dataId);\n      const values = xTexData.values as TypedArray;\n\n      const newShape: number[] = new Array(xRank);\n      for (let i = 0; i < newShape.length; i++) {\n        newShape[i] = x.shape[permutedAxes[i]];\n      }\n      const maxInputValues =\n          transposeImplCPU(values, x.shape, x.dtype, permutedAxes, newShape);\n\n      maxInput = backend.makeTensorInfo(newShape, x.dtype);\n      const maxInputData = backend.texData.get(maxInput.dataId);\n      maxInputData.values = maxInputValues;\n    } else {\n      maxInput = transposeImpl(x, permutedAxes, backend);\n    }\n\n    axes = backend_util.getInnerMostAxes(axes.length, xRank);\n  }\n\n  backend_util.assertAxesAreInnerMostDims('max', axes, xRank);\n  const [maxOutShape, reduceShape] =\n      backend_util.computeOutAndReduceShapes(maxInput.shape, axes);\n\n  let outShape = maxOutShape;\n  if (keepDims) {\n    // rather than reshape at the end, set the target shape here.\n    outShape = backend_util.expandShapeToKeepDim(maxOutShape, origAxes);\n  }\n\n  let out;\n  if (shouldExecuteOnCPU) {\n    const xTexData = backend.texData.get(maxInput.dataId);\n    const values = xTexData.values as TypedArray;\n\n    const outValues =\n        maxImplCPU(values, util.sizeFromShape(reduceShape), outShape, x.dtype);\n\n    out = backend.makeTensorInfo(outShape, x.dtype);\n    const outData = backend.texData.get(out.dataId);\n    outData.values = outValues;\n  } else {\n    out = maxImpl(maxInput, reduceShape, outShape, backend);\n  }\n\n  if (maxInputIsTransposed) {\n    backend.disposeIntermediateTensorInfo(maxInput);\n  }\n\n  return out;\n}\n\nexport const maxConfig: KernelConfig = {\n  kernelName: Max,\n  backendName: 'webgl',\n  kernelFunc: max as {} as KernelFunc\n};\n"]},"metadata":{},"sourceType":"module"}