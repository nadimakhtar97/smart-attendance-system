{"ast":null,"code":"/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { backend_util, Softmax, util } from '@tensorflow/tfjs-core';\nimport { exp } from './Exp';\nimport { max } from './Max';\nimport { realDiv } from './RealDiv';\nimport { reshape } from './Reshape';\nimport { sub } from './Sub';\nimport { sum } from './Sum';\nexport function softmax(args) {\n  const {\n    inputs,\n    backend,\n    attrs\n  } = args;\n  const {\n    logits\n  } = inputs;\n  const {\n    dim\n  } = attrs;\n  const axes = util.parseAxisParam([dim], logits.shape);\n  const maxLogit = max({\n    inputs: {\n      x: logits\n    },\n    backend,\n    attrs: {\n      reductionIndices: axes,\n      keepDims: false\n    }\n  });\n  const expandedShape = backend_util.expandShapeToKeepDim(maxLogit.shape, axes);\n  const maxLogitsReshaped = reshape({\n    inputs: {\n      x: maxLogit\n    },\n    backend,\n    attrs: {\n      shape: expandedShape\n    }\n  });\n  const a = sub({\n    inputs: {\n      a: logits,\n      b: maxLogitsReshaped\n    },\n    backend\n  });\n  const b = exp({\n    inputs: {\n      x: a\n    },\n    backend\n  });\n  const sumExp = sum({\n    inputs: {\n      x: b\n    },\n    backend,\n    attrs: {\n      axis: axes,\n      keepDims: false\n    }\n  });\n  const sumExpReshaped = reshape({\n    inputs: {\n      x: sumExp\n    },\n    backend,\n    attrs: {\n      shape: expandedShape\n    }\n  });\n  const res = realDiv({\n    inputs: {\n      a: b,\n      b: sumExpReshaped\n    },\n    backend\n  });\n  backend.disposeIntermediateTensorInfo(maxLogit);\n  backend.disposeIntermediateTensorInfo(maxLogitsReshaped);\n  backend.disposeIntermediateTensorInfo(a);\n  backend.disposeIntermediateTensorInfo(b);\n  backend.disposeIntermediateTensorInfo(sumExp);\n  backend.disposeIntermediateTensorInfo(sumExpReshaped);\n  return res;\n}\nexport const softmaxConfig = {\n  kernelName: Softmax,\n  backendName: 'webgl',\n  kernelFunc: softmax\n};","map":{"version":3,"mappings":"AAAA;;;;;;;;;;;;;;;;AAiBA,SAAQA,YAAR,EAAgDC,OAAhD,EAAkGC,IAAlG,QAA6G,uBAA7G;AAIA,SAAQC,GAAR,QAAkB,OAAlB;AACA,SAAQC,GAAR,QAAkB,OAAlB;AACA,SAAQC,OAAR,QAAsB,WAAtB;AACA,SAAQC,OAAR,QAAsB,WAAtB;AACA,SAAQC,GAAR,QAAkB,OAAlB;AACA,SAAQC,GAAR,QAAkB,OAAlB;AAEA,OAAM,SAAUC,OAAV,CAAkBC,IAAlB,EAIL;AACC,QAAM;AAACC,UAAD;AAASC,WAAT;AAAkBC;AAAlB,MAA2BH,IAAjC;AACA,QAAM;AAACI;AAAD,MAAWH,MAAjB;AACA,QAAM;AAACI;AAAD,MAAQF,KAAd;AAEA,QAAMG,IAAI,GAAGd,IAAI,CAACe,cAAL,CAAoB,CAACF,GAAD,CAApB,EAA2BD,MAAM,CAACI,KAAlC,CAAb;AAEA,QAAMC,QAAQ,GAAGf,GAAG,CAAC;AACnBO,UAAM,EAAE;AAACS,OAAC,EAAEN;AAAJ,KADW;AAEnBF,WAFmB;AAGnBC,SAAK,EAAE;AAACQ,sBAAgB,EAAEL,IAAnB;AAAyBM,cAAQ,EAAE;AAAnC;AAHY,GAAD,CAApB;AAMA,QAAMC,aAAa,GAAGvB,YAAY,CAACwB,oBAAb,CAAkCL,QAAQ,CAACD,KAA3C,EAAkDF,IAAlD,CAAtB;AAEA,QAAMS,iBAAiB,GACnBnB,OAAO,CAAC;AAACK,UAAM,EAAE;AAACS,OAAC,EAAED;AAAJ,KAAT;AAAwBP,WAAxB;AAAiCC,SAAK,EAAE;AAACK,WAAK,EAAEK;AAAR;AAAxC,GAAD,CADX;AAEA,QAAMG,CAAC,GACHnB,GAAG,CAAC;AAACI,UAAM,EAAE;AAACe,OAAC,EAAEZ,MAAJ;AAAYa,OAAC,EAAEF;AAAf,KAAT;AAA4Cb;AAA5C,GAAD,CADP;AAEA,QAAMe,CAAC,GAAGxB,GAAG,CAAC;AAACQ,UAAM,EAAE;AAACS,OAAC,EAAEM;AAAJ,KAAT;AAAiBd;AAAjB,GAAD,CAAb;AACA,QAAMgB,MAAM,GACRpB,GAAG,CAAC;AAACG,UAAM,EAAE;AAACS,OAAC,EAAEO;AAAJ,KAAT;AAAiBf,WAAjB;AAA0BC,SAAK,EAAE;AAACgB,UAAI,EAAEb,IAAP;AAAaM,cAAQ,EAAE;AAAvB;AAAjC,GAAD,CADP;AAEA,QAAMQ,cAAc,GAChBxB,OAAO,CAAC;AAACK,UAAM,EAAE;AAACS,OAAC,EAAEQ;AAAJ,KAAT;AAAsBhB,WAAtB;AAA+BC,SAAK,EAAE;AAACK,WAAK,EAAEK;AAAR;AAAtC,GAAD,CADX;AAGA,QAAMQ,GAAG,GACL1B,OAAO,CAAC;AAACM,UAAM,EAAE;AAACe,OAAC,EAAEC,CAAJ;AAAOA,OAAC,EAAEG;AAAV,KAAT;AAAoClB;AAApC,GAAD,CADX;AAGAA,SAAO,CAACoB,6BAAR,CAAsCb,QAAtC;AACAP,SAAO,CAACoB,6BAAR,CAAsCP,iBAAtC;AACAb,SAAO,CAACoB,6BAAR,CAAsCN,CAAtC;AACAd,SAAO,CAACoB,6BAAR,CAAsCL,CAAtC;AACAf,SAAO,CAACoB,6BAAR,CAAsCJ,MAAtC;AACAhB,SAAO,CAACoB,6BAAR,CAAsCF,cAAtC;AAEA,SAAOC,GAAP;AACD;AAED,OAAO,MAAME,aAAa,GAAiB;AACzCC,YAAU,EAAEjC,OAD6B;AAEzCkC,aAAW,EAAE,OAF4B;AAGzCC,YAAU,EAAE3B;AAH6B,CAApC","names":["backend_util","Softmax","util","exp","max","realDiv","reshape","sub","sum","softmax","args","inputs","backend","attrs","logits","dim","axes","parseAxisParam","shape","maxLogit","x","reductionIndices","keepDims","expandedShape","expandShapeToKeepDim","maxLogitsReshaped","a","b","sumExp","axis","sumExpReshaped","res","disposeIntermediateTensorInfo","softmaxConfig","kernelName","backendName","kernelFunc"],"sources":["/home/nadimakhtar97/smart-attendance-system/tfjs-backend-webgl/src/kernels/Softmax.ts"],"sourcesContent":["/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, KernelConfig, KernelFunc, Softmax, SoftmaxAttrs, SoftmaxInputs, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendWebGL} from '../backend_webgl';\n\nimport {exp} from './Exp';\nimport {max} from './Max';\nimport {realDiv} from './RealDiv';\nimport {reshape} from './Reshape';\nimport {sub} from './Sub';\nimport {sum} from './Sum';\n\nexport function softmax(args: {\n  inputs: SoftmaxInputs,\n  backend: MathBackendWebGL,\n  attrs: SoftmaxAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {logits} = inputs;\n  const {dim} = attrs;\n\n  const axes = util.parseAxisParam([dim], logits.shape);\n\n  const maxLogit = max({\n    inputs: {x: logits},\n    backend,\n    attrs: {reductionIndices: axes, keepDims: false}\n  });\n\n  const expandedShape = backend_util.expandShapeToKeepDim(maxLogit.shape, axes);\n\n  const maxLogitsReshaped =\n      reshape({inputs: {x: maxLogit}, backend, attrs: {shape: expandedShape}});\n  const a =\n      sub({inputs: {a: logits, b: maxLogitsReshaped}, backend}) as TensorInfo;\n  const b = exp({inputs: {x: a}, backend}) as TensorInfo;\n  const sumExp =\n      sum({inputs: {x: b}, backend, attrs: {axis: axes, keepDims: false}});\n  const sumExpReshaped =\n      reshape({inputs: {x: sumExp}, backend, attrs: {shape: expandedShape}});\n\n  const res =\n      realDiv({inputs: {a: b, b: sumExpReshaped}, backend}) as TensorInfo;\n\n  backend.disposeIntermediateTensorInfo(maxLogit);\n  backend.disposeIntermediateTensorInfo(maxLogitsReshaped);\n  backend.disposeIntermediateTensorInfo(a);\n  backend.disposeIntermediateTensorInfo(b);\n  backend.disposeIntermediateTensorInfo(sumExp);\n  backend.disposeIntermediateTensorInfo(sumExpReshaped);\n\n  return res;\n}\n\nexport const softmaxConfig: KernelConfig = {\n  kernelName: Softmax,\n  backendName: 'webgl',\n  kernelFunc: softmax as {} as KernelFunc\n};\n"]},"metadata":{},"sourceType":"module"}