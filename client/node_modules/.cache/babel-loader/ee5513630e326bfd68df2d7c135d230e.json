{"ast":null,"code":"/**\n * @license\n * Copyright 2018 Google LLC\n *\n * Use of this source code is governed by an MIT-style\n * license that can be found in the LICENSE file or at\n * https://opensource.org/licenses/MIT.\n * =============================================================================\n */\nimport { argMax, clone, dispose, mul, reshape, tensor1d, tidy } from '@tensorflow/tfjs-core';\n\nfunction standardizeSampleOrClassWeights(xWeight, outputNames, weightType) {\n  const numOutputs = outputNames.length;\n\n  if (xWeight == null || Array.isArray(xWeight) && xWeight.length === 0) {\n    return outputNames.map(name => null);\n  }\n\n  if (numOutputs === 1) {\n    if (Array.isArray(xWeight) && xWeight.length === 1) {\n      return xWeight;\n    } else if (typeof xWeight === 'object' && outputNames[0] in xWeight) {\n      return [xWeight[outputNames[0]]];\n    } else {\n      return [xWeight];\n    }\n  }\n\n  if (Array.isArray(xWeight)) {\n    if (xWeight.length !== numOutputs) {\n      throw new Error(`Provided ${weightType} is an array of ${xWeight.length} ` + `element(s), but the model has ${numOutputs} outputs. ` + `Make sure a set of weights is provided for each model output.`);\n    }\n\n    return xWeight;\n  } else if (typeof xWeight === 'object' && Object.keys(xWeight).length > 0 && typeof xWeight[Object.keys(xWeight)[0]] === 'object') {\n    const output = [];\n    outputNames.forEach(outputName => {\n      if (outputName in xWeight) {\n        output.push(xWeight[outputName]);\n      } else {\n        output.push(null);\n      }\n    });\n    return output;\n  } else {\n    throw new Error(`The model has multiple (${numOutputs}) outputs, ` + `so ${weightType} must be either an array with ` + `${numOutputs} elements or an object with ${outputNames} keys. ` + `Provided ${weightType} not understood: ${JSON.stringify(xWeight)}`);\n  }\n}\n/**\n * Standardize class weighting objects.\n *\n * This function takes a single class-weighting object, an array of them,\n * or a map from output name to class-weighting object. It compares it to the\n * output name(s) of the model, base on which it outputs an array of\n * class-weighting objects of which the length matches the number of outputs.\n *\n * @param classWeight Input class-weighting object(s).\n * @param outputNames All output name(s) of the model.\n * @return An array of class-weighting objects. The length of the array matches\n *   the model's number of outputs.\n */\n\n\nexport function standardizeClassWeights(classWeight, outputNames) {\n  return standardizeSampleOrClassWeights(classWeight, outputNames, 'classWeight');\n}\nexport function standardizeSampleWeights(classWeight, outputNames) {\n  return standardizeSampleOrClassWeights(classWeight, outputNames, 'sampleWeight');\n}\n/**\n * Standardize by-sample and/or by-class weights for training.\n *\n * Note that this function operates on one model output at a time. For a model\n * with multiple outputs, you must call this function multiple times.\n *\n * @param y The target tensor that the by-sample and/or by-class weight is for.\n *     The values of y are assumed to encode the classes, either directly\n *     as an integer index, or as one-hot encoding.\n * @param sampleWeight By-sample weights.\n * @param classWeight By-class weights: an object mapping class indices\n *     (integers) to a weight (float) to apply to the model's loss for the\n *     samples from this class during training. This can be useful to tell the\n *     model to \"pay more attention\" to samples from an under-represented class.\n * @param sampleWeightMode The mode for the sample weights.\n * @return A Promise of weight tensor, of which the size of the first dimension\n *     matches that of `y`.\n */\n\nexport async function standardizeWeights(y, sampleWeight, classWeight, sampleWeightMode) {\n  if (sampleWeight != null || sampleWeightMode != null) {\n    // TODO(cais): Once 'temporal' mode is implemented, document it in the doc\n    // string.\n    throw new Error('Support sampleWeight is not implemented yet');\n  }\n\n  if (classWeight != null) {\n    // Apply class weights per sample.\n    const yClasses = tidy(() => {\n      if (y.shape.length === 1) {\n        // Assume class indices.\n        return clone(y);\n      } else if (y.shape.length === 2) {\n        if (y.shape[1] > 1) {\n          // Assume one-hot encoding of classes.\n          const axis = 1;\n          return argMax(y, axis);\n        } else if (y.shape[1] === 1) {\n          // Class index.\n          return reshape(y, [y.shape[0]]);\n        } else {\n          throw new Error(`Encountered unexpected last-dimension size (${y.shape[1]}) ` + `during handling of class weights. The size is expected to be ` + `>= 1.`);\n        }\n      } else {\n        throw new Error(`Unexpected rank of target (y) tensor (${y.rank}) during ` + `handling of class weights. The rank is expected to be 1 or 2.`);\n      }\n    });\n    const yClassIndices = Array.from(await yClasses.data());\n    dispose(yClasses);\n    const classSampleWeight = [];\n    yClassIndices.forEach(classIndex => {\n      if (classWeight[classIndex] == null) {\n        throw new Error(`classWeight must contain all classes in the training data. ` + `The class ${classIndex} exists in the data but not in ` + `classWeight`);\n      } else {\n        classSampleWeight.push(classWeight[classIndex]);\n      }\n    });\n    return tensor1d(classSampleWeight, 'float32');\n  } else {\n    return null;\n  }\n}\n/**\n * Apply per-sample weights on the loss values from a number of samples.\n *\n * @param losses Loss tensor of shape `[batchSize]`.\n * @param sampleWeights Per-sample weight tensor of shape `[batchSize]`.\n * @returns Tensor of the same shape as`losses`.\n */\n\nexport function computeWeightedLoss(losses, sampleWeights) {\n  return mul(losses, sampleWeights);\n}","map":{"version":3,"mappings":"AAAA;;;;;;;;;AAUA,SAAQA,MAAR,EAAgBC,KAAhB,EAAuBC,OAAvB,EAAgCC,GAAhC,EAAqCC,OAArC,EAAgEC,QAAhE,EAA0EC,IAA1E,QAAqF,uBAArF;;AAuBA,SAASC,+BAAT,CACIC,OADJ,EACuDC,WADvD,EAEIC,UAFJ,EAE4C;AAC1C,QAAMC,UAAU,GAAGF,WAAW,CAACG,MAA/B;;AACA,MAAIJ,OAAO,IAAI,IAAX,IAAoBK,KAAK,CAACC,OAAN,CAAcN,OAAd,KAA0BA,OAAO,CAACI,MAAR,KAAmB,CAArE,EAAyE;AACvE,WAAOH,WAAW,CAACM,GAAZ,CAAgBC,IAAI,IAAI,IAAxB,CAAP;AACD;;AACD,MAAIL,UAAU,KAAK,CAAnB,EAAsB;AACpB,QAAIE,KAAK,CAACC,OAAN,CAAcN,OAAd,KAA0BA,OAAO,CAACI,MAAR,KAAmB,CAAjD,EAAoD;AAClD,aAAOJ,OAAP;AACD,KAFD,MAEO,IAAI,OAAOA,OAAP,KAAmB,QAAnB,IAA+BC,WAAW,CAAC,CAAD,CAAX,IAAkBD,OAArD,EAA8D;AACnE,aAAO,CAAEA,OAA0B,CAACC,WAAW,CAAC,CAAD,CAAZ,CAA5B,CAAP;AACD,KAFM,MAEA;AACL,aAAO,CAACD,OAAD,CAAP;AACD;AACF;;AACD,MAAIK,KAAK,CAACC,OAAN,CAAcN,OAAd,CAAJ,EAA4B;AAC1B,QAAIA,OAAO,CAACI,MAAR,KAAmBD,UAAvB,EAAmC;AACjC,YAAM,IAAIM,KAAJ,CACF,YAAYP,UAAU,mBAAmBF,OAAO,CAACI,MAAM,GAAvD,GACA,iCAAiCD,UAAU,YAD3C,GAEA,+DAHE,CAAN;AAID;;AACD,WAAOH,OAAP;AACD,GARD,MAQO,IACH,OAAOA,OAAP,KAAmB,QAAnB,IAA+BU,MAAM,CAACC,IAAP,CAAYX,OAAZ,EAAqBI,MAArB,GAA8B,CAA7D,IACA,OAAQJ,OAA0B,CAACU,MAAM,CAACC,IAAP,CAAYX,OAAZ,EAAqB,CAArB,CAAD,CAAlC,KACI,QAHD,EAGW;AAChB,UAAMY,MAAM,GAAkB,EAA9B;AACAX,eAAW,CAACY,OAAZ,CAAoBC,UAAU,IAAG;AAC/B,UAAIA,UAAU,IAAId,OAAlB,EAA2B;AACzBY,cAAM,CAACG,IAAP,CAAaf,OAA0B,CAACc,UAAD,CAAvC;AACD,OAFD,MAEO;AACLF,cAAM,CAACG,IAAP,CAAY,IAAZ;AACD;AACF,KAND;AAOA,WAAOH,MAAP;AACD,GAbM,MAaA;AACL,UAAM,IAAIH,KAAJ,CACF,2BAA2BN,UAAU,aAArC,GACA,MAAMD,UAAU,gCADhB,GAEA,GAAGC,UAAU,+BAA+BF,WAAW,SAFvD,GAGA,YAAYC,UAAU,oBAAoBc,IAAI,CAACC,SAAL,CAAejB,OAAf,CAAuB,EAJ/D,CAAN;AAKD;AACF;AAED;;;;;;;;;;;;;;;AAaA,OAAM,SAAUkB,uBAAV,CACFC,WADE,EAEFlB,WAFE,EAEmB;AACvB,SAAOF,+BAA+B,CAClCoB,WADkC,EACrBlB,WADqB,EACR,aADQ,CAAtC;AAED;AAED,OAAM,SAAUmB,wBAAV,CACFD,WADE,EAEFlB,WAFE,EAEmB;AACvB,SAAOF,+BAA+B,CAClCoB,WADkC,EACrBlB,WADqB,EACR,cADQ,CAAtC;AAED;AAED;;;;;;;;;;;;;;;;;;;AAkBA,OAAO,eAAeoB,kBAAf,CACHC,CADG,EACQC,YADR,EAC+BJ,WAD/B,EAEHK,gBAFG,EAE0B;AAC/B,MAAID,YAAY,IAAI,IAAhB,IAAwBC,gBAAgB,IAAI,IAAhD,EAAsD;AACpD;AACA;AACA,UAAM,IAAIf,KAAJ,CAAU,6CAAV,CAAN;AACD;;AAED,MAAIU,WAAW,IAAI,IAAnB,EAAyB;AACvB;AACA,UAAMM,QAAQ,GAAa3B,IAAI,CAAC,MAAK;AACnC,UAAIwB,CAAC,CAACI,KAAF,CAAQtB,MAAR,KAAmB,CAAvB,EAA0B;AACxB;AACA,eAAOX,KAAK,CAAC6B,CAAD,CAAZ;AACD,OAHD,MAGO,IAAIA,CAAC,CAACI,KAAF,CAAQtB,MAAR,KAAmB,CAAvB,EAA0B;AAC/B,YAAIkB,CAAC,CAACI,KAAF,CAAQ,CAAR,IAAa,CAAjB,EAAoB;AAClB;AACA,gBAAMC,IAAI,GAAG,CAAb;AACA,iBAAOnC,MAAM,CAAC8B,CAAD,EAAIK,IAAJ,CAAb;AACD,SAJD,MAIO,IAAIL,CAAC,CAACI,KAAF,CAAQ,CAAR,MAAe,CAAnB,EAAsB;AAC3B;AACA,iBAAO9B,OAAO,CAAC0B,CAAD,EAAI,CAACA,CAAC,CAACI,KAAF,CAAQ,CAAR,CAAD,CAAJ,CAAd;AACD,SAHM,MAGA;AACL,gBAAM,IAAIjB,KAAJ,CACF,+CAA+Ca,CAAC,CAACI,KAAF,CAAQ,CAAR,CAAU,IAAzD,GACA,+DADA,GAEA,OAHE,CAAN;AAID;AACF,OAdM,MAcA;AACL,cAAM,IAAIjB,KAAJ,CACF,yCAAyCa,CAAC,CAACM,IAAI,WAA/C,GACA,+DAFE,CAAN;AAGD;AACF,KAvB8B,CAA/B;AAyBA,UAAMC,aAAa,GAAGxB,KAAK,CAACyB,IAAN,CAAW,MAAML,QAAQ,CAACM,IAAT,EAAjB,CAAtB;AACArC,WAAO,CAAC+B,QAAD,CAAP;AACA,UAAMO,iBAAiB,GAAa,EAApC;AACAH,iBAAa,CAAChB,OAAd,CAAsBoB,UAAU,IAAG;AACjC,UAAId,WAAW,CAACc,UAAD,CAAX,IAA2B,IAA/B,EAAqC;AACnC,cAAM,IAAIxB,KAAJ,CACF,gEACA,aAAawB,UAAU,iCADvB,GAEA,aAHE,CAAN;AAID,OALD,MAKO;AACLD,yBAAiB,CAACjB,IAAlB,CAAuBI,WAAW,CAACc,UAAD,CAAlC;AACD;AACF,KATD;AAWA,WAAOpC,QAAQ,CAACmC,iBAAD,EAAoB,SAApB,CAAf;AACD,GA1CD,MA0CO;AACL,WAAO,IAAP;AACD;AACF;AAED;;;;;;;;AAOA,OAAM,SAAUE,mBAAV,CAA8BC,MAA9B,EAA8CC,aAA9C,EAAmE;AACvE,SAAOzC,GAAG,CAACwC,MAAD,EAASC,aAAT,CAAV;AACD","names":["argMax","clone","dispose","mul","reshape","tensor1d","tidy","standardizeSampleOrClassWeights","xWeight","outputNames","weightType","numOutputs","length","Array","isArray","map","name","Error","Object","keys","output","forEach","outputName","push","JSON","stringify","standardizeClassWeights","classWeight","standardizeSampleWeights","standardizeWeights","y","sampleWeight","sampleWeightMode","yClasses","shape","axis","rank","yClassIndices","from","data","classSampleWeight","classIndex","computeWeightedLoss","losses","sampleWeights"],"sources":["/home/nadimakhtar97/smart-attendance-system/tfjs-layers/src/engine/training_utils.ts"],"sourcesContent":["/**\n * @license\n * Copyright 2018 Google LLC\n *\n * Use of this source code is governed by an MIT-style\n * license that can be found in the LICENSE file or at\n * https://opensource.org/licenses/MIT.\n * =============================================================================\n */\n\nimport {argMax, clone, dispose, mul, reshape, Tensor, Tensor1D, tensor1d, tidy} from '@tensorflow/tfjs-core';\n\n/**\n * For multi-class classification problems, this object is designed to store a\n * mapping from class index to the \"weight\" of the class, where higher weighted\n * classes have larger impact on loss, accuracy, and other metrics.\n *\n * This is useful for cases in which you want the model to \"pay more attention\"\n * to examples from an under-represented class, e.g., in unbalanced datasets.\n */\nexport type ClassWeight = {\n  [classIndex: number]: number\n};\n\n/**\n * Class weighting for a model with multiple outputs.\n *\n * This object maps each output name to a class-weighting object.\n */\nexport type ClassWeightMap = {\n  [outputName: string]: ClassWeight\n};\n\nfunction standardizeSampleOrClassWeights(\n    xWeight: ClassWeight|ClassWeight[]|ClassWeightMap, outputNames: string[],\n    weightType: 'sampleWeight'|'classWeight'): ClassWeight[] {\n  const numOutputs = outputNames.length;\n  if (xWeight == null || (Array.isArray(xWeight) && xWeight.length === 0)) {\n    return outputNames.map(name => null);\n  }\n  if (numOutputs === 1) {\n    if (Array.isArray(xWeight) && xWeight.length === 1) {\n      return xWeight;\n    } else if (typeof xWeight === 'object' && outputNames[0] in xWeight) {\n      return [(xWeight as ClassWeightMap)[outputNames[0]]];\n    } else {\n      return [xWeight as ClassWeight];\n    }\n  }\n  if (Array.isArray(xWeight)) {\n    if (xWeight.length !== numOutputs) {\n      throw new Error(\n          `Provided ${weightType} is an array of ${xWeight.length} ` +\n          `element(s), but the model has ${numOutputs} outputs. ` +\n          `Make sure a set of weights is provided for each model output.`);\n    }\n    return xWeight;\n  } else if (\n      typeof xWeight === 'object' && Object.keys(xWeight).length > 0 &&\n      typeof (xWeight as ClassWeightMap)[Object.keys(xWeight)[0]] ===\n          'object') {\n    const output: ClassWeight[] = [];\n    outputNames.forEach(outputName => {\n      if (outputName in xWeight) {\n        output.push((xWeight as ClassWeightMap)[outputName]);\n      } else {\n        output.push(null);\n      }\n    });\n    return output;\n  } else {\n    throw new Error(\n        `The model has multiple (${numOutputs}) outputs, ` +\n        `so ${weightType} must be either an array with ` +\n        `${numOutputs} elements or an object with ${outputNames} keys. ` +\n        `Provided ${weightType} not understood: ${JSON.stringify(xWeight)}`);\n  }\n}\n\n/**\n * Standardize class weighting objects.\n *\n * This function takes a single class-weighting object, an array of them,\n * or a map from output name to class-weighting object. It compares it to the\n * output name(s) of the model, base on which it outputs an array of\n * class-weighting objects of which the length matches the number of outputs.\n *\n * @param classWeight Input class-weighting object(s).\n * @param outputNames All output name(s) of the model.\n * @return An array of class-weighting objects. The length of the array matches\n *   the model's number of outputs.\n */\nexport function standardizeClassWeights(\n    classWeight: ClassWeight|ClassWeight[]|ClassWeightMap,\n    outputNames: string[]): ClassWeight[] {\n  return standardizeSampleOrClassWeights(\n      classWeight, outputNames, 'classWeight');\n}\n\nexport function standardizeSampleWeights(\n    classWeight: ClassWeight|ClassWeight[]|ClassWeightMap,\n    outputNames: string[]): ClassWeight[] {\n  return standardizeSampleOrClassWeights(\n      classWeight, outputNames, 'sampleWeight');\n}\n\n/**\n * Standardize by-sample and/or by-class weights for training.\n *\n * Note that this function operates on one model output at a time. For a model\n * with multiple outputs, you must call this function multiple times.\n *\n * @param y The target tensor that the by-sample and/or by-class weight is for.\n *     The values of y are assumed to encode the classes, either directly\n *     as an integer index, or as one-hot encoding.\n * @param sampleWeight By-sample weights.\n * @param classWeight By-class weights: an object mapping class indices\n *     (integers) to a weight (float) to apply to the model's loss for the\n *     samples from this class during training. This can be useful to tell the\n *     model to \"pay more attention\" to samples from an under-represented class.\n * @param sampleWeightMode The mode for the sample weights.\n * @return A Promise of weight tensor, of which the size of the first dimension\n *     matches that of `y`.\n */\nexport async function standardizeWeights(\n    y: Tensor, sampleWeight?: Tensor, classWeight?: ClassWeight,\n    sampleWeightMode?: 'temporal'): Promise<Tensor> {\n  if (sampleWeight != null || sampleWeightMode != null) {\n    // TODO(cais): Once 'temporal' mode is implemented, document it in the doc\n    // string.\n    throw new Error('Support sampleWeight is not implemented yet');\n  }\n\n  if (classWeight != null) {\n    // Apply class weights per sample.\n    const yClasses: Tensor1D = tidy(() => {\n      if (y.shape.length === 1) {\n        // Assume class indices.\n        return clone(y) as Tensor1D;\n      } else if (y.shape.length === 2) {\n        if (y.shape[1] > 1) {\n          // Assume one-hot encoding of classes.\n          const axis = 1;\n          return argMax(y, axis);\n        } else if (y.shape[1] === 1) {\n          // Class index.\n          return reshape(y, [y.shape[0]]);\n        } else {\n          throw new Error(\n              `Encountered unexpected last-dimension size (${y.shape[1]}) ` +\n              `during handling of class weights. The size is expected to be ` +\n              `>= 1.`);\n        }\n      } else {\n        throw new Error(\n            `Unexpected rank of target (y) tensor (${y.rank}) during ` +\n            `handling of class weights. The rank is expected to be 1 or 2.`);\n      }\n    });\n\n    const yClassIndices = Array.from(await yClasses.data());\n    dispose(yClasses);\n    const classSampleWeight: number[] = [];\n    yClassIndices.forEach(classIndex => {\n      if (classWeight[classIndex] == null) {\n        throw new Error(\n            `classWeight must contain all classes in the training data. ` +\n            `The class ${classIndex} exists in the data but not in ` +\n            `classWeight`);\n      } else {\n        classSampleWeight.push(classWeight[classIndex]);\n      }\n    });\n\n    return tensor1d(classSampleWeight, 'float32');\n  } else {\n    return null;\n  }\n}\n\n/**\n * Apply per-sample weights on the loss values from a number of samples.\n *\n * @param losses Loss tensor of shape `[batchSize]`.\n * @param sampleWeights Per-sample weight tensor of shape `[batchSize]`.\n * @returns Tensor of the same shape as`losses`.\n */\nexport function computeWeightedLoss(losses: Tensor, sampleWeights: Tensor) {\n  return mul(losses, sampleWeights);\n}\n"]},"metadata":{},"sourceType":"module"}