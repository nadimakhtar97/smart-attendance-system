{"ast":null,"code":"/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { LogSoftmax } from '../kernel_names';\nimport { exp } from '../ops/exp';\nimport { mul } from '../ops/mul';\nimport { sub } from '../ops/sub';\nimport { sum } from '../ops/sum';\nexport const logSoftmaxGradConfig = {\n  kernelName: LogSoftmax,\n  inputsToSave: [],\n  outputsToSave: [true],\n  gradFunc: (dy, saved, attrs) => {\n    const [value] = saved;\n    const {\n      axis\n    } = attrs;\n    return {\n      logits: () => {\n        const keepDims = true;\n        const softmax = exp(value);\n        return sub(dy, mul(sum(dy, axis, keepDims), softmax));\n      }\n    };\n  }\n};","map":{"version":3,"mappings":"AAAA;;;;;;;;;;;;;;;;AAiBA,SAAQA,UAAR,QAA0C,iBAA1C;AAEA,SAAQC,GAAR,QAAkB,YAAlB;AACA,SAAQC,GAAR,QAAkB,YAAlB;AACA,SAAQC,GAAR,QAAkB,YAAlB;AACA,SAAQC,GAAR,QAAkB,YAAlB;AAGA,OAAO,MAAMC,oBAAoB,GAAe;AAC9CC,YAAU,EAAEN,UADkC;AAE9CO,cAAY,EAAE,EAFgC;AAG9CC,eAAa,EAAE,CAAC,IAAD,CAH+B;AAI9CC,UAAQ,EAAE,CAACC,EAAD,EAAaC,KAAb,EAA8BC,KAA9B,KAAqD;AAC7D,UAAM,CAACC,KAAD,IAAUF,KAAhB;AACA,UAAM;AAACG;AAAD,QAASF,KAAf;AACA,WAAO;AACLG,YAAM,EAAE,MAAK;AACX,cAAMC,QAAQ,GAAG,IAAjB;AACA,cAAMC,OAAO,GAAGhB,GAAG,CAACY,KAAD,CAAnB;AACA,eAAOV,GAAG,CAACO,EAAD,EAAKR,GAAG,CAACE,GAAG,CAACM,EAAD,EAAKI,IAAL,EAAWE,QAAX,CAAJ,EAA0BC,OAA1B,CAAR,CAAV;AACD;AALI,KAAP;AAOD;AAd6C,CAAzC","names":["LogSoftmax","exp","mul","sub","sum","logSoftmaxGradConfig","kernelName","inputsToSave","outputsToSave","gradFunc","dy","saved","attrs","value","axis","logits","keepDims","softmax"],"sources":["/home/nadimakhtar97/smart-attendance-system/tfjs-core/src/gradients/LogSoftmax_grad.ts"],"sourcesContent":["/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {LogSoftmax, LogSoftmaxAttrs} from '../kernel_names';\nimport {GradConfig, NamedAttrMap} from '../kernel_registry';\nimport {exp} from '../ops/exp';\nimport {mul} from '../ops/mul';\nimport {sub} from '../ops/sub';\nimport {sum} from '../ops/sum';\nimport {Tensor} from '../tensor';\n\nexport const logSoftmaxGradConfig: GradConfig = {\n  kernelName: LogSoftmax,\n  inputsToSave: [],\n  outputsToSave: [true],\n  gradFunc: (dy: Tensor, saved: Tensor[], attrs: NamedAttrMap) => {\n    const [value] = saved;\n    const {axis} = attrs as {} as LogSoftmaxAttrs;\n    return {\n      logits: () => {\n        const keepDims = true;\n        const softmax = exp(value);\n        return sub(dy, mul(sum(dy, axis, keepDims), softmax));\n      }\n    };\n  }\n};\n"]},"metadata":{},"sourceType":"module"}