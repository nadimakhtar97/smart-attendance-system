{"ast":null,"code":"/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { backend_util, Cumsum } from '@tensorflow/tfjs-core';\nimport { CumSumProgram } from '../cumsum_gpu';\nimport { identity } from './Identity';\nimport { transpose } from './Transpose';\nexport function cumsum(args) {\n  const {\n    inputs,\n    backend,\n    attrs\n  } = args;\n  const {\n    x\n  } = inputs;\n  const {\n    axis,\n    exclusive,\n    reverse\n  } = attrs;\n  const xRank = x.shape.length;\n  const permutation = backend_util.getAxesPermutation([axis], xRank);\n  let permutedX = x;\n\n  if (permutation != null) {\n    permutedX = transpose({\n      inputs: {\n        x\n      },\n      backend,\n      attrs: {\n        perm: permutation\n      }\n    });\n  }\n\n  const permutedAxis = backend_util.getInnerMostAxes(1, xRank)[0];\n\n  if (permutedAxis !== xRank - 1) {\n    throw new Error(`WebGL cumsum shader expects an inner-most axis=${x.shape.length - 1} ` + `but got axis=${axis}`);\n  }\n\n  const size = permutedX.shape[permutedAxis];\n  let result = identity({\n    inputs: {\n      x: permutedX\n    },\n    backend\n  }); // Use cumsum parallel algorithm, ref:\n  // https://developer.nvidia.com/gpugems/gpugems3/part-vi-gpu-computing/chapter-39-parallel-prefix-sum-scan-cuda\n\n  for (let i = 0; i <= Math.ceil(Math.log2(size)) - 1; i++) {\n    const program = new CumSumProgram(permutedX.shape, false, reverse);\n    const customValues = [[i]];\n    const prevResult = result;\n    result = backend.runWebGLProgram(program, [result], result.dtype, customValues);\n    backend.disposeIntermediateTensorInfo(prevResult);\n  } // For exclusive cumsum, shift the end result in the direction of sum\n  // and add 0 to the front index.\n\n\n  if (exclusive) {\n    const program = new CumSumProgram(permutedX.shape, exclusive, reverse);\n    const prevResult = result;\n    result = backend.runWebGLProgram(program, [result], result.dtype);\n    backend.disposeIntermediateTensorInfo(prevResult);\n  }\n\n  if (permutation != null) {\n    const reversePermutation = backend_util.getUndoAxesPermutation(permutation);\n    const reverseTransposedResult = transpose({\n      inputs: {\n        x: result\n      },\n      backend,\n      attrs: {\n        perm: reversePermutation\n      }\n    });\n    backend.disposeIntermediateTensorInfo(result);\n    backend.disposeIntermediateTensorInfo(permutedX);\n    return reverseTransposedResult;\n  }\n\n  return result;\n}\nexport const cumsumConfig = {\n  kernelName: Cumsum,\n  backendName: 'webgl',\n  kernelFunc: cumsum\n};","map":{"version":3,"mappings":"AAAA;;;;;;;;;;;;;;;;AAiBA,SAAQA,YAAR,EAAsBC,MAAtB,QAAoG,uBAApG;AAGA,SAAQC,aAAR,QAA4B,eAA5B;AAEA,SAAQC,QAAR,QAAuB,YAAvB;AACA,SAAQC,SAAR,QAAwB,aAAxB;AAEA,OAAM,SAAUC,MAAV,CACFC,IADE,EAEuE;AAE3E,QAAM;AAACC,UAAD;AAASC,WAAT;AAAkBC;AAAlB,MAA2BH,IAAjC;AACA,QAAM;AAACI;AAAD,MAAMH,MAAZ;AACA,QAAM;AAACI,QAAD;AAAOC,aAAP;AAAkBC;AAAlB,MAA6BJ,KAAnC;AAEA,QAAMK,KAAK,GAAGJ,CAAC,CAACK,KAAF,CAAQC,MAAtB;AACA,QAAMC,WAAW,GAAGjB,YAAY,CAACkB,kBAAb,CAAgC,CAACP,IAAD,CAAhC,EAAwCG,KAAxC,CAApB;AACA,MAAIK,SAAS,GAAGT,CAAhB;;AACA,MAAIO,WAAW,IAAI,IAAnB,EAAyB;AACvBE,aAAS,GAAGf,SAAS,CAAC;AAACG,YAAM,EAAE;AAACG;AAAD,OAAT;AAAcF,aAAd;AAAuBC,WAAK,EAAE;AAACW,YAAI,EAAEH;AAAP;AAA9B,KAAD,CAArB;AACD;;AACD,QAAMI,YAAY,GAAGrB,YAAY,CAACsB,gBAAb,CAA8B,CAA9B,EAAiCR,KAAjC,EAAwC,CAAxC,CAArB;;AAEA,MAAIO,YAAY,KAAKP,KAAK,GAAG,CAA7B,EAAgC;AAC9B,UAAM,IAAIS,KAAJ,CACF,kDACIb,CAAC,CAACK,KAAF,CAAQC,MAAR,GAAiB,CAAC,GADtB,GAEA,gBAAgBL,IAAI,EAHlB,CAAN;AAID;;AACD,QAAMa,IAAI,GAAGL,SAAS,CAACJ,KAAV,CAAgBM,YAAhB,CAAb;AACA,MAAII,MAAM,GAAGtB,QAAQ,CAAC;AAACI,UAAM,EAAE;AAACG,OAAC,EAAES;AAAJ,KAAT;AAAyBX;AAAzB,GAAD,CAArB,CArB2E,CAsB3E;AACA;;AAEA,OAAK,IAAIkB,CAAC,GAAG,CAAb,EAAgBA,CAAC,IAAIC,IAAI,CAACC,IAAL,CAAUD,IAAI,CAACE,IAAL,CAAUL,IAAV,CAAV,IAA6B,CAAlD,EAAqDE,CAAC,EAAtD,EAA0D;AACxD,UAAMI,OAAO,GAAG,IAAI5B,aAAJ,CAAkBiB,SAAS,CAACJ,KAA5B,EAAmC,KAAnC,EAA0CF,OAA1C,CAAhB;AACA,UAAMkB,YAAY,GAAG,CAAC,CAACL,CAAD,CAAD,CAArB;AACA,UAAMM,UAAU,GAAGP,MAAnB;AACAA,UAAM,GACFjB,OAAO,CAACyB,eAAR,CAAwBH,OAAxB,EAAiC,CAACL,MAAD,CAAjC,EAA2CA,MAAM,CAACS,KAAlD,EAAyDH,YAAzD,CADJ;AAEAvB,WAAO,CAAC2B,6BAAR,CAAsCH,UAAtC;AACD,GAhC0E,CAiC3E;AACA;;;AACA,MAAIpB,SAAJ,EAAe;AACb,UAAMkB,OAAO,GAAG,IAAI5B,aAAJ,CAAkBiB,SAAS,CAACJ,KAA5B,EAAmCH,SAAnC,EAA8CC,OAA9C,CAAhB;AACA,UAAMmB,UAAU,GAAGP,MAAnB;AACAA,UAAM,GAAGjB,OAAO,CAACyB,eAAR,CAAwBH,OAAxB,EAAiC,CAACL,MAAD,CAAjC,EAA2CA,MAAM,CAACS,KAAlD,CAAT;AACA1B,WAAO,CAAC2B,6BAAR,CAAsCH,UAAtC;AACD;;AAED,MAAIf,WAAW,IAAI,IAAnB,EAAyB;AACvB,UAAMmB,kBAAkB,GAAGpC,YAAY,CAACqC,sBAAb,CAAoCpB,WAApC,CAA3B;AACA,UAAMqB,uBAAuB,GAAGlC,SAAS,CACrC;AAACG,YAAM,EAAE;AAACG,SAAC,EAAEe;AAAJ,OAAT;AAAsBjB,aAAtB;AAA+BC,WAAK,EAAE;AAACW,YAAI,EAAEgB;AAAP;AAAtC,KADqC,CAAzC;AAGA5B,WAAO,CAAC2B,6BAAR,CAAsCV,MAAtC;AACAjB,WAAO,CAAC2B,6BAAR,CAAsChB,SAAtC;AAEA,WAAOmB,uBAAP;AACD;;AAED,SAAOb,MAAP;AACD;AAED,OAAO,MAAMc,YAAY,GAAiB;AACxCC,YAAU,EAAEvC,MAD4B;AAExCwC,aAAW,EAAE,OAF2B;AAGxCC,YAAU,EAAErC;AAH4B,CAAnC","names":["backend_util","Cumsum","CumSumProgram","identity","transpose","cumsum","args","inputs","backend","attrs","x","axis","exclusive","reverse","xRank","shape","length","permutation","getAxesPermutation","permutedX","perm","permutedAxis","getInnerMostAxes","Error","size","result","i","Math","ceil","log2","program","customValues","prevResult","runWebGLProgram","dtype","disposeIntermediateTensorInfo","reversePermutation","getUndoAxesPermutation","reverseTransposedResult","cumsumConfig","kernelName","backendName","kernelFunc"],"sources":["/home/nadimakhtar97/smart-attendance-system/tfjs-backend-webgl/src/kernels/Cumsum.ts"],"sourcesContent":["/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, Cumsum, CumsumAttrs, CumsumInputs, KernelConfig, KernelFunc, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {MathBackendWebGL} from '../backend_webgl';\nimport {CumSumProgram} from '../cumsum_gpu';\n\nimport {identity} from './Identity';\nimport {transpose} from './Transpose';\n\nexport function cumsum(\n    args:\n        {inputs: CumsumInputs, backend: MathBackendWebGL, attrs: CumsumAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {axis, exclusive, reverse} = attrs;\n\n  const xRank = x.shape.length;\n  const permutation = backend_util.getAxesPermutation([axis], xRank);\n  let permutedX = x;\n  if (permutation != null) {\n    permutedX = transpose({inputs: {x}, backend, attrs: {perm: permutation}});\n  }\n  const permutedAxis = backend_util.getInnerMostAxes(1, xRank)[0];\n\n  if (permutedAxis !== xRank - 1) {\n    throw new Error(\n        `WebGL cumsum shader expects an inner-most axis=${\n            x.shape.length - 1} ` +\n        `but got axis=${axis}`);\n  }\n  const size = permutedX.shape[permutedAxis];\n  let result = identity({inputs: {x: permutedX}, backend});\n  // Use cumsum parallel algorithm, ref:\n  // https://developer.nvidia.com/gpugems/gpugems3/part-vi-gpu-computing/chapter-39-parallel-prefix-sum-scan-cuda\n\n  for (let i = 0; i <= Math.ceil(Math.log2(size)) - 1; i++) {\n    const program = new CumSumProgram(permutedX.shape, false, reverse);\n    const customValues = [[i]];\n    const prevResult = result;\n    result =\n        backend.runWebGLProgram(program, [result], result.dtype, customValues);\n    backend.disposeIntermediateTensorInfo(prevResult);\n  }\n  // For exclusive cumsum, shift the end result in the direction of sum\n  // and add 0 to the front index.\n  if (exclusive) {\n    const program = new CumSumProgram(permutedX.shape, exclusive, reverse);\n    const prevResult = result;\n    result = backend.runWebGLProgram(program, [result], result.dtype);\n    backend.disposeIntermediateTensorInfo(prevResult);\n  }\n\n  if (permutation != null) {\n    const reversePermutation = backend_util.getUndoAxesPermutation(permutation);\n    const reverseTransposedResult = transpose(\n        {inputs: {x: result}, backend, attrs: {perm: reversePermutation}});\n\n    backend.disposeIntermediateTensorInfo(result);\n    backend.disposeIntermediateTensorInfo(permutedX);\n\n    return reverseTransposedResult;\n  }\n\n  return result;\n}\n\nexport const cumsumConfig: KernelConfig = {\n  kernelName: Cumsum,\n  backendName: 'webgl',\n  kernelFunc: cumsum as {} as KernelFunc\n};\n"]},"metadata":{},"sourceType":"module"}