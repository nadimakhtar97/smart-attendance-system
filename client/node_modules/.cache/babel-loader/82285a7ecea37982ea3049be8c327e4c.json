{"ast":null,"code":"/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n *\n * =============================================================================\n */\nimport * as tf from '@tensorflow/tfjs-core';\nimport * as seedrandom from 'seedrandom';\nimport { deepClone } from '../util/deep_clone';\nimport { deepMapAndAwaitAll, deepZip, zipToList } from '../util/deep_map';\nimport { GrowingRingBuffer } from '../util/growing_ring_buffer';\nimport { RingBuffer } from '../util/ring_buffer'; // Here we implement a simple asynchronous iterator.\n// This lets us avoid using either third-party stream libraries or\n// recent TypeScript language support requiring polyfills.\n\n/**\n * Create a `LazyIterator` from an array of items.\n */\n\nexport function iteratorFromItems(items) {\n  return new ArrayIterator(items);\n}\n/**\n * Create a `LazyIterator` of incrementing integers.\n */\n\nexport function iteratorFromIncrementing(start) {\n  let i = start;\n  return iteratorFromFunction(() => ({\n    value: i++,\n    done: false\n  }));\n}\n/**\n * Create a `LazyIterator` from a function.\n *\n * ```js\n * let i = -1;\n * const func = () =>\n *    ++i < 5 ? {value: i, done: false} : {value: null, done: true};\n * const iter = tf.data.iteratorFromFunction(func);\n * await iter.forEachAsync(e => console.log(e));\n * ```\n *\n * @param func A function that produces data on each call.\n */\n\nexport function iteratorFromFunction(func) {\n  return new FunctionCallIterator(func);\n}\n/**\n * Create a `LazyIterator` by concatenating underlying streams, which are\n * themselves provided as a stream.\n *\n * This can also be thought of as a \"stream flatten\" operation.\n *\n * @param baseIterators A stream of streams to be concatenated.\n * @param baseErrorHandler An optional function that can intercept `Error`s\n *   raised during a `next()` call on the base stream.  This function can decide\n *   whether the error should be propagated, whether the error should be\n *   ignored, or whether the base stream should be terminated.\n */\n\nexport function iteratorFromConcatenated(baseIterators, baseErrorHandler) {\n  return new ChainedIterator(baseIterators, baseErrorHandler);\n}\n/**\n * Create a `LazyIterator` by concatenating streams produced by calling a\n * stream-generating function a given number of times.\n *\n * Since a `LazyIterator` is read-once, it cannot be repeated, but this\n * function can be used to achieve a similar effect:\n *\n *   LazyIterator.ofConcatenatedFunction(() => new MyIterator(), 6);\n *\n * @param iteratorFunc: A function that produces a new stream on each call.\n * @param count: The number of times to call the function.\n * @param baseErrorHandler An optional function that can intercept `Error`s\n *   raised during a `next()` call on the base stream.  This function can decide\n *   whether the error should be propagated, whether the error should be\n *   ignored, or whether the base stream should be terminated.\n */\n\nexport function iteratorFromConcatenatedFunction(iteratorFunc, count, baseErrorHandler) {\n  return iteratorFromConcatenated(iteratorFromFunction(iteratorFunc).take(count), baseErrorHandler);\n}\n/**\n * Create a `LazyIterator` by zipping together an array, dict, or nested\n * structure of `LazyIterator`s (and perhaps additional constants).\n *\n * The underlying streams must provide elements in a consistent order such\n * that they correspond.\n *\n * Typically, the underlying streams should have the same number of\n * elements. If they do not, the behavior is determined by the\n * `mismatchMode` argument.\n *\n * The nested structure of the `iterators` argument determines the\n * structure of elements in the resulting iterator.\n *\n * @param iterators: An array or object containing LazyIterators at the\n * leaves.\n * @param mismatchMode: Determines what to do when one underlying iterator\n * is exhausted before the others.  `ZipMismatchMode.FAIL` (the default)\n * causes an error to be thrown in this case.  `ZipMismatchMode.SHORTEST`\n * causes the zipped iterator to terminate with the furst underlying\n * streams, so elements remaining on the longer streams are ignored.\n * `ZipMismatchMode.LONGEST` causes the zipped stream to continue, filling\n * in nulls for the exhausted streams, until all streams are exhausted.\n */\n\nexport function iteratorFromZipped(iterators) {\n  let mismatchMode = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : ZipMismatchMode.FAIL;\n  return new ZipIterator(iterators, mismatchMode);\n}\n/**\n * An asynchronous iterator, providing lazy access to a potentially\n * unbounded stream of elements.\n *\n * Iterator can be obtained from a dataset:\n * `const iter = await dataset.iterator();`\n */\n\nexport class LazyIterator {\n  /**\n   * Collect all remaining elements of a bounded stream into an array.\n   * Obviously this will succeed only for small streams that fit in memory.\n   * Useful for testing.\n   *\n   * @returns A Promise for an array of stream elements, which will resolve\n   *   when the stream is exhausted.\n   */\n  async toArray() {\n    const result = [];\n    let x = await this.next();\n\n    while (!x.done) {\n      result.push(x.value);\n      x = await this.next();\n    }\n\n    return result;\n  }\n  /**\n   * Collect all elements of this dataset into an array with prefetching 100\n   * elements. This is useful for testing, because the prefetch changes the\n   * order in which the Promises are resolved along the processing pipeline.\n   * This may help expose bugs where results are dependent on the order of\n   * Promise resolution rather than on the logical order of the stream (i.e.,\n   * due to hidden mutable state).\n   *\n   * @returns A Promise for an array of stream elements, which will resolve\n   *   when the stream is exhausted.\n   */\n\n\n  async toArrayForTest() {\n    const stream = this.prefetch(100);\n    const result = [];\n    let x = await stream.next();\n\n    while (!x.done) {\n      result.push(x.value);\n      x = await stream.next();\n    }\n\n    return result;\n  }\n  /**\n   * Draw items from the stream until it is exhausted.\n   *\n   * This can be useful when the stream has side effects but no output.  In\n   * that case, calling this function guarantees that the stream will be\n   * fully processed.\n   */\n\n\n  async resolveFully() {\n    let x = await this.next();\n\n    while (!x.done) {\n      x = await this.next();\n    }\n  }\n  /**\n   * Draw items from the stream until it is exhausted, or a predicate fails.\n   *\n   * This can be useful when the stream has side effects but no output.  In\n   * that case, calling this function guarantees that the stream will be\n   * fully processed.\n   */\n\n\n  async resolveWhile(predicate) {\n    let x = await this.next();\n    let shouldContinue = predicate(x.value);\n\n    while (!x.done && shouldContinue) {\n      x = await this.next();\n      shouldContinue = predicate(x.value);\n    }\n  }\n  /**\n   * Handles errors thrown on this stream using a provided handler function.\n   *\n   * @param handler A function that handles any `Error` thrown during a `next()`\n   *   call and returns true if the stream should continue (dropping the failed\n   *   call) or false if the stream should quietly terminate.  If the handler\n   *   itself throws (or rethrows) an `Error`, that will be propagated.\n   *\n   * @returns A `LazyIterator` of elements passed through from upstream,\n   *   possibly filtering or terminating on upstream `next()` calls that\n   *   throw an `Error`.\n   */\n\n\n  handleErrors(handler) {\n    return new ErrorHandlingLazyIterator(this, handler);\n  } // TODO(soergel): Implement reduce() etc.\n\n  /**\n   * Filters this stream according to `predicate`.\n   *\n   * @param predicate A function mapping a stream element to a boolean or a\n   * `Promise` for one.\n   *\n   * @returns A `LazyIterator` of elements for which the predicate was true.\n   */\n\n\n  filter(predicate) {\n    return new FilterIterator(this, predicate);\n  }\n  /**\n   * Maps this stream through a 1-to-1 transform.\n   *\n   * @param transform A function mapping a stream element to a transformed\n   *   element.\n   *\n   * @returns A `LazyIterator` of transformed elements.\n   */\n\n\n  map(transform) {\n    return new MapIterator(this, transform);\n  }\n  /**\n   * Maps this stream through an async 1-to-1 transform.\n   *\n   * @param transform A function mapping a stream element to a `Promise` for a\n   *   transformed stream element.\n   *\n   * @returns A `LazyIterator` of transformed elements.\n   */\n\n\n  mapAsync(transform) {\n    return new AsyncMapIterator(this, transform);\n  }\n  /**\n   * Maps this stream through a 1-to-1 transform, forcing serial execution.\n   *\n   * @param transform A function mapping a stream element to a transformed\n   *   element.\n   *\n   * @returns A `LazyIterator` of transformed elements.\n   */\n\n\n  serialMapAsync(transform) {\n    return new AsyncMapIterator(this, transform).serial();\n  }\n  /**\n   * Maps this stream through a 1-to-many transform.\n   *\n   * @param transform A function mapping a stream element to an array of\n   *   transformed elements.\n   *\n   * @returns A `DataStream` of transformed elements.\n   */\n\n\n  flatmap(transform) {\n    return new FlatmapIterator(this, transform);\n  }\n  /**\n   * Apply a function to every element of the stream.\n   *\n   * @param f A function to apply to each stream element.\n   */\n\n\n  async forEachAsync(f) {\n    return this.map(f).resolveFully();\n  }\n  /**\n   * Apply a function to every element of the stream, forcing serial execution.\n   *\n   * @param f A function to apply to each stream element.  Should return 'true'\n   *   to indicate that the stream should continue, or 'false' to cause it to\n   *   terminate.\n   */\n\n\n  async serialForEach(f) {\n    return this.serialMapAsync(f).resolveWhile(x => x === true);\n  }\n  /**\n   * Groups elements into batches, represented as arrays of elements.\n   *\n   * We can think of the elements of this iterator as 'rows' (even if they are\n   * nested structures).  By the same token, consecutive values for a given\n   * key within the elements form a 'column'.  This matches the usual sense of\n   * 'row' and 'column' when processing tabular data (e.g., parsing a CSV).\n   *\n   * Thus, \"Row-major\" means that the resulting batch is simply a collection of\n   * rows: `[row1, row2, row3, ...]`.  This is contrast to the column-major\n   * form, which is needed for vectorized computation.\n   *\n   * @param batchSize The number of elements desired per batch.\n   * @param smallLastBatch Whether to emit the final batch when it has fewer\n   *   than batchSize elements. Default true.\n   * @returns A `LazyIterator` of batches of elements, represented as arrays\n   *   of the original element type.\n   */\n\n\n  rowMajorBatch(batchSize) {\n    let smallLastBatch = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : true;\n    return new RowMajorBatchIterator(this, batchSize, smallLastBatch);\n  }\n  /**\n   * Groups elements into batches, represented in column-major form.\n   *\n   * We can think of the elements of this iterator as 'rows' (even if they are\n   * nested structures).  By the same token, consecutive values for a given\n   * key within the elements form a 'column'.  This matches the usual sense of\n   * 'row' and 'column' when processing tabular data (e.g., parsing a CSV).\n   *\n   * Thus, \"column-major\" means that the resulting batch is a (potentially\n   * nested) structure representing the columns.  Each column entry, then,\n   * contains a collection of the values found in that column for a range of\n   * input elements.  This representation allows for vectorized computation, in\n   * contrast to the row-major form.\n   *\n   * The inputs should all have the same nested structure (i.e., of arrays and\n   * dicts).  The result is a single object with the same nested structure,\n   * where the leaves are arrays collecting the values of the inputs at that\n   * location (or, optionally, the result of a custom function applied to those\n   * arrays).\n   *\n   * @param batchSize The number of elements desired per batch.\n   * @param smallLastBatch Whether to emit the final batch when it has fewer\n   *   than batchSize elements. Default true.\n   * @param zipFn: (optional) A function that expects an array of elements at a\n   *   single node of the object tree, and returns a `DeepMapResult`.  The\n   *   `DeepMapResult` either provides a result value for that node (i.e.,\n   *   representing the subtree), or indicates that the node should be processed\n   *   recursively.  The default zipFn recurses as far as possible and places\n   *   arrays at the leaves.\n   * @returns A `LazyIterator` of batches of elements, represented as an object\n   *   with collections at the leaves.\n   */\n\n\n  columnMajorBatch(batchSize) {\n    let smallLastBatch = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : true;\n    let zipFn = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : zipToList;\n    // First collect the desired number of input elements as a row-major batch.\n    const rowBatches = this.rowMajorBatch(batchSize, smallLastBatch); // Now 'rotate' or 'pivot' the data, collecting all values from each column\n    // in the batch (i.e., for each key within the elements) into an array.\n\n    return rowBatches.map(x => deepZip(x, zipFn));\n  }\n  /**\n   * Concatenate this `LazyIterator` with another.\n   *\n   * @param iterator A `LazyIterator` to be concatenated onto this one.\n   * @param baseErrorHandler An optional function that can intercept `Error`s\n   *   raised during a `next()` call on the base stream.  This function can\n   *   decide whether the error should be propagated, whether the error should\n   *   be ignored, or whether the base stream should be terminated.\n   * @returns A `LazyIterator`.\n   */\n\n\n  concatenate(iterator, baseErrorHandler) {\n    return new ChainedIterator(iteratorFromItems([this, iterator]), baseErrorHandler);\n  }\n  /**\n   * Limits this stream to return at most `count` items.\n   *\n   * @param count The maximum number of items to provide from the stream. If\n   * a negative or undefined value is given, the entire stream is returned\n   *   unaltered.\n   */\n\n\n  take(count) {\n    if (count < 0 || count == null) {\n      return this;\n    }\n\n    return new TakeIterator(this, count);\n  }\n  /**\n   * Skips the first `count` items in this stream.\n   *\n   * @param count The number of items to skip.  If a negative or undefined\n   * value is given, the entire stream is returned unaltered.\n   */\n\n\n  skip(count) {\n    if (count < 0 || count == null) {\n      return this;\n    }\n\n    return new SkipIterator(this, count);\n  }\n  /**\n   * Prefetch the first `bufferSize` items in this stream.\n   *\n   * Note this prefetches Promises, but makes no guarantees about when those\n   * Promises resolve.\n   *\n   * @param bufferSize: An integer specifying the number of elements to be\n   *   prefetched.\n   */\n\n\n  prefetch(bufferSize) {\n    return new PrefetchIterator(this, bufferSize);\n  } // TODO(soergel): deep sharded shuffle, where supported\n\n  /**\n   * Randomly shuffles the elements of this stream.\n   *\n   * @param bufferSize: An integer specifying the number of elements from\n   * this stream from which the new stream will sample.\n   * @param seed: (Optional.) An integer specifying the random seed that\n   * will be used to create the distribution.\n   */\n\n\n  shuffle(windowSize, seed) {\n    return new ShuffleIterator(this, windowSize, seed);\n  }\n  /**\n   * Force an iterator to execute serially: each next() call will await the\n   * prior one, so that they cannot execute concurrently.\n   */\n\n\n  serial() {\n    return new SerialIterator(this);\n  }\n\n} // ============================================================================\n// The following private classes serve to implement the chainable methods\n// on LazyIterator.  Unfortunately they can't be placed in separate files,\n// due to resulting trouble with circular imports.\n// ============================================================================\n// Iterators that just extend LazyIterator directly\n// ============================================================================\n\nclass ArrayIterator extends LazyIterator {\n  constructor(items) {\n    super();\n    this.items = items;\n    this.trav = 0;\n  }\n\n  summary() {\n    return `Array of ${this.items.length} items`;\n  }\n\n  async next() {\n    if (this.trav >= this.items.length) {\n      return {\n        value: null,\n        done: true\n      };\n    }\n\n    const item = this.items[this.trav];\n    this.trav++;\n    return {\n      value: deepClone(item),\n      done: false\n    };\n  }\n\n}\n\nclass FunctionCallIterator extends LazyIterator {\n  constructor(nextFn) {\n    super();\n    this.nextFn = nextFn;\n  }\n\n  summary() {\n    return `Function call`;\n  }\n\n  async next() {\n    try {\n      return this.nextFn();\n    } catch (e) {\n      // Modify the error message but leave the stack trace intact\n      e.message = `Error thrown while iterating through a dataset: ${e.message}`;\n      throw e;\n    }\n  }\n\n}\n\nclass SerialIterator extends LazyIterator {\n  constructor(upstream) {\n    super();\n    this.upstream = upstream;\n    this.lastRead = Promise.resolve({\n      value: null,\n      done: false\n    });\n  }\n\n  summary() {\n    return `${this.upstream.summary()} -> Serial`;\n  }\n\n  async next() {\n    // This sets this.lastRead to a new Promise right away, as opposed to\n    // saying `await this.lastRead; this.lastRead = this.serialNext();` which\n    // would not work because this.nextRead would be updated only after the\n    // promise resolves.\n    this.lastRead = this.lastRead.then(() => this.serialNext());\n    return this.lastRead;\n  }\n\n  async serialNext() {\n    return this.upstream.next();\n  }\n\n}\n\nclass SkipIterator extends LazyIterator {\n  constructor(upstream, maxCount) {\n    super();\n    this.upstream = upstream;\n    this.maxCount = maxCount; // Local state that should not be clobbered by out-of-order execution.\n\n    this.count = 0;\n    this.lastRead = Promise.resolve({\n      value: null,\n      done: false\n    });\n  }\n\n  summary() {\n    return `${this.upstream.summary()} -> Skip`;\n  }\n\n  async next() {\n    // This sets this.lastRead to a new Promise right away, as opposed to\n    // saying `await this.lastRead; this.lastRead = this.serialNext();` which\n    // would not work because this.nextRead would be updated only after the\n    // promise resolves.\n    this.lastRead = this.lastRead.then(() => this.serialNext());\n    return this.lastRead;\n  }\n\n  async serialNext() {\n    // TODO(soergel): consider tradeoffs of reading in parallel, eg.\n    // collecting next() promises in an Array and then waiting for\n    // Promise.all() of those. Benefit: pseudo-parallel execution.  Drawback:\n    // maybe delayed GC.\n    while (this.count++ < this.maxCount) {\n      const skipped = await this.upstream.next(); // short-circuit if upstream is already empty\n\n      if (skipped.done) {\n        return skipped;\n      }\n\n      tf.dispose(skipped.value);\n    }\n\n    return this.upstream.next();\n  }\n\n}\n\nclass TakeIterator extends LazyIterator {\n  constructor(upstream, maxCount) {\n    super();\n    this.upstream = upstream;\n    this.maxCount = maxCount;\n    this.count = 0;\n  }\n\n  summary() {\n    return `${this.upstream.summary()} -> Take`;\n  }\n\n  async next() {\n    if (this.count++ >= this.maxCount) {\n      return {\n        value: null,\n        done: true\n      };\n    }\n\n    return this.upstream.next();\n  }\n\n} // Note this batch just groups items into row-wise element arrays.\n// Rotating these to a column-wise representation happens only at the dataset\n// level.\n\n\nclass RowMajorBatchIterator extends LazyIterator {\n  constructor(upstream, batchSize) {\n    let enableSmallLastBatch = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : true;\n    super();\n    this.upstream = upstream;\n    this.batchSize = batchSize;\n    this.enableSmallLastBatch = enableSmallLastBatch;\n    this.lastRead = Promise.resolve({\n      value: null,\n      done: false\n    });\n  }\n\n  summary() {\n    return `${this.upstream.summary()} -> RowMajorBatch`;\n  }\n\n  async next() {\n    // This sets this.lastRead to a new Promise right away, as opposed to\n    // saying `await this.lastRead; this.lastRead = this.serialNext();` which\n    // would not work because this.nextRead would be updated only after the\n    // promise resolves.\n    this.lastRead = this.lastRead.then(() => this.serialNext());\n    return this.lastRead;\n  }\n\n  async serialNext() {\n    const batch = [];\n\n    while (batch.length < this.batchSize) {\n      const item = await this.upstream.next();\n\n      if (item.done) {\n        if (this.enableSmallLastBatch && batch.length > 0) {\n          return {\n            value: batch,\n            done: false\n          };\n        }\n\n        return {\n          value: null,\n          done: true\n        };\n      }\n\n      batch.push(item.value);\n    }\n\n    return {\n      value: batch,\n      done: false\n    };\n  }\n\n}\n\nclass FilterIterator extends LazyIterator {\n  constructor(upstream, predicate) {\n    super();\n    this.upstream = upstream;\n    this.predicate = predicate;\n    this.lastRead = Promise.resolve({\n      value: null,\n      done: false\n    });\n  }\n\n  summary() {\n    return `${this.upstream.summary()} -> Filter`;\n  }\n\n  async next() {\n    // This sets this.lastRead to a new Promise right away, as opposed to\n    // saying `await this.lastRead; this.lastRead = this.serialNext();` which\n    // would not work because this.nextRead would be updated only after the\n    // promise resolves.\n    this.lastRead = this.lastRead.then(() => this.serialNext());\n    return this.lastRead;\n  }\n\n  async serialNext() {\n    while (true) {\n      const item = await this.upstream.next();\n\n      if (item.done || this.predicate(item.value)) {\n        return item;\n      }\n\n      tf.dispose(item.value);\n    }\n  }\n\n}\n\nclass MapIterator extends LazyIterator {\n  constructor(upstream, transform) {\n    super();\n    this.upstream = upstream;\n    this.transform = transform;\n  }\n\n  summary() {\n    return `${this.upstream.summary()} -> Map`;\n  }\n\n  async next() {\n    const item = await this.upstream.next();\n\n    if (item.done) {\n      return {\n        value: null,\n        done: true\n      };\n    }\n\n    const inputTensors = tf.tensor_util.getTensorsInContainer(item.value); // Careful: the transform may mutate the item in place.\n    // That's why we have to remember the input Tensors above, and then\n    // below dispose only those that were not passed through to the output.\n    // Note too that the transform function is responsible for tidying\n    // any intermediate Tensors.  Here we are concerned only about the\n    // inputs.\n\n    const mapped = this.transform(item.value);\n    const outputTensors = tf.tensor_util.getTensorsInContainer(mapped); // TODO(soergel) faster intersection\n    // TODO(soergel) move to tf.disposeExcept(in, out)?\n\n    for (const t of inputTensors) {\n      if (!tf.tensor_util.isTensorInList(t, outputTensors)) {\n        t.dispose();\n      }\n    }\n\n    return {\n      value: mapped,\n      done: false\n    };\n  }\n\n}\n\nclass ErrorHandlingLazyIterator extends LazyIterator {\n  constructor(upstream, handler) {\n    super();\n    this.upstream = upstream;\n    this.handler = handler;\n    this.count = 0;\n    this.lastRead = Promise.resolve({\n      value: null,\n      done: false\n    });\n  }\n\n  summary() {\n    return `${this.upstream.summary()} -> handleErrors`;\n  }\n\n  async next() {\n    // This sets this.lastRead to a new Promise right away, as opposed to\n    // saying `await this.lastRead; this.lastRead = this.serialNext();` which\n    // would not work because this.nextRead would be updated only after the\n    // promise resolves.\n    this.lastRead = this.lastRead.then(() => this.serialNext());\n    return this.lastRead;\n  }\n\n  async serialNext() {\n    while (true) {\n      try {\n        return await this.upstream.next();\n      } catch (e) {\n        if (!this.handler(e)) {\n          return {\n            value: null,\n            done: true\n          };\n        } // If the handler returns true, loop and fetch the next upstream item.\n        // If the upstream iterator throws an endless stream of errors, and if\n        // the handler says to ignore them, then we loop forever here.  That is\n        // the correct behavior-- it's up to the handler to decide when to stop.\n\n      }\n    }\n  }\n\n}\n\nclass AsyncMapIterator extends LazyIterator {\n  constructor(upstream, transform) {\n    super();\n    this.upstream = upstream;\n    this.transform = transform;\n  }\n\n  summary() {\n    return `${this.upstream.summary()} -> AsyncMap`;\n  }\n\n  async next() {\n    const item = await this.upstream.next();\n\n    if (item.done) {\n      return {\n        value: null,\n        done: true\n      };\n    }\n\n    const inputTensors = tf.tensor_util.getTensorsInContainer(item.value); // Careful: the transform may mutate the item in place.\n    // That's why we have to remember the input Tensors above, and then\n    // below dispose only those that were not passed through to the output.\n    // Note too that the transform function is responsible for tidying\n    // any intermediate Tensors.  Here we are concerned only about the\n    // inputs.\n\n    const mapped = await this.transform(item.value);\n    const outputTensors = tf.tensor_util.getTensorsInContainer(mapped); // TODO(soergel) faster intersection\n    // TODO(soergel) move to tf.disposeExcept(in, out)?\n\n    for (const t of inputTensors) {\n      if (!tf.tensor_util.isTensorInList(t, outputTensors)) {\n        t.dispose();\n      }\n    }\n\n    return {\n      value: mapped,\n      done: false\n    };\n  }\n\n} // Iterators that maintain a queue of pending items\n// ============================================================================\n\n/**\n * A base class for transforming streams that operate by maintaining an\n * output queue of elements that are ready to return via next().  This is\n * commonly required when the transformation is 1-to-many:  A call to next()\n * may trigger a call to the underlying stream, which will produce many\n * mapped elements of this stream-- of which we need to return only one, so\n * we have to queue the rest.\n */\n\n\nexport class OneToManyIterator extends LazyIterator {\n  constructor() {\n    super();\n    this.outputQueue = new GrowingRingBuffer();\n    this.lastRead = Promise.resolve({\n      value: null,\n      done: false\n    });\n  }\n\n  async next() {\n    // This sets this.lastRead to a new Promise right away, as opposed to\n    // saying `await this.lastRead; this.lastRead = this.serialNext();` which\n    // would not work because this.nextRead would be updated only after the\n    // promise resolves.\n    this.lastRead = this.lastRead.then(() => this.serialNext());\n    return this.lastRead;\n  }\n\n  async serialNext() {\n    // Fetch so that the queue contains at least one item if possible.\n    // If the upstream source is exhausted, AND there are no items left in\n    // the output queue, then this stream is also exhausted.\n    while (this.outputQueue.length() === 0) {\n      // TODO(soergel): consider parallel reads.\n      if (!(await this.pump())) {\n        return {\n          value: null,\n          done: true\n        };\n      }\n    }\n\n    return {\n      value: this.outputQueue.shift(),\n      done: false\n    };\n  }\n\n}\n\nclass FlatmapIterator extends OneToManyIterator {\n  constructor(upstream, transform) {\n    super();\n    this.upstream = upstream;\n    this.transform = transform;\n  }\n\n  summary() {\n    return `${this.upstream.summary()} -> Flatmap`;\n  }\n\n  async pump() {\n    const item = await this.upstream.next();\n\n    if (item.done) {\n      return false;\n    }\n\n    const inputTensors = tf.tensor_util.getTensorsInContainer(item.value); // Careful: the transform may mutate the item in place.\n    // that's why we have to remember the input Tensors above, and then\n    // below dispose only those that were not passed through to the output.\n    // Note too that the transform function is responsible for tidying any\n    // intermediate Tensors.  Here we are concerned only about the inputs.\n\n    const mappedArray = this.transform(item.value);\n    const outputTensors = tf.tensor_util.getTensorsInContainer(mappedArray);\n    this.outputQueue.pushAll(mappedArray); // TODO(soergel) faster intersection, and deduplicate outputTensors\n    // TODO(soergel) move to tf.disposeExcept(in, out)?\n\n    for (const t of inputTensors) {\n      if (!tf.tensor_util.isTensorInList(t, outputTensors)) {\n        t.dispose();\n      }\n    }\n\n    return true;\n  }\n\n}\n/**\n * Provides a `LazyIterator` that concatenates a stream of underlying\n * streams.\n *\n * Doing this in a concurrency-safe way requires some trickery.  In\n * particular, we want this stream to return the elements from the\n * underlying streams in the correct order according to when next() was\n * called, even if the resulting Promises resolve in a different order.\n */\n\n\nexport class ChainedIterator extends LazyIterator {\n  constructor(iterators, baseErrorHandler) {\n    super();\n    this.baseErrorHandler = baseErrorHandler; // Strict Promise execution order:\n    // a next() call may not even begin until the previous one completes.\n\n    this.lastRead = null; // Local state that should not be clobbered by out-of-order execution.\n\n    this.iterator = null;\n    this.moreIterators = iterators;\n  }\n\n  summary() {\n    const upstreamSummaries = 'TODO: fill in upstream of chained summaries';\n    return `${upstreamSummaries} -> Chained`;\n  }\n\n  async next() {\n    this.lastRead = this.readFromChain(this.lastRead);\n    return this.lastRead;\n  }\n\n  async readFromChain(lastRead) {\n    // Must await on the previous read since the previous read may have advanced\n    // the stream of streams, from which we need to read.\n    // This is unfortunate since we can't parallelize reads. Which means\n    // prefetching of chained streams is a no-op.\n    // One solution is to prefetch immediately upstream of this.\n    await lastRead;\n\n    if (this.iterator == null) {\n      const iteratorResult = await this.moreIterators.next();\n\n      if (iteratorResult.done) {\n        // No more streams to stream from.\n        return {\n          value: null,\n          done: true\n        };\n      }\n\n      this.iterator = iteratorResult.value;\n\n      if (this.baseErrorHandler != null) {\n        this.iterator = this.iterator.handleErrors(this.baseErrorHandler);\n      }\n    }\n\n    const itemResult = await this.iterator.next();\n\n    if (itemResult.done) {\n      this.iterator = null;\n      return this.readFromChain(lastRead);\n    }\n\n    return itemResult;\n  }\n\n}\nexport var ZipMismatchMode;\n\n(function (ZipMismatchMode) {\n  ZipMismatchMode[ZipMismatchMode[\"FAIL\"] = 0] = \"FAIL\";\n  ZipMismatchMode[ZipMismatchMode[\"SHORTEST\"] = 1] = \"SHORTEST\";\n  ZipMismatchMode[ZipMismatchMode[\"LONGEST\"] = 2] = \"LONGEST\"; // use nulls for exhausted streams; use up the longest stream.\n})(ZipMismatchMode || (ZipMismatchMode = {}));\n/**\n * Provides a `LazyIterator` that zips together an array, dict, or nested\n * structure of `LazyIterator`s (and perhaps additional constants).\n *\n * The underlying streams must provide elements in a consistent order such\n * that they correspond.\n *\n * Typically, the underlying streams should have the same number of\n * elements. If they do not, the behavior is determined by the\n * `mismatchMode` argument.\n *\n * The nested structure of the `iterators` argument determines the\n * structure of elements in the resulting iterator.\n *\n * Doing this in a concurrency-safe way requires some trickery.  In\n * particular, we want this stream to return the elements from the\n * underlying streams in the correct order according to when next() was\n * called, even if the resulting Promises resolve in a different order.\n *\n * @param iterators: An array or object containing LazyIterators at the\n * leaves.\n * @param mismatchMode: Determines what to do when one underlying iterator\n * is exhausted before the others.  `ZipMismatchMode.FAIL` (the default)\n * causes an error to be thrown in this case.  `ZipMismatchMode.SHORTEST`\n * causes the zipped iterator to terminate with the furst underlying\n * streams, so elements remaining on the longer streams are ignored.\n * `ZipMismatchMode.LONGEST` causes the zipped stream to continue, filling\n * in nulls for the exhausted streams, until all streams are exhausted.\n */\n\n\nclass ZipIterator extends LazyIterator {\n  constructor(iterators) {\n    let mismatchMode = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : ZipMismatchMode.FAIL;\n    super();\n    this.iterators = iterators;\n    this.mismatchMode = mismatchMode;\n    this.count = 0;\n    this.currentPromise = null;\n  }\n\n  summary() {\n    const upstreamSummaries = 'TODO: fill in upstream of zip summaries';\n    return `{${upstreamSummaries}} -> Zip`;\n  }\n\n  async nextState(afterState) {\n    // This chaining ensures that the underlying next() are not even called\n    // before the previous ones have resolved.\n    await afterState; // Collect underlying iterator \"done\" signals as a side effect in\n    // getNext()\n\n    let numIterators = 0;\n    let iteratorsDone = 0;\n\n    function getNext(container) {\n      if (container instanceof LazyIterator) {\n        const result = container.next();\n        return {\n          value: result.then(x => {\n            numIterators++;\n\n            if (x.done) {\n              iteratorsDone++;\n            }\n\n            return x.value;\n          }),\n          recurse: false\n        };\n      } else {\n        return {\n          value: null,\n          recurse: true\n        };\n      }\n    }\n\n    const mapped = await deepMapAndAwaitAll(this.iterators, getNext);\n\n    if (numIterators === iteratorsDone) {\n      // The streams have all ended.\n      return {\n        value: null,\n        done: true\n      };\n    }\n\n    if (iteratorsDone > 0) {\n      switch (this.mismatchMode) {\n        case ZipMismatchMode.FAIL:\n          throw new Error('Zipped streams should have the same length. ' + `Mismatched at element ${this.count}.`);\n\n        case ZipMismatchMode.SHORTEST:\n          return {\n            value: null,\n            done: true\n          };\n\n        case ZipMismatchMode.LONGEST:\n        default: // Continue.  The exhausted streams already produced value: null.\n\n      }\n    }\n\n    this.count++;\n    return {\n      value: mapped,\n      done: false\n    };\n  }\n\n  async next() {\n    this.currentPromise = this.nextState(this.currentPromise);\n    return this.currentPromise;\n  }\n\n} // Iterators that maintain a ring buffer of pending promises\n// ============================================================================\n\n/**\n * A stream that prefetches a given number of items from an upstream source,\n * returning them in FIFO order.\n *\n * Note this prefetches Promises, but makes no guarantees about when those\n * Promises resolve.\n */\n\n\nexport class PrefetchIterator extends LazyIterator {\n  constructor(upstream, bufferSize) {\n    super();\n    this.upstream = upstream;\n    this.bufferSize = bufferSize;\n    this.buffer = new RingBuffer(bufferSize);\n  }\n\n  summary() {\n    return `${this.upstream.summary()} -> Prefetch`;\n  }\n  /**\n   * Refill the prefetch buffer.  Returns only after the buffer is full, or\n   * the upstream source is exhausted.\n   */\n\n\n  refill() {\n    while (!this.buffer.isFull()) {\n      const v = this.upstream.next();\n      this.buffer.push(v);\n    }\n  }\n\n  next() {\n    this.refill(); // This shift will never throw an error because the buffer is always\n    // full after a refill. If the stream is exhausted, the buffer will be\n    // full of Promises that will resolve to the end-of-stream signal.\n\n    return this.buffer.shift();\n  }\n\n}\n/**\n * A stream that performs a sliding-window random shuffle on an upstream\n * source. This is like a `PrefetchIterator` except that the items are\n * returned in randomized order.  Mixing naturally improves as the buffer\n * size increases.\n */\n\nexport class ShuffleIterator extends PrefetchIterator {\n  constructor(upstream, windowSize, seed) {\n    super(upstream, windowSize);\n    this.upstream = upstream;\n    this.windowSize = windowSize; // Local state that should not be clobbered by out-of-order execution.\n\n    this.upstreamExhausted = false;\n    this.random = seedrandom.alea(seed || tf.util.now().toString());\n    this.lastRead = Promise.resolve({\n      value: null,\n      done: false\n    });\n  }\n\n  async next() {\n    // This sets this.lastRead to a new Promise right away, as opposed to\n    // saying `await this.lastRead; this.lastRead = this.serialNext();` which\n    // would not work because this.nextRead would be updated only after the\n    // promise resolves.\n    this.lastRead = this.lastRead.then(() => this.serialNext());\n    return this.lastRead;\n  }\n\n  randomInt(max) {\n    return Math.floor(this.random() * max);\n  }\n\n  chooseIndex() {\n    return this.randomInt(this.buffer.length());\n  }\n\n  async serialNext() {\n    // TODO(soergel): consider performance\n    if (!this.upstreamExhausted) {\n      this.refill();\n    }\n\n    while (!this.buffer.isEmpty()) {\n      const chosenIndex = this.chooseIndex();\n      const result = await this.buffer.shuffleExcise(chosenIndex);\n\n      if (result.done) {\n        this.upstreamExhausted = true;\n      } else {\n        this.refill();\n        return result;\n      }\n    }\n\n    return {\n      value: null,\n      done: true\n    };\n  }\n\n}","map":{"version":3,"mappings":"AAAA;;;;;;;;;;;;;;;;;AAkBA,OAAO,KAAKA,EAAZ,MAAoB,uBAApB;AACA,OAAO,KAAKC,UAAZ,MAA4B,YAA5B;AAGA,SAAQC,SAAR,QAAwB,oBAAxB;AACA,SAAQC,kBAAR,EAA+DC,OAA/D,EAAwEC,SAAxE,QAAwF,kBAAxF;AACA,SAAQC,iBAAR,QAAgC,6BAAhC;AACA,SAAQC,UAAR,QAAyB,qBAAzB,C,CAOA;AACA;AACA;;AAEA;;;;AAGA,OAAM,SAAUC,iBAAV,CAA+BC,KAA/B,EAAyC;AAC7C,SAAO,IAAIC,aAAJ,CAAkBD,KAAlB,CAAP;AACD;AAED;;;;AAGA,OAAM,SAAUE,wBAAV,CAAmCC,KAAnC,EAAgD;AACpD,MAAIC,CAAC,GAAGD,KAAR;AACA,SAAOE,oBAAoB,CAAC,OAAO;AAACC,SAAK,EAAEF,CAAC,EAAT;AAAaG,QAAI,EAAE;AAAnB,GAAP,CAAD,CAA3B;AACD;AAED;;;;;;;;;;;;;;AAaA,OAAM,SAAUF,oBAAV,CACFG,IADE,EAE+C;AACnD,SAAO,IAAIC,oBAAJ,CAAyBD,IAAzB,CAAP;AACD;AAED;;;;;;;;;;;;;AAYA,OAAM,SAAUE,wBAAV,CACFC,aADE,EAEFC,gBAFE,EAEsC;AAC1C,SAAO,IAAIC,eAAJ,CAAoBF,aAApB,EAAmCC,gBAAnC,CAAP;AACD;AAED;;;;;;;;;;;;;;;;;AAgBA,OAAM,SAAUE,gCAAV,CACFC,YADE,EACmDC,KADnD,EAEFJ,gBAFE,EAEsC;AAC1C,SAAOF,wBAAwB,CAC3BL,oBAAoB,CAACU,YAAD,CAApB,CAAmCE,IAAnC,CAAwCD,KAAxC,CAD2B,EACqBJ,gBADrB,CAA/B;AAED;AAED;;;;;;;;;;;;;;;;;;;;;;;;;AAwBA,OAAM,SAAUM,kBAAV,CACFC,SADE,EAEkD;AAAA,MAApDC,YAAoD,uEAApBC,eAAe,CAACC,IAAI;AACtD,SAAO,IAAIC,WAAJ,CAAmBJ,SAAnB,EAA8BC,YAA9B,CAAP;AACD;AAED;;;;;;;;AAOA,OAAM,MAAgBI,YAAhB,CAA4B;AAgBhC;;;;;;;;AAQa,QAAPC,OAAO;AACX,UAAMC,MAAM,GAAQ,EAApB;AACA,QAAIC,CAAC,GAAG,MAAM,KAAKC,IAAL,EAAd;;AACA,WAAO,CAACD,CAAC,CAACpB,IAAV,EAAgB;AACdmB,YAAM,CAACG,IAAP,CAAYF,CAAC,CAACrB,KAAd;AACAqB,OAAC,GAAG,MAAM,KAAKC,IAAL,EAAV;AACD;;AACD,WAAOF,MAAP;AACD;AAED;;;;;;;;;;;;;AAWoB,QAAdI,cAAc;AAClB,UAAMC,MAAM,GAAG,KAAKC,QAAL,CAAc,GAAd,CAAf;AACA,UAAMN,MAAM,GAAQ,EAApB;AACA,QAAIC,CAAC,GAAG,MAAMI,MAAM,CAACH,IAAP,EAAd;;AACA,WAAO,CAACD,CAAC,CAACpB,IAAV,EAAgB;AACdmB,YAAM,CAACG,IAAP,CAAYF,CAAC,CAACrB,KAAd;AACAqB,OAAC,GAAG,MAAMI,MAAM,CAACH,IAAP,EAAV;AACD;;AACD,WAAOF,MAAP;AACD;AAED;;;;;;;;;AAOkB,QAAZO,YAAY;AAChB,QAAIN,CAAC,GAAG,MAAM,KAAKC,IAAL,EAAd;;AACA,WAAO,CAACD,CAAC,CAACpB,IAAV,EAAgB;AACdoB,OAAC,GAAG,MAAM,KAAKC,IAAL,EAAV;AACD;AACF;AAED;;;;;;;;;AAOkB,QAAZM,YAAY,CAACC,SAAD,EAA6B;AAC7C,QAAIR,CAAC,GAAG,MAAM,KAAKC,IAAL,EAAd;AACA,QAAIQ,cAAc,GAAGD,SAAS,CAACR,CAAC,CAACrB,KAAH,CAA9B;;AACA,WAAQ,CAACqB,CAAC,CAACpB,IAAJ,IAAa6B,cAApB,EAAoC;AAClCT,OAAC,GAAG,MAAM,KAAKC,IAAL,EAAV;AACAQ,oBAAc,GAAGD,SAAS,CAACR,CAAC,CAACrB,KAAH,CAA1B;AACD;AACF;AAED;;;;;;;;;;;;;;AAYA+B,cAAY,CAACC,OAAD,EAAmC;AAC7C,WAAO,IAAIC,yBAAJ,CAA8B,IAA9B,EAAoCD,OAApC,CAAP;AACD,GApG+B,CAsGhC;;AAEA;;;;;;;;;;AAQAE,QAAM,CAACL,SAAD,EAAiC;AACrC,WAAO,IAAIM,cAAJ,CAAmB,IAAnB,EAAyBN,SAAzB,CAAP;AACD;AAED;;;;;;;;;;AAQAO,KAAG,CAAIC,SAAJ,EAA8B;AAC/B,WAAO,IAAIC,WAAJ,CAAgB,IAAhB,EAAsBD,SAAtB,CAAP;AACD;AAED;;;;;;;;;;AAQAE,UAAQ,CAAIF,SAAJ,EAAuC;AAC7C,WAAO,IAAIG,gBAAJ,CAAqB,IAArB,EAA2BH,SAA3B,CAAP;AACD;AAED;;;;;;;;;;AAQAI,gBAAc,CAAIJ,SAAJ,EAAuC;AACnD,WAAO,IAAIG,gBAAJ,CAAqB,IAArB,EAA2BH,SAA3B,EAAsCK,MAAtC,EAAP;AACD;AAED;;;;;;;;;;AAQAC,SAAO,CAAIN,SAAJ,EAAgC;AACrC,WAAO,IAAIO,eAAJ,CAAoB,IAApB,EAA0BP,SAA1B,CAAP;AACD;AAED;;;;;;;AAKkB,QAAZQ,YAAY,CAACC,CAAD,EAAsB;AACtC,WAAO,KAAKV,GAAL,CAASU,CAAT,EAAYnB,YAAZ,EAAP;AACD;AAED;;;;;;;;;AAOmB,QAAboB,aAAa,CAACD,CAAD,EAAkC;AACnD,WAAO,KAAKL,cAAL,CAAoBK,CAApB,EAAuBlB,YAAvB,CAAoCP,CAAC,IAAKA,CAAC,KAAK,IAAhD,CAAP;AACD;AAED;;;;;;;;;;;;;;;;;;;;AAkBA2B,eAAa,CAACC,SAAD,EAAyC;AAAA,QAArBC,cAAqB,uEAAJ,IAAI;AACpD,WAAO,IAAIC,qBAAJ,CAA0B,IAA1B,EAAgCF,SAAhC,EAA2CC,cAA3C,CAAP;AACD;AAED;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAgCAE,kBAAgB,CACZH,SADY,EAGmC;AAAA,QAF5BC,cAE4B,uEAFX,IAEW;AAAA,QAA/CG,KAA+C,uEAAT/D,SAAS;AAEjD;AACA,UAAMgE,UAAU,GAAG,KAAKN,aAAL,CAAmBC,SAAnB,EAA8BC,cAA9B,CAAnB,CAHiD,CAIjD;AACA;;AACA,WAAOI,UAAU,CAAClB,GAAX,CAAef,CAAC,IAAIhC,OAAO,CAACgC,CAAD,EAAIgC,KAAJ,CAA3B,CAAP;AACD;AAED;;;;;;;;;;;;AAUAE,aAAW,CACPC,QADO,EAEPlD,gBAFO,EAEiC;AAC1C,WAAO,IAAIC,eAAJ,CACHd,iBAAiB,CAAC,CAAC,IAAD,EAAO+D,QAAP,CAAD,CADd,EACkClD,gBADlC,CAAP;AAED;AAED;;;;;;;;;AAOAK,MAAI,CAACD,KAAD,EAAc;AAChB,QAAIA,KAAK,GAAG,CAAR,IAAaA,KAAK,IAAI,IAA1B,EAAgC;AAC9B,aAAO,IAAP;AACD;;AACD,WAAO,IAAI+C,YAAJ,CAAiB,IAAjB,EAAuB/C,KAAvB,CAAP;AACD;AAED;;;;;;;;AAMAgD,MAAI,CAAChD,KAAD,EAAc;AAChB,QAAIA,KAAK,GAAG,CAAR,IAAaA,KAAK,IAAI,IAA1B,EAAgC;AAC9B,aAAO,IAAP;AACD;;AACD,WAAO,IAAIiD,YAAJ,CAAiB,IAAjB,EAAuBjD,KAAvB,CAAP;AACD;AAED;;;;;;;;;;;AASAgB,UAAQ,CAACkC,UAAD,EAAmB;AACzB,WAAO,IAAIC,gBAAJ,CAAqB,IAArB,EAA2BD,UAA3B,CAAP;AACD,GAjT+B,CAmThC;;AAEA;;;;;;;;;;AAQAE,SAAO,CAACC,UAAD,EAAqBC,IAArB,EAAkC;AACvC,WAAO,IAAIC,eAAJ,CAAoB,IAApB,EAA0BF,UAA1B,EAAsCC,IAAtC,CAAP;AACD;AAED;;;;;;AAIAtB,QAAM;AACJ,WAAO,IAAIwB,cAAJ,CAAmB,IAAnB,CAAP;AACD;;AAvU+B,C,CA0UlC;AACA;AACA;AACA;AACA;AAEA;AACA;;AAEA,MAAMvE,aAAN,SAA+BuB,YAA/B,CAA8C;AAE5CiD,cAAsBzE,KAAtB,EAAgC;AAC9B;AADoB;AADd,gBAAO,CAAP;AAGP;;AAED0E,SAAO;AACL,WAAO,YAAY,KAAK1E,KAAL,CAAW2E,MAAM,QAApC;AACD;;AAES,QAAJ/C,IAAI;AACR,QAAI,KAAKgD,IAAL,IAAa,KAAK5E,KAAL,CAAW2E,MAA5B,EAAoC;AAClC,aAAO;AAACrE,aAAK,EAAE,IAAR;AAAcC,YAAI,EAAE;AAApB,OAAP;AACD;;AACD,UAAMsE,IAAI,GAAG,KAAK7E,KAAL,CAAW,KAAK4E,IAAhB,CAAb;AACA,SAAKA,IAAL;AACA,WAAO;AAACtE,WAAK,EAAEb,SAAS,CAACoF,IAAD,CAAjB;AAAyBtE,UAAI,EAAE;AAA/B,KAAP;AACD;;AAjB2C;;AAoB9C,MAAME,oBAAN,SAAsCe,YAAtC,CAAqD;AACnDiD,cACcK,MADd,EACyE;AACvE;AADY;AAEb;;AAEDJ,SAAO;AACL,WAAO,eAAP;AACD;;AAES,QAAJ9C,IAAI;AACR,QAAI;AACF,aAAO,KAAKkD,MAAL,EAAP;AACD,KAFD,CAEE,OAAOC,CAAP,EAAU;AACV;AACAA,OAAC,CAACC,OAAF,GACI,mDAAmDD,CAAC,CAACC,OAAO,EADhE;AAEA,YAAMD,CAAN;AACD;AACF;;AAnBkD;;AAsBrD,MAAMP,cAAN,SAAgChD,YAAhC,CAA+C;AAK7CiD,cAAsBQ,QAAtB,EAA+C;AAC7C;AADoB;AAEpB,SAAKC,QAAL,GAAgBC,OAAO,CAACC,OAAR,CAAgB;AAAC9E,WAAK,EAAE,IAAR;AAAcC,UAAI,EAAE;AAApB,KAAhB,CAAhB;AACD;;AAEDmE,SAAO;AACL,WAAO,GAAG,KAAKO,QAAL,CAAcP,OAAd,EAAuB,YAAjC;AACD;;AAES,QAAJ9C,IAAI;AACR;AACA;AACA;AACA;AACA,SAAKsD,QAAL,GAAgB,KAAKA,QAAL,CAAcG,IAAd,CAAmB,MAAM,KAAKC,UAAL,EAAzB,CAAhB;AACA,WAAO,KAAKJ,QAAZ;AACD;;AAEuB,QAAVI,UAAU;AACtB,WAAO,KAAKL,QAAL,CAAcrD,IAAd,EAAP;AACD;;AAzB4C;;AA4B/C,MAAMqC,YAAN,SAA8BzC,YAA9B,CAA6C;AAQ3CiD,cAAsBQ,QAAtB,EAA2DM,QAA3D,EAA2E;AACzE;AADoB;AAAqC,6BAAgB,CAH3E;;AACA,iBAAQ,CAAR;AAIE,SAAKL,QAAL,GAAgBC,OAAO,CAACC,OAAR,CAAgB;AAAC9E,WAAK,EAAE,IAAR;AAAcC,UAAI,EAAE;AAApB,KAAhB,CAAhB;AACD;;AAEDmE,SAAO;AACL,WAAO,GAAG,KAAKO,QAAL,CAAcP,OAAd,EAAuB,UAAjC;AACD;;AAES,QAAJ9C,IAAI;AACR;AACA;AACA;AACA;AACA,SAAKsD,QAAL,GAAgB,KAAKA,QAAL,CAAcG,IAAd,CAAmB,MAAM,KAAKC,UAAL,EAAzB,CAAhB;AACA,WAAO,KAAKJ,QAAZ;AACD;;AAEuB,QAAVI,UAAU;AACtB;AACA;AACA;AACA;AACA,WAAO,KAAKtE,KAAL,KAAe,KAAKuE,QAA3B,EAAqC;AACnC,YAAMC,OAAO,GAAG,MAAM,KAAKP,QAAL,CAAcrD,IAAd,EAAtB,CADmC,CAEnC;;AACA,UAAI4D,OAAO,CAACjF,IAAZ,EAAkB;AAChB,eAAOiF,OAAP;AACD;;AACDjG,QAAE,CAACkG,OAAH,CAAWD,OAAO,CAAClF,KAAnB;AACD;;AACD,WAAO,KAAK2E,QAAL,CAAcrD,IAAd,EAAP;AACD;;AAxC0C;;AA2C7C,MAAMmC,YAAN,SAA8BvC,YAA9B,CAA6C;AAE3CiD,cAAsBQ,QAAtB,EAA2DM,QAA3D,EAA2E;AACzE;AADoB;AAAqC;AAD3D,iBAAQ,CAAR;AAGC;;AAEDb,SAAO;AACL,WAAO,GAAG,KAAKO,QAAL,CAAcP,OAAd,EAAuB,UAAjC;AACD;;AAES,QAAJ9C,IAAI;AACR,QAAI,KAAKZ,KAAL,MAAgB,KAAKuE,QAAzB,EAAmC;AACjC,aAAO;AAACjF,aAAK,EAAE,IAAR;AAAcC,YAAI,EAAE;AAApB,OAAP;AACD;;AACD,WAAO,KAAK0E,QAAL,CAAcrD,IAAd,EAAP;AACD;;AAf0C,C,CAkB7C;AACA;AACA;;;AACA,MAAM6B,qBAAN,SAAuCjC,YAAvC,CAAwD;AAKtDiD,cACcQ,QADd,EACmD1B,SADnD,EAEyC;AAAA,QAA3BmC,oBAA2B,uEAAJ,IAAI;AACvC;AAFY;AAAqC;AACrC;AAEZ,SAAKR,QAAL,GAAgBC,OAAO,CAACC,OAAR,CAAgB;AAAC9E,WAAK,EAAE,IAAR;AAAcC,UAAI,EAAE;AAApB,KAAhB,CAAhB;AACD;;AAEDmE,SAAO;AACL,WAAO,GAAG,KAAKO,QAAL,CAAcP,OAAd,EAAuB,mBAAjC;AACD;;AAES,QAAJ9C,IAAI;AACR;AACA;AACA;AACA;AACA,SAAKsD,QAAL,GAAgB,KAAKA,QAAL,CAAcG,IAAd,CAAmB,MAAM,KAAKC,UAAL,EAAzB,CAAhB;AACA,WAAO,KAAKJ,QAAZ;AACD;;AAEuB,QAAVI,UAAU;AACtB,UAAMK,KAAK,GAAQ,EAAnB;;AACA,WAAOA,KAAK,CAAChB,MAAN,GAAe,KAAKpB,SAA3B,EAAsC;AACpC,YAAMsB,IAAI,GAAG,MAAM,KAAKI,QAAL,CAAcrD,IAAd,EAAnB;;AACA,UAAIiD,IAAI,CAACtE,IAAT,EAAe;AACb,YAAI,KAAKmF,oBAAL,IAA6BC,KAAK,CAAChB,MAAN,GAAe,CAAhD,EAAmD;AACjD,iBAAO;AAACrE,iBAAK,EAAEqF,KAAR;AAAepF,gBAAI,EAAE;AAArB,WAAP;AACD;;AACD,eAAO;AAACD,eAAK,EAAE,IAAR;AAAcC,cAAI,EAAE;AAApB,SAAP;AACD;;AACDoF,WAAK,CAAC9D,IAAN,CAAWgD,IAAI,CAACvE,KAAhB;AACD;;AACD,WAAO;AAACA,WAAK,EAAEqF,KAAR;AAAepF,UAAI,EAAE;AAArB,KAAP;AACD;;AAtCqD;;AAyCxD,MAAMkC,cAAN,SAAgCjB,YAAhC,CAA+C;AAK7CiD,cACcQ,QADd,EAEc9C,SAFd,EAE8C;AAC5C;AAFY;AACA;AAEZ,SAAK+C,QAAL,GAAgBC,OAAO,CAACC,OAAR,CAAgB;AAAC9E,WAAK,EAAE,IAAR;AAAcC,UAAI,EAAE;AAApB,KAAhB,CAAhB;AACD;;AAEDmE,SAAO;AACL,WAAO,GAAG,KAAKO,QAAL,CAAcP,OAAd,EAAuB,YAAjC;AACD;;AAES,QAAJ9C,IAAI;AACR;AACA;AACA;AACA;AACA,SAAKsD,QAAL,GAAgB,KAAKA,QAAL,CAAcG,IAAd,CAAmB,MAAM,KAAKC,UAAL,EAAzB,CAAhB;AACA,WAAO,KAAKJ,QAAZ;AACD;;AAEuB,QAAVI,UAAU;AACtB,WAAO,IAAP,EAAa;AACX,YAAMT,IAAI,GAAG,MAAM,KAAKI,QAAL,CAAcrD,IAAd,EAAnB;;AACA,UAAIiD,IAAI,CAACtE,IAAL,IAAa,KAAK4B,SAAL,CAAe0C,IAAI,CAACvE,KAApB,CAAjB,EAA6C;AAC3C,eAAOuE,IAAP;AACD;;AACDtF,QAAE,CAACkG,OAAH,CAAWZ,IAAI,CAACvE,KAAhB;AACD;AACF;;AAjC4C;;AAoC/C,MAAMsC,WAAN,SAAgCpB,YAAhC,CAA+C;AAC7CiD,cACcQ,QADd,EAEctC,SAFd,EAEwC;AACtC;AAFY;AACA;AAEb;;AAED+B,SAAO;AACL,WAAO,GAAG,KAAKO,QAAL,CAAcP,OAAd,EAAuB,SAAjC;AACD;;AAES,QAAJ9C,IAAI;AACR,UAAMiD,IAAI,GAAG,MAAM,KAAKI,QAAL,CAAcrD,IAAd,EAAnB;;AACA,QAAIiD,IAAI,CAACtE,IAAT,EAAe;AACb,aAAO;AAACD,aAAK,EAAE,IAAR;AAAcC,YAAI,EAAE;AAApB,OAAP;AACD;;AACD,UAAMqF,YAAY,GAAGrG,EAAE,CAACsG,WAAH,CAAeC,qBAAf,CAAqCjB,IAAI,CAACvE,KAA1C,CAArB,CALQ,CAMR;AACA;AACA;AACA;AACA;AACA;;AACA,UAAMyF,MAAM,GAAG,KAAKpD,SAAL,CAAekC,IAAI,CAACvE,KAApB,CAAf;AACA,UAAM0F,aAAa,GAAGzG,EAAE,CAACsG,WAAH,CAAeC,qBAAf,CAAqCC,MAArC,CAAtB,CAbQ,CAeR;AACA;;AACA,SAAK,MAAME,CAAX,IAAgBL,YAAhB,EAA8B;AAC5B,UAAI,CAACrG,EAAE,CAACsG,WAAH,CAAeK,cAAf,CAA8BD,CAA9B,EAAiCD,aAAjC,CAAL,EAAsD;AACpDC,SAAC,CAACR,OAAF;AACD;AACF;;AACD,WAAO;AAACnF,WAAK,EAAEyF,MAAR;AAAgBxF,UAAI,EAAE;AAAtB,KAAP;AACD;;AAlC4C;;AAqC/C,MAAMgC,yBAAN,SAA2Cf,YAA3C,CAA0D;AAExDiD,cACcQ,QADd,EAEc3C,OAFd,EAEgD;AAC9C;AAFY;AACA;AAHd,iBAAQ,CAAR;AAKE,SAAK4C,QAAL,GAAgBC,OAAO,CAACC,OAAR,CAAgB;AAAC9E,WAAK,EAAE,IAAR;AAAcC,UAAI,EAAE;AAApB,KAAhB,CAAhB;AACD;;AAEDmE,SAAO;AACL,WAAO,GAAG,KAAKO,QAAL,CAAcP,OAAd,EAAuB,kBAAjC;AACD;;AAMS,QAAJ9C,IAAI;AACR;AACA;AACA;AACA;AACA,SAAKsD,QAAL,GAAgB,KAAKA,QAAL,CAAcG,IAAd,CAAmB,MAAM,KAAKC,UAAL,EAAzB,CAAhB;AACA,WAAO,KAAKJ,QAAZ;AACD;;AAEe,QAAVI,UAAU;AACd,WAAO,IAAP,EAAa;AACX,UAAI;AACF,eAAO,MAAM,KAAKL,QAAL,CAAcrD,IAAd,EAAb;AACD,OAFD,CAEE,OAAOmD,CAAP,EAAU;AACV,YAAI,CAAC,KAAKzC,OAAL,CAAayC,CAAb,CAAL,EAAsB;AACpB,iBAAO;AAACzE,iBAAK,EAAE,IAAR;AAAcC,gBAAI,EAAE;AAApB,WAAP;AACD,SAHS,CAIV;AAEA;AACA;AACA;;AACD;AACF;AACF;;AAzCuD;;AA4C1D,MAAMuC,gBAAN,SAAqCtB,YAArC,CAAoD;AAClDiD,cACcQ,QADd,EAEctC,SAFd,EAEiD;AAC/C;AAFY;AACA;AAEb;;AAED+B,SAAO;AACL,WAAO,GAAG,KAAKO,QAAL,CAAcP,OAAd,EAAuB,cAAjC;AACD;;AAES,QAAJ9C,IAAI;AACR,UAAMiD,IAAI,GAAG,MAAM,KAAKI,QAAL,CAAcrD,IAAd,EAAnB;;AACA,QAAIiD,IAAI,CAACtE,IAAT,EAAe;AACb,aAAO;AAACD,aAAK,EAAE,IAAR;AAAcC,YAAI,EAAE;AAApB,OAAP;AACD;;AACD,UAAMqF,YAAY,GAAGrG,EAAE,CAACsG,WAAH,CAAeC,qBAAf,CAAqCjB,IAAI,CAACvE,KAA1C,CAArB,CALQ,CAMR;AACA;AACA;AACA;AACA;AACA;;AACA,UAAMyF,MAAM,GAAG,MAAM,KAAKpD,SAAL,CAAekC,IAAI,CAACvE,KAApB,CAArB;AACA,UAAM0F,aAAa,GAAGzG,EAAE,CAACsG,WAAH,CAAeC,qBAAf,CAAqCC,MAArC,CAAtB,CAbQ,CAeR;AACA;;AACA,SAAK,MAAME,CAAX,IAAgBL,YAAhB,EAA8B;AAC5B,UAAI,CAACrG,EAAE,CAACsG,WAAH,CAAeK,cAAf,CAA8BD,CAA9B,EAAiCD,aAAjC,CAAL,EAAsD;AACpDC,SAAC,CAACR,OAAF;AACD;AACF;;AACD,WAAO;AAACnF,WAAK,EAAEyF,MAAR;AAAgBxF,UAAI,EAAE;AAAtB,KAAP;AACD;;AAlCiD,C,CAqCpD;AACA;;AAEA;;;;;;;;;;AAQA,OAAM,MAAgB4F,iBAAhB,SAA6C3E,YAA7C,CAA4D;AAQhEiD;AACE;AACA,SAAK2B,WAAL,GAAmB,IAAIvG,iBAAJ,EAAnB;AACA,SAAKqF,QAAL,GAAgBC,OAAO,CAACC,OAAR,CAAgB;AAAC9E,WAAK,EAAE,IAAR;AAAcC,UAAI,EAAE;AAApB,KAAhB,CAAhB;AACD;;AAES,QAAJqB,IAAI;AACR;AACA;AACA;AACA;AACA,SAAKsD,QAAL,GAAgB,KAAKA,QAAL,CAAcG,IAAd,CAAmB,MAAM,KAAKC,UAAL,EAAzB,CAAhB;AACA,WAAO,KAAKJ,QAAZ;AACD;;AAgBe,QAAVI,UAAU;AACd;AACA;AACA;AACA,WAAO,KAAKc,WAAL,CAAiBzB,MAAjB,OAA8B,CAArC,EAAwC;AACtC;AACA,UAAI,EAAC,MAAM,KAAK0B,IAAL,EAAP,CAAJ,EAAwB;AACtB,eAAO;AAAC/F,eAAK,EAAE,IAAR;AAAcC,cAAI,EAAE;AAApB,SAAP;AACD;AACF;;AACD,WAAO;AAACD,WAAK,EAAE,KAAK8F,WAAL,CAAiBE,KAAjB,EAAR;AAAkC/F,UAAI,EAAE;AAAxC,KAAP;AACD;;AAhD+D;;AAkDlE,MAAM2C,eAAN,SAAoCiD,iBAApC,CAAwD;AACtD1B,cACcQ,QADd,EAEctC,SAFd,EAE0C;AACxC;AAFY;AACA;AAEb;;AAED+B,SAAO;AACL,WAAO,GAAG,KAAKO,QAAL,CAAcP,OAAd,EAAuB,aAAjC;AACD;;AAES,QAAJ2B,IAAI;AACR,UAAMxB,IAAI,GAAG,MAAM,KAAKI,QAAL,CAAcrD,IAAd,EAAnB;;AACA,QAAIiD,IAAI,CAACtE,IAAT,EAAe;AACb,aAAO,KAAP;AACD;;AACD,UAAMqF,YAAY,GAAGrG,EAAE,CAACsG,WAAH,CAAeC,qBAAf,CAAqCjB,IAAI,CAACvE,KAA1C,CAArB,CALQ,CAMR;AACA;AACA;AACA;AACA;;AACA,UAAMiG,WAAW,GAAG,KAAK5D,SAAL,CAAekC,IAAI,CAACvE,KAApB,CAApB;AACA,UAAM0F,aAAa,GACfzG,EAAE,CAACsG,WAAH,CAAeC,qBAAf,CAAqCS,WAArC,CADJ;AAEA,SAAKH,WAAL,CAAiBI,OAAjB,CAAyBD,WAAzB,EAdQ,CAgBR;AACA;;AACA,SAAK,MAAMN,CAAX,IAAgBL,YAAhB,EAA8B;AAC5B,UAAI,CAACrG,EAAE,CAACsG,WAAH,CAAeK,cAAf,CAA8BD,CAA9B,EAAiCD,aAAjC,CAAL,EAAsD;AACpDC,SAAC,CAACR,OAAF;AACD;AACF;;AAED,WAAO,IAAP;AACD;;AApCqD;AAuCxD;;;;;;;;;;;AASA,OAAM,MAAO5E,eAAP,SAAkCW,YAAlC,CAAiD;AASrDiD,cACItD,SADJ,EAEqBP,gBAFrB,EAE6D;AAC3D;AADmB,6CAAwC,CAV7D;AACA;;AACQ,oBAAuC,IAAvC,CAQqD,CAN7D;;AACQ,oBAA4B,IAA5B;AAON,SAAK6F,aAAL,GAAqBtF,SAArB;AACD;;AAEDuD,SAAO;AACL,UAAMgC,iBAAiB,GAAG,6CAA1B;AACA,WAAO,GAAGA,iBAAiB,aAA3B;AACD;;AAES,QAAJ9E,IAAI;AACR,SAAKsD,QAAL,GAAgB,KAAKyB,aAAL,CAAmB,KAAKzB,QAAxB,CAAhB;AACA,WAAO,KAAKA,QAAZ;AACD;;AAE0B,QAAbyB,aAAa,CAACzB,QAAD,EAAqC;AAE9D;AACA;AACA;AACA;AACA;AACA,UAAMA,QAAN;;AACA,QAAI,KAAKpB,QAAL,IAAiB,IAArB,EAA2B;AACzB,YAAM8C,cAAc,GAAG,MAAM,KAAKH,aAAL,CAAmB7E,IAAnB,EAA7B;;AACA,UAAIgF,cAAc,CAACrG,IAAnB,EAAyB;AACvB;AACA,eAAO;AAACD,eAAK,EAAE,IAAR;AAAcC,cAAI,EAAE;AAApB,SAAP;AACD;;AACD,WAAKuD,QAAL,GAAgB8C,cAAc,CAACtG,KAA/B;;AACA,UAAI,KAAKM,gBAAL,IAAyB,IAA7B,EAAmC;AACjC,aAAKkD,QAAL,GAAgB,KAAKA,QAAL,CAAczB,YAAd,CAA2B,KAAKzB,gBAAhC,CAAhB;AACD;AACF;;AACD,UAAMiG,UAAU,GAAG,MAAM,KAAK/C,QAAL,CAAclC,IAAd,EAAzB;;AACA,QAAIiF,UAAU,CAACtG,IAAf,EAAqB;AACnB,WAAKuD,QAAL,GAAgB,IAAhB;AACA,aAAO,KAAK6C,aAAL,CAAmBzB,QAAnB,CAAP;AACD;;AACD,WAAO2B,UAAP;AACD;;AAnDoD;AAsDvD,WAAYxF,eAAZ;;AAAA,WAAYA,eAAZ,EAA2B;AACzBA;AACAA;AACAA,8DAHyB,CAGd;AACZ,CAJD,EAAYA,eAAe,KAAfA,eAAe,MAA3B;AAMA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AA6BA,MAAME,WAAN,SAAwDC,YAAxD,CAAuE;AAIrEiD,cACuBtD,SADvB,EAE2E;AAAA,QAApDC,YAAoD,uEAApBC,eAAe,CAACC,IAAI;AACzE;AAFqB;AACA;AALf,iBAAQ,CAAR;AACA,0BAA6C,IAA7C;AAMP;;AAEDoD,SAAO;AACL,UAAMgC,iBAAiB,GAAG,yCAA1B;AACA,WAAO,IAAIA,iBAAiB,UAA5B;AACD;;AAEsB,QAATI,SAAS,CAACC,UAAD,EAAuC;AAE5D;AACA;AACA,UAAMA,UAAN,CAJ4D,CAM5D;AACA;;AACA,QAAIC,YAAY,GAAG,CAAnB;AACA,QAAIC,aAAa,GAAG,CAApB;;AAEA,aAASC,OAAT,CAAiBC,SAAjB,EAA6C;AAC3C,UAAIA,SAAS,YAAY3F,YAAzB,EAAuC;AACrC,cAAME,MAAM,GAAGyF,SAAS,CAACvF,IAAV,EAAf;AACA,eAAO;AACLtB,eAAK,EAAEoB,MAAM,CAAC2D,IAAP,CAAY1D,CAAC,IAAG;AACrBqF,wBAAY;;AACZ,gBAAIrF,CAAC,CAACpB,IAAN,EAAY;AACV0G,2BAAa;AACd;;AACD,mBAAOtF,CAAC,CAACrB,KAAT;AACD,WANM,CADF;AAQL8G,iBAAO,EAAE;AARJ,SAAP;AAUD,OAZD,MAYO;AACL,eAAO;AAAC9G,eAAK,EAAE,IAAR;AAAc8G,iBAAO,EAAE;AAAvB,SAAP;AACD;AACF;;AAED,UAAMrB,MAAM,GAAM,MAAMrG,kBAAkB,CAAC,KAAKyB,SAAN,EAAiB+F,OAAjB,CAA1C;;AAEA,QAAIF,YAAY,KAAKC,aAArB,EAAoC;AAClC;AACA,aAAO;AAAC3G,aAAK,EAAE,IAAR;AAAcC,YAAI,EAAE;AAApB,OAAP;AACD;;AACD,QAAI0G,aAAa,GAAG,CAApB,EAAuB;AACrB,cAAQ,KAAK7F,YAAb;AACE,aAAKC,eAAe,CAACC,IAArB;AACE,gBAAM,IAAI+F,KAAJ,CACF,iDACA,yBAAyB,KAAKrG,KAAK,GAFjC,CAAN;;AAGF,aAAKK,eAAe,CAACiG,QAArB;AACE,iBAAO;AAAChH,iBAAK,EAAE,IAAR;AAAcC,gBAAI,EAAE;AAApB,WAAP;;AACF,aAAKc,eAAe,CAACkG,OAArB;AACA,gBARF,CASI;;AATJ;AAWD;;AAED,SAAKvG,KAAL;AACA,WAAO;AAACV,WAAK,EAAEyF,MAAR;AAAgBxF,UAAI,EAAE;AAAtB,KAAP;AACD;;AAES,QAAJqB,IAAI;AACR,SAAK4F,cAAL,GAAsB,KAAKV,SAAL,CAAe,KAAKU,cAApB,CAAtB;AACA,WAAO,KAAKA,cAAZ;AACD;;AAvEoE,C,CA0EvE;AACA;;AAEA;;;;;;;;;AAOA,OAAM,MAAOrD,gBAAP,SAAmC3C,YAAnC,CAAkD;AAGtDiD,cACcQ,QADd,EACmDf,UADnD,EACqE;AACnE;AADY;AAAqC;AAEjD,SAAKuD,MAAL,GAAc,IAAI3H,UAAJ,CAA2CoE,UAA3C,CAAd;AACD;;AAEDQ,SAAO;AACL,WAAO,GAAG,KAAKO,QAAL,CAAcP,OAAd,EAAuB,cAAjC;AACD;AAED;;;;;;AAIUgD,QAAM;AACd,WAAO,CAAC,KAAKD,MAAL,CAAYE,MAAZ,EAAR,EAA8B;AAC5B,YAAMC,CAAC,GAAG,KAAK3C,QAAL,CAAcrD,IAAd,EAAV;AACA,WAAK6F,MAAL,CAAY5F,IAAZ,CAAiB+F,CAAjB;AACD;AACF;;AAEDhG,MAAI;AACF,SAAK8F,MAAL,GADE,CAEF;AACA;AACA;;AACA,WAAO,KAAKD,MAAL,CAAYnB,KAAZ,EAAP;AACD;;AA9BqD;AAiCxD;;;;;;;AAMA,OAAM,MAAO/B,eAAP,SAAkCJ,gBAAlC,CAAqD;AAUzDM,cACcQ,QADd,EACmDZ,UADnD,EAEIC,IAFJ,EAEiB;AACf,UAAMW,QAAN,EAAgBZ,UAAhB;AAFY;AAAqC,iCAClC,CALjB;;AACQ,6BAAoB,KAApB;AAMN,SAAKwD,MAAL,GAAcrI,UAAU,CAACsI,IAAX,CAAgBxD,IAAI,IAAI/E,EAAE,CAACwI,IAAH,CAAQC,GAAR,GAAcC,QAAd,EAAxB,CAAd;AACA,SAAK/C,QAAL,GAAgBC,OAAO,CAACC,OAAR,CAAgB;AAAC9E,WAAK,EAAE,IAAR;AAAcC,UAAI,EAAE;AAApB,KAAhB,CAAhB;AACD;;AAES,QAAJqB,IAAI;AACR;AACA;AACA;AACA;AACA,SAAKsD,QAAL,GAAgB,KAAKA,QAAL,CAAcG,IAAd,CAAmB,MAAM,KAAKC,UAAL,EAAzB,CAAhB;AACA,WAAO,KAAKJ,QAAZ;AACD;;AAEOgD,WAAS,CAACC,GAAD,EAAY;AAC3B,WAAOC,IAAI,CAACC,KAAL,CAAW,KAAKR,MAAL,KAAgBM,GAA3B,CAAP;AACD;;AAESG,aAAW;AACnB,WAAO,KAAKJ,SAAL,CAAe,KAAKT,MAAL,CAAY9C,MAAZ,EAAf,CAAP;AACD;;AAEe,QAAVW,UAAU;AACd;AACA,QAAI,CAAC,KAAKiD,iBAAV,EAA6B;AAC3B,WAAKb,MAAL;AACD;;AACD,WAAO,CAAC,KAAKD,MAAL,CAAYe,OAAZ,EAAR,EAA+B;AAC7B,YAAMC,WAAW,GAAG,KAAKH,WAAL,EAApB;AACA,YAAM5G,MAAM,GAAG,MAAM,KAAK+F,MAAL,CAAYiB,aAAZ,CAA0BD,WAA1B,CAArB;;AACA,UAAI/G,MAAM,CAACnB,IAAX,EAAiB;AACf,aAAKgI,iBAAL,GAAyB,IAAzB;AACD,OAFD,MAEO;AACL,aAAKb,MAAL;AACA,eAAOhG,MAAP;AACD;AACF;;AACD,WAAO;AAACpB,WAAK,EAAE,IAAR;AAAcC,UAAI,EAAE;AAApB,KAAP;AACD;;AAnDwD","names":["tf","seedrandom","deepClone","deepMapAndAwaitAll","deepZip","zipToList","GrowingRingBuffer","RingBuffer","iteratorFromItems","items","ArrayIterator","iteratorFromIncrementing","start","i","iteratorFromFunction","value","done","func","FunctionCallIterator","iteratorFromConcatenated","baseIterators","baseErrorHandler","ChainedIterator","iteratorFromConcatenatedFunction","iteratorFunc","count","take","iteratorFromZipped","iterators","mismatchMode","ZipMismatchMode","FAIL","ZipIterator","LazyIterator","toArray","result","x","next","push","toArrayForTest","stream","prefetch","resolveFully","resolveWhile","predicate","shouldContinue","handleErrors","handler","ErrorHandlingLazyIterator","filter","FilterIterator","map","transform","MapIterator","mapAsync","AsyncMapIterator","serialMapAsync","serial","flatmap","FlatmapIterator","forEachAsync","f","serialForEach","rowMajorBatch","batchSize","smallLastBatch","RowMajorBatchIterator","columnMajorBatch","zipFn","rowBatches","concatenate","iterator","TakeIterator","skip","SkipIterator","bufferSize","PrefetchIterator","shuffle","windowSize","seed","ShuffleIterator","SerialIterator","constructor","summary","length","trav","item","nextFn","e","message","upstream","lastRead","Promise","resolve","then","serialNext","maxCount","skipped","dispose","enableSmallLastBatch","batch","inputTensors","tensor_util","getTensorsInContainer","mapped","outputTensors","t","isTensorInList","OneToManyIterator","outputQueue","pump","shift","mappedArray","pushAll","moreIterators","upstreamSummaries","readFromChain","iteratorResult","itemResult","nextState","afterState","numIterators","iteratorsDone","getNext","container","recurse","Error","SHORTEST","LONGEST","currentPromise","buffer","refill","isFull","v","random","alea","util","now","toString","randomInt","max","Math","floor","chooseIndex","upstreamExhausted","isEmpty","chosenIndex","shuffleExcise"],"sources":["/home/nadimakhtar97/smart-attendance-system/tfjs-data/src/iterators/lazy_iterator.ts"],"sourcesContent":["/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n *\n * =============================================================================\n */\n\nimport * as tf from '@tensorflow/tfjs-core';\nimport * as seedrandom from 'seedrandom';\n\nimport {Container} from '../types';\nimport {deepClone} from '../util/deep_clone';\nimport {deepMapAndAwaitAll, DeepMapAsyncResult, DeepMapResult, deepZip, zipToList} from '../util/deep_map';\nimport {GrowingRingBuffer} from '../util/growing_ring_buffer';\nimport {RingBuffer} from '../util/ring_buffer';\n\n/**\n * A nested structure of LazyIterators, used as the input to zip().\n */\nexport type IteratorContainer = Container<LazyIterator<tf.TensorContainer>>;\n\n// Here we implement a simple asynchronous iterator.\n// This lets us avoid using either third-party stream libraries or\n// recent TypeScript language support requiring polyfills.\n\n/**\n * Create a `LazyIterator` from an array of items.\n */\nexport function iteratorFromItems<T>(items: T[]): LazyIterator<T> {\n  return new ArrayIterator(items);\n}\n\n/**\n * Create a `LazyIterator` of incrementing integers.\n */\nexport function iteratorFromIncrementing(start: number): LazyIterator<number> {\n  let i = start;\n  return iteratorFromFunction(() => ({value: i++, done: false}));\n}\n\n/**\n * Create a `LazyIterator` from a function.\n *\n * ```js\n * let i = -1;\n * const func = () =>\n *    ++i < 5 ? {value: i, done: false} : {value: null, done: true};\n * const iter = tf.data.iteratorFromFunction(func);\n * await iter.forEachAsync(e => console.log(e));\n * ```\n *\n * @param func A function that produces data on each call.\n */\nexport function iteratorFromFunction<T>(\n    func: () =>\n        IteratorResult<T>| Promise<IteratorResult<T>>): LazyIterator<T> {\n  return new FunctionCallIterator(func);\n}\n\n/**\n * Create a `LazyIterator` by concatenating underlying streams, which are\n * themselves provided as a stream.\n *\n * This can also be thought of as a \"stream flatten\" operation.\n *\n * @param baseIterators A stream of streams to be concatenated.\n * @param baseErrorHandler An optional function that can intercept `Error`s\n *   raised during a `next()` call on the base stream.  This function can decide\n *   whether the error should be propagated, whether the error should be\n *   ignored, or whether the base stream should be terminated.\n */\nexport function iteratorFromConcatenated<T>(\n    baseIterators: LazyIterator<LazyIterator<T>>,\n    baseErrorHandler?: (e: Error) => boolean): LazyIterator<T> {\n  return new ChainedIterator(baseIterators, baseErrorHandler);\n}\n\n/**\n * Create a `LazyIterator` by concatenating streams produced by calling a\n * stream-generating function a given number of times.\n *\n * Since a `LazyIterator` is read-once, it cannot be repeated, but this\n * function can be used to achieve a similar effect:\n *\n *   LazyIterator.ofConcatenatedFunction(() => new MyIterator(), 6);\n *\n * @param iteratorFunc: A function that produces a new stream on each call.\n * @param count: The number of times to call the function.\n * @param baseErrorHandler An optional function that can intercept `Error`s\n *   raised during a `next()` call on the base stream.  This function can decide\n *   whether the error should be propagated, whether the error should be\n *   ignored, or whether the base stream should be terminated.\n */\nexport function iteratorFromConcatenatedFunction<T>(\n    iteratorFunc: () => IteratorResult<LazyIterator<T>>, count: number,\n    baseErrorHandler?: (e: Error) => boolean): LazyIterator<T> {\n  return iteratorFromConcatenated(\n      iteratorFromFunction(iteratorFunc).take(count), baseErrorHandler);\n}\n\n/**\n * Create a `LazyIterator` by zipping together an array, dict, or nested\n * structure of `LazyIterator`s (and perhaps additional constants).\n *\n * The underlying streams must provide elements in a consistent order such\n * that they correspond.\n *\n * Typically, the underlying streams should have the same number of\n * elements. If they do not, the behavior is determined by the\n * `mismatchMode` argument.\n *\n * The nested structure of the `iterators` argument determines the\n * structure of elements in the resulting iterator.\n *\n * @param iterators: An array or object containing LazyIterators at the\n * leaves.\n * @param mismatchMode: Determines what to do when one underlying iterator\n * is exhausted before the others.  `ZipMismatchMode.FAIL` (the default)\n * causes an error to be thrown in this case.  `ZipMismatchMode.SHORTEST`\n * causes the zipped iterator to terminate with the furst underlying\n * streams, so elements remaining on the longer streams are ignored.\n * `ZipMismatchMode.LONGEST` causes the zipped stream to continue, filling\n * in nulls for the exhausted streams, until all streams are exhausted.\n */\nexport function iteratorFromZipped<O extends tf.TensorContainer>(\n    iterators: IteratorContainer,\n    mismatchMode: ZipMismatchMode = ZipMismatchMode.FAIL): LazyIterator<O> {\n  return new ZipIterator<O>(iterators, mismatchMode);\n}\n\n/**\n * An asynchronous iterator, providing lazy access to a potentially\n * unbounded stream of elements.\n *\n * Iterator can be obtained from a dataset:\n * `const iter = await dataset.iterator();`\n */\nexport abstract class LazyIterator<T> {\n  // This class implements AsyncIterator<T>, but we have not yet set the\n  // TypeScript --downlevelIteration flag to enable that.\n\n  abstract summary(): string;\n\n  /**\n   * Returns a `Promise` for the next element in the stream.\n   *\n   * When an item can be provided successfully, the return value is\n   * `{value:T, done:false}`.\n   *\n   * Calling next() on a closed stream returns `{value:null, done:true}`.\n   */\n  abstract async next(): Promise<IteratorResult<T>>;\n\n  /**\n   * Collect all remaining elements of a bounded stream into an array.\n   * Obviously this will succeed only for small streams that fit in memory.\n   * Useful for testing.\n   *\n   * @returns A Promise for an array of stream elements, which will resolve\n   *   when the stream is exhausted.\n   */\n  async toArray(): Promise<T[]> {\n    const result: T[] = [];\n    let x = await this.next();\n    while (!x.done) {\n      result.push(x.value);\n      x = await this.next();\n    }\n    return result;\n  }\n\n  /**\n   * Collect all elements of this dataset into an array with prefetching 100\n   * elements. This is useful for testing, because the prefetch changes the\n   * order in which the Promises are resolved along the processing pipeline.\n   * This may help expose bugs where results are dependent on the order of\n   * Promise resolution rather than on the logical order of the stream (i.e.,\n   * due to hidden mutable state).\n   *\n   * @returns A Promise for an array of stream elements, which will resolve\n   *   when the stream is exhausted.\n   */\n  async toArrayForTest(): Promise<T[]> {\n    const stream = this.prefetch(100);\n    const result: T[] = [];\n    let x = await stream.next();\n    while (!x.done) {\n      result.push(x.value);\n      x = await stream.next();\n    }\n    return result;\n  }\n\n  /**\n   * Draw items from the stream until it is exhausted.\n   *\n   * This can be useful when the stream has side effects but no output.  In\n   * that case, calling this function guarantees that the stream will be\n   * fully processed.\n   */\n  async resolveFully(): Promise<void> {\n    let x = await this.next();\n    while (!x.done) {\n      x = await this.next();\n    }\n  }\n\n  /**\n   * Draw items from the stream until it is exhausted, or a predicate fails.\n   *\n   * This can be useful when the stream has side effects but no output.  In\n   * that case, calling this function guarantees that the stream will be\n   * fully processed.\n   */\n  async resolveWhile(predicate: (r: T) => boolean): Promise<void> {\n    let x = await this.next();\n    let shouldContinue = predicate(x.value);\n    while ((!x.done) && shouldContinue) {\n      x = await this.next();\n      shouldContinue = predicate(x.value);\n    }\n  }\n\n  /**\n   * Handles errors thrown on this stream using a provided handler function.\n   *\n   * @param handler A function that handles any `Error` thrown during a `next()`\n   *   call and returns true if the stream should continue (dropping the failed\n   *   call) or false if the stream should quietly terminate.  If the handler\n   *   itself throws (or rethrows) an `Error`, that will be propagated.\n   *\n   * @returns A `LazyIterator` of elements passed through from upstream,\n   *   possibly filtering or terminating on upstream `next()` calls that\n   *   throw an `Error`.\n   */\n  handleErrors(handler: (error: Error) => boolean): LazyIterator<T> {\n    return new ErrorHandlingLazyIterator(this, handler);\n  }\n\n  // TODO(soergel): Implement reduce() etc.\n\n  /**\n   * Filters this stream according to `predicate`.\n   *\n   * @param predicate A function mapping a stream element to a boolean or a\n   * `Promise` for one.\n   *\n   * @returns A `LazyIterator` of elements for which the predicate was true.\n   */\n  filter(predicate: (value: T) => boolean): LazyIterator<T> {\n    return new FilterIterator(this, predicate);\n  }\n\n  /**\n   * Maps this stream through a 1-to-1 transform.\n   *\n   * @param transform A function mapping a stream element to a transformed\n   *   element.\n   *\n   * @returns A `LazyIterator` of transformed elements.\n   */\n  map<O>(transform: (value: T) => O): LazyIterator<O> {\n    return new MapIterator(this, transform);\n  }\n\n  /**\n   * Maps this stream through an async 1-to-1 transform.\n   *\n   * @param transform A function mapping a stream element to a `Promise` for a\n   *   transformed stream element.\n   *\n   * @returns A `LazyIterator` of transformed elements.\n   */\n  mapAsync<O>(transform: (value: T) => Promise<O>): LazyIterator<O> {\n    return new AsyncMapIterator(this, transform);\n  }\n\n  /**\n   * Maps this stream through a 1-to-1 transform, forcing serial execution.\n   *\n   * @param transform A function mapping a stream element to a transformed\n   *   element.\n   *\n   * @returns A `LazyIterator` of transformed elements.\n   */\n  serialMapAsync<O>(transform: (value: T) => Promise<O>): LazyIterator<O> {\n    return new AsyncMapIterator(this, transform).serial();\n  }\n\n  /**\n   * Maps this stream through a 1-to-many transform.\n   *\n   * @param transform A function mapping a stream element to an array of\n   *   transformed elements.\n   *\n   * @returns A `DataStream` of transformed elements.\n   */\n  flatmap<O>(transform: (value: T) => O[]): LazyIterator<O> {\n    return new FlatmapIterator(this, transform);\n  }\n\n  /**\n   * Apply a function to every element of the stream.\n   *\n   * @param f A function to apply to each stream element.\n   */\n  async forEachAsync(f: (value: T) => void): Promise<void> {\n    return this.map(f).resolveFully();\n  }\n\n  /**\n   * Apply a function to every element of the stream, forcing serial execution.\n   *\n   * @param f A function to apply to each stream element.  Should return 'true'\n   *   to indicate that the stream should continue, or 'false' to cause it to\n   *   terminate.\n   */\n  async serialForEach(f: (value: T) => Promise<boolean>): Promise<void> {\n    return this.serialMapAsync(f).resolveWhile(x => (x === true));\n  }\n\n  /**\n   * Groups elements into batches, represented as arrays of elements.\n   *\n   * We can think of the elements of this iterator as 'rows' (even if they are\n   * nested structures).  By the same token, consecutive values for a given\n   * key within the elements form a 'column'.  This matches the usual sense of\n   * 'row' and 'column' when processing tabular data (e.g., parsing a CSV).\n   *\n   * Thus, \"Row-major\" means that the resulting batch is simply a collection of\n   * rows: `[row1, row2, row3, ...]`.  This is contrast to the column-major\n   * form, which is needed for vectorized computation.\n   *\n   * @param batchSize The number of elements desired per batch.\n   * @param smallLastBatch Whether to emit the final batch when it has fewer\n   *   than batchSize elements. Default true.\n   * @returns A `LazyIterator` of batches of elements, represented as arrays\n   *   of the original element type.\n   */\n  rowMajorBatch(batchSize: number, smallLastBatch = true): LazyIterator<T[]> {\n    return new RowMajorBatchIterator(this, batchSize, smallLastBatch);\n  }\n\n  /**\n   * Groups elements into batches, represented in column-major form.\n   *\n   * We can think of the elements of this iterator as 'rows' (even if they are\n   * nested structures).  By the same token, consecutive values for a given\n   * key within the elements form a 'column'.  This matches the usual sense of\n   * 'row' and 'column' when processing tabular data (e.g., parsing a CSV).\n   *\n   * Thus, \"column-major\" means that the resulting batch is a (potentially\n   * nested) structure representing the columns.  Each column entry, then,\n   * contains a collection of the values found in that column for a range of\n   * input elements.  This representation allows for vectorized computation, in\n   * contrast to the row-major form.\n   *\n   * The inputs should all have the same nested structure (i.e., of arrays and\n   * dicts).  The result is a single object with the same nested structure,\n   * where the leaves are arrays collecting the values of the inputs at that\n   * location (or, optionally, the result of a custom function applied to those\n   * arrays).\n   *\n   * @param batchSize The number of elements desired per batch.\n   * @param smallLastBatch Whether to emit the final batch when it has fewer\n   *   than batchSize elements. Default true.\n   * @param zipFn: (optional) A function that expects an array of elements at a\n   *   single node of the object tree, and returns a `DeepMapResult`.  The\n   *   `DeepMapResult` either provides a result value for that node (i.e.,\n   *   representing the subtree), or indicates that the node should be processed\n   *   recursively.  The default zipFn recurses as far as possible and places\n   *   arrays at the leaves.\n   * @returns A `LazyIterator` of batches of elements, represented as an object\n   *   with collections at the leaves.\n   */\n  columnMajorBatch(\n      batchSize: number, smallLastBatch = true,\n      // tslint:disable-next-line:no-any\n      zipFn: (xs: any[]) => DeepMapResult = zipToList):\n      LazyIterator<tf.TensorContainer> {\n    // First collect the desired number of input elements as a row-major batch.\n    const rowBatches = this.rowMajorBatch(batchSize, smallLastBatch);\n    // Now 'rotate' or 'pivot' the data, collecting all values from each column\n    // in the batch (i.e., for each key within the elements) into an array.\n    return rowBatches.map(x => deepZip(x, zipFn));\n  }\n\n  /**\n   * Concatenate this `LazyIterator` with another.\n   *\n   * @param iterator A `LazyIterator` to be concatenated onto this one.\n   * @param baseErrorHandler An optional function that can intercept `Error`s\n   *   raised during a `next()` call on the base stream.  This function can\n   *   decide whether the error should be propagated, whether the error should\n   *   be ignored, or whether the base stream should be terminated.\n   * @returns A `LazyIterator`.\n   */\n  concatenate(\n      iterator: LazyIterator<T>,\n      baseErrorHandler?: (e: Error) => boolean): LazyIterator<T> {\n    return new ChainedIterator(\n        iteratorFromItems([this, iterator]), baseErrorHandler);\n  }\n\n  /**\n   * Limits this stream to return at most `count` items.\n   *\n   * @param count The maximum number of items to provide from the stream. If\n   * a negative or undefined value is given, the entire stream is returned\n   *   unaltered.\n   */\n  take(count: number): LazyIterator<T> {\n    if (count < 0 || count == null) {\n      return this;\n    }\n    return new TakeIterator(this, count);\n  }\n\n  /**\n   * Skips the first `count` items in this stream.\n   *\n   * @param count The number of items to skip.  If a negative or undefined\n   * value is given, the entire stream is returned unaltered.\n   */\n  skip(count: number): LazyIterator<T> {\n    if (count < 0 || count == null) {\n      return this;\n    }\n    return new SkipIterator(this, count);\n  }\n\n  /**\n   * Prefetch the first `bufferSize` items in this stream.\n   *\n   * Note this prefetches Promises, but makes no guarantees about when those\n   * Promises resolve.\n   *\n   * @param bufferSize: An integer specifying the number of elements to be\n   *   prefetched.\n   */\n  prefetch(bufferSize: number): LazyIterator<T> {\n    return new PrefetchIterator(this, bufferSize);\n  }\n\n  // TODO(soergel): deep sharded shuffle, where supported\n\n  /**\n   * Randomly shuffles the elements of this stream.\n   *\n   * @param bufferSize: An integer specifying the number of elements from\n   * this stream from which the new stream will sample.\n   * @param seed: (Optional.) An integer specifying the random seed that\n   * will be used to create the distribution.\n   */\n  shuffle(windowSize: number, seed?: string): LazyIterator<T> {\n    return new ShuffleIterator(this, windowSize, seed);\n  }\n\n  /**\n   * Force an iterator to execute serially: each next() call will await the\n   * prior one, so that they cannot execute concurrently.\n   */\n  serial(): LazyIterator<T> {\n    return new SerialIterator(this);\n  }\n}\n\n// ============================================================================\n// The following private classes serve to implement the chainable methods\n// on LazyIterator.  Unfortunately they can't be placed in separate files,\n// due to resulting trouble with circular imports.\n// ============================================================================\n\n// Iterators that just extend LazyIterator directly\n// ============================================================================\n\nclass ArrayIterator<T> extends LazyIterator<T> {\n  private trav = 0;\n  constructor(protected items: T[]) {\n    super();\n  }\n\n  summary() {\n    return `Array of ${this.items.length} items`;\n  }\n\n  async next(): Promise<IteratorResult<T>> {\n    if (this.trav >= this.items.length) {\n      return {value: null, done: true};\n    }\n    const item = this.items[this.trav];\n    this.trav++;\n    return {value: deepClone(item), done: false};\n  }\n}\n\nclass FunctionCallIterator<T> extends LazyIterator<T> {\n  constructor(\n      protected nextFn: () => IteratorResult<T>| Promise<IteratorResult<T>>) {\n    super();\n  }\n\n  summary() {\n    return `Function call`;\n  }\n\n  async next(): Promise<IteratorResult<T>> {\n    try {\n      return this.nextFn();\n    } catch (e) {\n      // Modify the error message but leave the stack trace intact\n      e.message =\n          `Error thrown while iterating through a dataset: ${e.message}`;\n      throw e;\n    }\n  }\n}\n\nclass SerialIterator<T> extends LazyIterator<T> {\n  // Strict Promise execution order:\n  // a next() call may not even begin until the previous one completes.\n  private lastRead: Promise<IteratorResult<T>>;\n\n  constructor(protected upstream: LazyIterator<T>) {\n    super();\n    this.lastRead = Promise.resolve({value: null, done: false});\n  }\n\n  summary() {\n    return `${this.upstream.summary()} -> Serial`;\n  }\n\n  async next(): Promise<IteratorResult<T>> {\n    // This sets this.lastRead to a new Promise right away, as opposed to\n    // saying `await this.lastRead; this.lastRead = this.serialNext();` which\n    // would not work because this.nextRead would be updated only after the\n    // promise resolves.\n    this.lastRead = this.lastRead.then(() => this.serialNext());\n    return this.lastRead;\n  }\n\n  private async serialNext(): Promise<IteratorResult<T>> {\n    return this.upstream.next();\n  }\n}\n\nclass SkipIterator<T> extends LazyIterator<T> {\n  // Strict Promise execution order:\n  // a next() call may not even begin until the previous one completes.\n  private lastRead: Promise<IteratorResult<T>>;\n\n  // Local state that should not be clobbered by out-of-order execution.\n  count = 0;\n\n  constructor(protected upstream: LazyIterator<T>, protected maxCount: number) {\n    super();\n    this.lastRead = Promise.resolve({value: null, done: false});\n  }\n\n  summary() {\n    return `${this.upstream.summary()} -> Skip`;\n  }\n\n  async next(): Promise<IteratorResult<T>> {\n    // This sets this.lastRead to a new Promise right away, as opposed to\n    // saying `await this.lastRead; this.lastRead = this.serialNext();` which\n    // would not work because this.nextRead would be updated only after the\n    // promise resolves.\n    this.lastRead = this.lastRead.then(() => this.serialNext());\n    return this.lastRead;\n  }\n\n  private async serialNext(): Promise<IteratorResult<T>> {\n    // TODO(soergel): consider tradeoffs of reading in parallel, eg.\n    // collecting next() promises in an Array and then waiting for\n    // Promise.all() of those. Benefit: pseudo-parallel execution.  Drawback:\n    // maybe delayed GC.\n    while (this.count++ < this.maxCount) {\n      const skipped = await this.upstream.next();\n      // short-circuit if upstream is already empty\n      if (skipped.done) {\n        return skipped;\n      }\n      tf.dispose(skipped.value as {});\n    }\n    return this.upstream.next();\n  }\n}\n\nclass TakeIterator<T> extends LazyIterator<T> {\n  count = 0;\n  constructor(protected upstream: LazyIterator<T>, protected maxCount: number) {\n    super();\n  }\n\n  summary() {\n    return `${this.upstream.summary()} -> Take`;\n  }\n\n  async next(): Promise<IteratorResult<T>> {\n    if (this.count++ >= this.maxCount) {\n      return {value: null, done: true};\n    }\n    return this.upstream.next();\n  }\n}\n\n// Note this batch just groups items into row-wise element arrays.\n// Rotating these to a column-wise representation happens only at the dataset\n// level.\nclass RowMajorBatchIterator<T> extends LazyIterator<T[]> {\n  // Strict Promise execution order:\n  // a next() call may not even begin until the previous one completes.\n  private lastRead: Promise<IteratorResult<T[]>>;\n\n  constructor(\n      protected upstream: LazyIterator<T>, protected batchSize: number,\n      protected enableSmallLastBatch = true) {\n    super();\n    this.lastRead = Promise.resolve({value: null, done: false});\n  }\n\n  summary() {\n    return `${this.upstream.summary()} -> RowMajorBatch`;\n  }\n\n  async next(): Promise<IteratorResult<T[]>> {\n    // This sets this.lastRead to a new Promise right away, as opposed to\n    // saying `await this.lastRead; this.lastRead = this.serialNext();` which\n    // would not work because this.nextRead would be updated only after the\n    // promise resolves.\n    this.lastRead = this.lastRead.then(() => this.serialNext());\n    return this.lastRead;\n  }\n\n  private async serialNext(): Promise<IteratorResult<T[]>> {\n    const batch: T[] = [];\n    while (batch.length < this.batchSize) {\n      const item = await this.upstream.next();\n      if (item.done) {\n        if (this.enableSmallLastBatch && batch.length > 0) {\n          return {value: batch, done: false};\n        }\n        return {value: null, done: true};\n      }\n      batch.push(item.value);\n    }\n    return {value: batch, done: false};\n  }\n}\n\nclass FilterIterator<T> extends LazyIterator<T> {\n  // Strict Promise execution order:\n  // a next() call may not even begin until the previous one completes.\n  private lastRead: Promise<IteratorResult<T>>;\n\n  constructor(\n      protected upstream: LazyIterator<T>,\n      protected predicate: (value: T) => boolean) {\n    super();\n    this.lastRead = Promise.resolve({value: null, done: false});\n  }\n\n  summary() {\n    return `${this.upstream.summary()} -> Filter`;\n  }\n\n  async next(): Promise<IteratorResult<T>> {\n    // This sets this.lastRead to a new Promise right away, as opposed to\n    // saying `await this.lastRead; this.lastRead = this.serialNext();` which\n    // would not work because this.nextRead would be updated only after the\n    // promise resolves.\n    this.lastRead = this.lastRead.then(() => this.serialNext());\n    return this.lastRead;\n  }\n\n  private async serialNext(): Promise<IteratorResult<T>> {\n    while (true) {\n      const item = await this.upstream.next();\n      if (item.done || this.predicate(item.value)) {\n        return item;\n      }\n      tf.dispose(item.value as {});\n    }\n  }\n}\n\nclass MapIterator<I, O> extends LazyIterator<O> {\n  constructor(\n      protected upstream: LazyIterator<I>,\n      protected transform: (value: I) => O) {\n    super();\n  }\n\n  summary() {\n    return `${this.upstream.summary()} -> Map`;\n  }\n\n  async next(): Promise<IteratorResult<O>> {\n    const item = await this.upstream.next();\n    if (item.done) {\n      return {value: null, done: true};\n    }\n    const inputTensors = tf.tensor_util.getTensorsInContainer(item.value as {});\n    // Careful: the transform may mutate the item in place.\n    // That's why we have to remember the input Tensors above, and then\n    // below dispose only those that were not passed through to the output.\n    // Note too that the transform function is responsible for tidying\n    // any intermediate Tensors.  Here we are concerned only about the\n    // inputs.\n    const mapped = this.transform(item.value);\n    const outputTensors = tf.tensor_util.getTensorsInContainer(mapped as {});\n\n    // TODO(soergel) faster intersection\n    // TODO(soergel) move to tf.disposeExcept(in, out)?\n    for (const t of inputTensors) {\n      if (!tf.tensor_util.isTensorInList(t, outputTensors)) {\n        t.dispose();\n      }\n    }\n    return {value: mapped, done: false};\n  }\n}\n\nclass ErrorHandlingLazyIterator<T> extends LazyIterator<T> {\n  count = 0;\n  constructor(\n      protected upstream: LazyIterator<T>,\n      protected handler: (error: Error) => boolean) {\n    super();\n    this.lastRead = Promise.resolve({value: null, done: false});\n  }\n\n  summary() {\n    return `${this.upstream.summary()} -> handleErrors`;\n  }\n\n  // Strict Promise execution order:\n  // a next() call may not even begin until the previous one completes.\n  private lastRead: Promise<IteratorResult<T>>;\n\n  async next(): Promise<IteratorResult<T>> {\n    // This sets this.lastRead to a new Promise right away, as opposed to\n    // saying `await this.lastRead; this.lastRead = this.serialNext();` which\n    // would not work because this.nextRead would be updated only after the\n    // promise resolves.\n    this.lastRead = this.lastRead.then(() => this.serialNext());\n    return this.lastRead;\n  }\n\n  async serialNext(): Promise<IteratorResult<T>> {\n    while (true) {\n      try {\n        return await this.upstream.next();\n      } catch (e) {\n        if (!this.handler(e)) {\n          return {value: null, done: true};\n        }\n        // If the handler returns true, loop and fetch the next upstream item.\n\n        // If the upstream iterator throws an endless stream of errors, and if\n        // the handler says to ignore them, then we loop forever here.  That is\n        // the correct behavior-- it's up to the handler to decide when to stop.\n      }\n    }\n  }\n}\n\nclass AsyncMapIterator<I, O> extends LazyIterator<O> {\n  constructor(\n      protected upstream: LazyIterator<I>,\n      protected transform: (value: I) => Promise<O>) {\n    super();\n  }\n\n  summary() {\n    return `${this.upstream.summary()} -> AsyncMap`;\n  }\n\n  async next(): Promise<IteratorResult<O>> {\n    const item = await this.upstream.next();\n    if (item.done) {\n      return {value: null, done: true};\n    }\n    const inputTensors = tf.tensor_util.getTensorsInContainer(item.value as {});\n    // Careful: the transform may mutate the item in place.\n    // That's why we have to remember the input Tensors above, and then\n    // below dispose only those that were not passed through to the output.\n    // Note too that the transform function is responsible for tidying\n    // any intermediate Tensors.  Here we are concerned only about the\n    // inputs.\n    const mapped = await this.transform(item.value);\n    const outputTensors = tf.tensor_util.getTensorsInContainer(mapped as {});\n\n    // TODO(soergel) faster intersection\n    // TODO(soergel) move to tf.disposeExcept(in, out)?\n    for (const t of inputTensors) {\n      if (!tf.tensor_util.isTensorInList(t, outputTensors)) {\n        t.dispose();\n      }\n    }\n    return {value: mapped, done: false};\n  }\n}\n\n// Iterators that maintain a queue of pending items\n// ============================================================================\n\n/**\n * A base class for transforming streams that operate by maintaining an\n * output queue of elements that are ready to return via next().  This is\n * commonly required when the transformation is 1-to-many:  A call to next()\n * may trigger a call to the underlying stream, which will produce many\n * mapped elements of this stream-- of which we need to return only one, so\n * we have to queue the rest.\n */\nexport abstract class OneToManyIterator<T> extends LazyIterator<T> {\n  // Strict Promise execution order:\n  // a next() call may not even begin until the previous one completes.\n  private lastRead: Promise<IteratorResult<T>>;\n\n  // Local state that should not be clobbered by out-of-order execution.\n  protected outputQueue: RingBuffer<T>;\n\n  constructor() {\n    super();\n    this.outputQueue = new GrowingRingBuffer<T>();\n    this.lastRead = Promise.resolve({value: null, done: false});\n  }\n\n  async next(): Promise<IteratorResult<T>> {\n    // This sets this.lastRead to a new Promise right away, as opposed to\n    // saying `await this.lastRead; this.lastRead = this.serialNext();` which\n    // would not work because this.nextRead would be updated only after the\n    // promise resolves.\n    this.lastRead = this.lastRead.then(() => this.serialNext());\n    return this.lastRead;\n  }\n\n  /**\n   * Read one or more chunks from upstream and process them, possibly\n   * reading or writing a carryover, and adding processed items to the\n   * output queue.  Note it's possible that no items are added to the queue\n   * on a given pump() call, even if the upstream stream is not closed\n   * (e.g., because items are filtered).\n   *\n   * @return `true` if any action was taken, i.e. fetching items from the\n   *   upstream source OR adding items to the output queue.  `false` if the\n   *   upstream source is exhausted AND nothing was added to the queue\n   * (i.e., any remaining carryover).\n   */\n  protected abstract async pump(): Promise<boolean>;\n\n  async serialNext(): Promise<IteratorResult<T>> {\n    // Fetch so that the queue contains at least one item if possible.\n    // If the upstream source is exhausted, AND there are no items left in\n    // the output queue, then this stream is also exhausted.\n    while (this.outputQueue.length() === 0) {\n      // TODO(soergel): consider parallel reads.\n      if (!await this.pump()) {\n        return {value: null, done: true};\n      }\n    }\n    return {value: this.outputQueue.shift(), done: false};\n  }\n}\nclass FlatmapIterator<I, O> extends OneToManyIterator<O> {\n  constructor(\n      protected upstream: LazyIterator<I>,\n      protected transform: (value: I) => O[]) {\n    super();\n  }\n\n  summary() {\n    return `${this.upstream.summary()} -> Flatmap`;\n  }\n\n  async pump(): Promise<boolean> {\n    const item = await this.upstream.next();\n    if (item.done) {\n      return false;\n    }\n    const inputTensors = tf.tensor_util.getTensorsInContainer(item.value as {});\n    // Careful: the transform may mutate the item in place.\n    // that's why we have to remember the input Tensors above, and then\n    // below dispose only those that were not passed through to the output.\n    // Note too that the transform function is responsible for tidying any\n    // intermediate Tensors.  Here we are concerned only about the inputs.\n    const mappedArray = this.transform(item.value);\n    const outputTensors =\n        tf.tensor_util.getTensorsInContainer(mappedArray as {});\n    this.outputQueue.pushAll(mappedArray);\n\n    // TODO(soergel) faster intersection, and deduplicate outputTensors\n    // TODO(soergel) move to tf.disposeExcept(in, out)?\n    for (const t of inputTensors) {\n      if (!tf.tensor_util.isTensorInList(t, outputTensors)) {\n        t.dispose();\n      }\n    }\n\n    return true;\n  }\n}\n\n/**\n * Provides a `LazyIterator` that concatenates a stream of underlying\n * streams.\n *\n * Doing this in a concurrency-safe way requires some trickery.  In\n * particular, we want this stream to return the elements from the\n * underlying streams in the correct order according to when next() was\n * called, even if the resulting Promises resolve in a different order.\n */\nexport class ChainedIterator<T> extends LazyIterator<T> {\n  // Strict Promise execution order:\n  // a next() call may not even begin until the previous one completes.\n  private lastRead: Promise<IteratorResult<T>> = null;\n\n  // Local state that should not be clobbered by out-of-order execution.\n  private iterator: LazyIterator<T> = null;\n  private moreIterators: LazyIterator<LazyIterator<T>>;\n\n  constructor(\n      iterators: LazyIterator<LazyIterator<T>>,\n      private readonly baseErrorHandler?: (e: Error) => boolean) {\n    super();\n    this.moreIterators = iterators;\n  }\n\n  summary() {\n    const upstreamSummaries = 'TODO: fill in upstream of chained summaries';\n    return `${upstreamSummaries} -> Chained`;\n  }\n\n  async next(): Promise<IteratorResult<T>> {\n    this.lastRead = this.readFromChain(this.lastRead);\n    return this.lastRead;\n  }\n\n  private async readFromChain(lastRead: Promise<IteratorResult<T>>):\n      Promise<IteratorResult<T>> {\n    // Must await on the previous read since the previous read may have advanced\n    // the stream of streams, from which we need to read.\n    // This is unfortunate since we can't parallelize reads. Which means\n    // prefetching of chained streams is a no-op.\n    // One solution is to prefetch immediately upstream of this.\n    await lastRead;\n    if (this.iterator == null) {\n      const iteratorResult = await this.moreIterators.next();\n      if (iteratorResult.done) {\n        // No more streams to stream from.\n        return {value: null, done: true};\n      }\n      this.iterator = iteratorResult.value;\n      if (this.baseErrorHandler != null) {\n        this.iterator = this.iterator.handleErrors(this.baseErrorHandler);\n      }\n    }\n    const itemResult = await this.iterator.next();\n    if (itemResult.done) {\n      this.iterator = null;\n      return this.readFromChain(lastRead);\n    }\n    return itemResult;\n  }\n}\n\nexport enum ZipMismatchMode {\n  FAIL,      // require zipped streams to have the same length\n  SHORTEST,  // terminate zip when the first stream is exhausted\n  LONGEST    // use nulls for exhausted streams; use up the longest stream.\n}\n\n/**\n * Provides a `LazyIterator` that zips together an array, dict, or nested\n * structure of `LazyIterator`s (and perhaps additional constants).\n *\n * The underlying streams must provide elements in a consistent order such\n * that they correspond.\n *\n * Typically, the underlying streams should have the same number of\n * elements. If they do not, the behavior is determined by the\n * `mismatchMode` argument.\n *\n * The nested structure of the `iterators` argument determines the\n * structure of elements in the resulting iterator.\n *\n * Doing this in a concurrency-safe way requires some trickery.  In\n * particular, we want this stream to return the elements from the\n * underlying streams in the correct order according to when next() was\n * called, even if the resulting Promises resolve in a different order.\n *\n * @param iterators: An array or object containing LazyIterators at the\n * leaves.\n * @param mismatchMode: Determines what to do when one underlying iterator\n * is exhausted before the others.  `ZipMismatchMode.FAIL` (the default)\n * causes an error to be thrown in this case.  `ZipMismatchMode.SHORTEST`\n * causes the zipped iterator to terminate with the furst underlying\n * streams, so elements remaining on the longer streams are ignored.\n * `ZipMismatchMode.LONGEST` causes the zipped stream to continue, filling\n * in nulls for the exhausted streams, until all streams are exhausted.\n */\nclass ZipIterator<O extends tf.TensorContainer> extends LazyIterator<O> {\n  private count = 0;\n  private currentPromise: Promise<IteratorResult<O>> = null;\n\n  constructor(\n      protected readonly iterators: IteratorContainer,\n      protected readonly mismatchMode: ZipMismatchMode = ZipMismatchMode.FAIL) {\n    super();\n  }\n\n  summary() {\n    const upstreamSummaries = 'TODO: fill in upstream of zip summaries';\n    return `{${upstreamSummaries}} -> Zip`;\n  }\n\n  private async nextState(afterState: Promise<IteratorResult<O>>):\n      Promise<IteratorResult<O>> {\n    // This chaining ensures that the underlying next() are not even called\n    // before the previous ones have resolved.\n    await afterState;\n\n    // Collect underlying iterator \"done\" signals as a side effect in\n    // getNext()\n    let numIterators = 0;\n    let iteratorsDone = 0;\n\n    function getNext(container: IteratorContainer): DeepMapAsyncResult {\n      if (container instanceof LazyIterator) {\n        const result = container.next();\n        return {\n          value: result.then(x => {\n            numIterators++;\n            if (x.done) {\n              iteratorsDone++;\n            }\n            return x.value;\n          }),\n          recurse: false\n        };\n      } else {\n        return {value: null, recurse: true};\n      }\n    }\n\n    const mapped: O = await deepMapAndAwaitAll(this.iterators, getNext);\n\n    if (numIterators === iteratorsDone) {\n      // The streams have all ended.\n      return {value: null, done: true};\n    }\n    if (iteratorsDone > 0) {\n      switch (this.mismatchMode) {\n        case ZipMismatchMode.FAIL:\n          throw new Error(\n              'Zipped streams should have the same length. ' +\n              `Mismatched at element ${this.count}.`);\n        case ZipMismatchMode.SHORTEST:\n          return {value: null, done: true};\n        case ZipMismatchMode.LONGEST:\n        default:\n          // Continue.  The exhausted streams already produced value: null.\n      }\n    }\n\n    this.count++;\n    return {value: mapped, done: false};\n  }\n\n  async next(): Promise<IteratorResult<O>> {\n    this.currentPromise = this.nextState(this.currentPromise);\n    return this.currentPromise;\n  }\n}\n\n// Iterators that maintain a ring buffer of pending promises\n// ============================================================================\n\n/**\n * A stream that prefetches a given number of items from an upstream source,\n * returning them in FIFO order.\n *\n * Note this prefetches Promises, but makes no guarantees about when those\n * Promises resolve.\n */\nexport class PrefetchIterator<T> extends LazyIterator<T> {\n  protected buffer: RingBuffer<Promise<IteratorResult<T>>>;\n\n  constructor(\n      protected upstream: LazyIterator<T>, protected bufferSize: number) {\n    super();\n    this.buffer = new RingBuffer<Promise<IteratorResult<T>>>(bufferSize);\n  }\n\n  summary() {\n    return `${this.upstream.summary()} -> Prefetch`;\n  }\n\n  /**\n   * Refill the prefetch buffer.  Returns only after the buffer is full, or\n   * the upstream source is exhausted.\n   */\n  protected refill() {\n    while (!this.buffer.isFull()) {\n      const v = this.upstream.next();\n      this.buffer.push(v);\n    }\n  }\n\n  next(): Promise<IteratorResult<T>> {\n    this.refill();\n    // This shift will never throw an error because the buffer is always\n    // full after a refill. If the stream is exhausted, the buffer will be\n    // full of Promises that will resolve to the end-of-stream signal.\n    return this.buffer.shift();\n  }\n}\n\n/**\n * A stream that performs a sliding-window random shuffle on an upstream\n * source. This is like a `PrefetchIterator` except that the items are\n * returned in randomized order.  Mixing naturally improves as the buffer\n * size increases.\n */\nexport class ShuffleIterator<T> extends PrefetchIterator<T> {\n  private readonly random: seedrandom.prng;\n\n  // Strict Promise execution order:\n  // a next() call may not even begin until the previous one completes.\n  private lastRead: Promise<IteratorResult<T>>;\n\n  // Local state that should not be clobbered by out-of-order execution.\n  private upstreamExhausted = false;\n\n  constructor(\n      protected upstream: LazyIterator<T>, protected windowSize: number,\n      seed?: string) {\n    super(upstream, windowSize);\n    this.random = seedrandom.alea(seed || tf.util.now().toString());\n    this.lastRead = Promise.resolve({value: null, done: false});\n  }\n\n  async next(): Promise<IteratorResult<T>> {\n    // This sets this.lastRead to a new Promise right away, as opposed to\n    // saying `await this.lastRead; this.lastRead = this.serialNext();` which\n    // would not work because this.nextRead would be updated only after the\n    // promise resolves.\n    this.lastRead = this.lastRead.then(() => this.serialNext());\n    return this.lastRead;\n  }\n\n  private randomInt(max: number) {\n    return Math.floor(this.random() * max);\n  }\n\n  protected chooseIndex(): number {\n    return this.randomInt(this.buffer.length());\n  }\n\n  async serialNext(): Promise<IteratorResult<T>> {\n    // TODO(soergel): consider performance\n    if (!this.upstreamExhausted) {\n      this.refill();\n    }\n    while (!this.buffer.isEmpty()) {\n      const chosenIndex = this.chooseIndex();\n      const result = await this.buffer.shuffleExcise(chosenIndex);\n      if (result.done) {\n        this.upstreamExhausted = true;\n      } else {\n        this.refill();\n        return result;\n      }\n    }\n    return {value: null, done: true};\n  }\n}\n"]},"metadata":{},"sourceType":"module"}