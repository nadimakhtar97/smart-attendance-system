{"ast":null,"code":"/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { env, Slice, slice_util, util } from '@tensorflow/tfjs-core';\nimport { sliceImplCPU } from '../kernel_utils/shared';\nimport { SliceProgram } from '../slice_gpu';\nimport { SlicePackedProgram } from '../slice_packed_gpu';\n\nfunction shallowSlice(x, begin, size, backend) {\n  const xTexData = backend.texData.get(x.dataId);\n  const t = backend.makeTensorInfo(size, x.dtype);\n  const newTexData = backend.texData.get(t.dataId); // Copy texture data from the original tensor.\n\n  Object.assign(newTexData, xTexData);\n  newTexData.refCount = 1;\n  newTexData.shape = size;\n  newTexData.dtype = x.dtype;\n  let flatOffset = slice_util.computeFlatOffset(begin, util.computeStrides(x.shape));\n\n  if (xTexData.slice) {\n    // We are slicing an already sliced tensor, so we have to accumulate\n    // the offset.\n    flatOffset += xTexData.slice.flatOffset;\n  }\n\n  newTexData.slice = {\n    flatOffset,\n    // Point to the original dataId, which is used to do ref counting.\n    origDataId: xTexData.slice && xTexData.slice.origDataId || x.dataId\n  }; // Increase the ref count for that data bucket.\n\n  const refCount = backend.dataRefCount.get(newTexData.slice.origDataId) || 1;\n  backend.dataRefCount.set(newTexData.slice.origDataId, refCount + 1);\n  return t;\n}\n\nexport function slice(args) {\n  const {\n    inputs,\n    backend,\n    attrs\n  } = args;\n  const {\n    x\n  } = inputs;\n  const {\n    begin,\n    size\n  } = attrs;\n  const [$begin, $size] = slice_util.parseSliceParams(x, begin, size);\n  slice_util.assertParamsValid(x, $begin, $size);\n\n  if (util.sizeFromShape($size) === 0) {\n    return backend.makeTensorInfo($size, x.dtype, []);\n  } // Run on cpu if dtype is string. For string, the backend represents it\n  // as Uint8Array[], where each Uint8Array is a character. Given that the\n  // computation is only on the outer array, uploading the whole data onto\n  // gpu is wasteful. Also, currently webgl doesn't have a design to\n  // upload and retrieve Uint8Array[] between cpu and gpu. Therefore, we\n  // just run the kernel on cpu if dtype is string.\n\n\n  if (backend.shouldExecuteOnCPU([x]) || x.dtype === 'string') {\n    const xTexData = backend.texData.get(x.dataId);\n    const outValues = sliceImplCPU(xTexData.values, $begin, $size, x.shape, x.dtype);\n    return backend.makeTensorInfo($size, x.dtype, outValues);\n  }\n\n  const {\n    isPacked\n  } = backend.texData.get(x.dataId);\n  const isContinous = slice_util.isSliceContinous(x.shape, $begin, $size);\n\n  if (isPacked || !isContinous) {\n    const program = env().getBool('WEBGL_PACK_ARRAY_OPERATIONS') ? new SlicePackedProgram($size) : new SliceProgram($size);\n    const customValues = [$begin];\n    return backend.runWebGLProgram(program, [x], x.dtype, customValues);\n  }\n\n  backend.uploadToGPU(x.dataId);\n  return shallowSlice(x, $begin, $size, backend);\n}\nexport const sliceConfig = {\n  kernelName: Slice,\n  backendName: 'webgl',\n  kernelFunc: slice\n};","map":{"version":3,"mappings":"AAAA;;;;;;;;;;;;;;;;AAiBA,SAAQA,GAAR,EAAuCC,KAAvC,EAA8CC,UAA9C,EAA2GC,IAA3G,QAAsH,uBAAtH;AAGA,SAAQC,YAAR,QAA2B,wBAA3B;AACA,SAAQC,YAAR,QAA2B,cAA3B;AACA,SAAQC,kBAAR,QAAiC,qBAAjC;;AAEA,SAASC,YAAT,CACIC,CADJ,EACmBC,KADnB,EACoCC,IADpC,EACoDC,OADpD,EAC6E;AAC3E,QAAMC,QAAQ,GAAGD,OAAO,CAACE,OAAR,CAAgBC,GAAhB,CAAoBN,CAAC,CAACO,MAAtB,CAAjB;AACA,QAAMC,CAAC,GAAGL,OAAO,CAACM,cAAR,CAAuBP,IAAvB,EAA6BF,CAAC,CAACU,KAA/B,CAAV;AACA,QAAMC,UAAU,GAAGR,OAAO,CAACE,OAAR,CAAgBC,GAAhB,CAAoBE,CAAC,CAACD,MAAtB,CAAnB,CAH2E,CAI3E;;AACAK,QAAM,CAACC,MAAP,CAAcF,UAAd,EAA0BP,QAA1B;AACAO,YAAU,CAACG,QAAX,GAAsB,CAAtB;AACAH,YAAU,CAACI,KAAX,GAAmBb,IAAnB;AACAS,YAAU,CAACD,KAAX,GAAmBV,CAAC,CAACU,KAArB;AACA,MAAIM,UAAU,GACVtB,UAAU,CAACuB,iBAAX,CAA6BhB,KAA7B,EAAoCN,IAAI,CAACuB,cAAL,CAAoBlB,CAAC,CAACe,KAAtB,CAApC,CADJ;;AAEA,MAAIX,QAAQ,CAACe,KAAb,EAAoB;AAClB;AACA;AACAH,cAAU,IAAIZ,QAAQ,CAACe,KAAT,CAAeH,UAA7B;AACD;;AACDL,YAAU,CAACQ,KAAX,GAAmB;AACjBH,cADiB;AAEjB;AACAI,cAAU,EAAEhB,QAAQ,CAACe,KAAT,IAAkBf,QAAQ,CAACe,KAAT,CAAeC,UAAjC,IAA+CpB,CAAC,CAACO;AAH5C,GAAnB,CAhB2E,CAsB3E;;AACA,QAAMO,QAAQ,GAAGX,OAAO,CAACkB,YAAR,CAAqBf,GAArB,CAAyBK,UAAU,CAACQ,KAAX,CAAiBC,UAA1C,KAAyD,CAA1E;AACAjB,SAAO,CAACkB,YAAR,CAAqBC,GAArB,CAAyBX,UAAU,CAACQ,KAAX,CAAiBC,UAA1C,EAAsDN,QAAQ,GAAG,CAAjE;AACA,SAAON,CAAP;AACD;;AAED,OAAM,SAAUW,KAAV,CACFI,IADE,EACuE;AAE3E,QAAM;AAACC,UAAD;AAASrB,WAAT;AAAkBsB;AAAlB,MAA2BF,IAAjC;AACA,QAAM;AAACvB;AAAD,MAAMwB,MAAZ;AACA,QAAM;AAACvB,SAAD;AAAQC;AAAR,MAAgBuB,KAAtB;AAEA,QAAM,CAACC,MAAD,EAASC,KAAT,IAAkBjC,UAAU,CAACkC,gBAAX,CAA4B5B,CAA5B,EAA+BC,KAA/B,EAAsCC,IAAtC,CAAxB;AACAR,YAAU,CAACmC,iBAAX,CAA6B7B,CAA7B,EAAgC0B,MAAhC,EAAwCC,KAAxC;;AAEA,MAAIhC,IAAI,CAACmC,aAAL,CAAmBH,KAAnB,MAA8B,CAAlC,EAAqC;AACnC,WAAOxB,OAAO,CAACM,cAAR,CAAuBkB,KAAvB,EAA8B3B,CAAC,CAACU,KAAhC,EAAuC,EAAvC,CAAP;AACD,GAX0E,CAa3E;AACA;AACA;AACA;AACA;AACA;;;AACA,MAAIP,OAAO,CAAC4B,kBAAR,CAA2B,CAAC/B,CAAD,CAA3B,KAAmCA,CAAC,CAACU,KAAF,KAAY,QAAnD,EAA6D;AAC3D,UAAMN,QAAQ,GAAGD,OAAO,CAACE,OAAR,CAAgBC,GAAhB,CAAoBN,CAAC,CAACO,MAAtB,CAAjB;AACA,UAAMyB,SAAS,GAAGpC,YAAY,CAC1BQ,QAAQ,CAAC6B,MADiB,EACKP,MADL,EACaC,KADb,EACoB3B,CAAC,CAACe,KADtB,EAC6Bf,CAAC,CAACU,KAD/B,CAA9B;AAEA,WAAOP,OAAO,CAACM,cAAR,CAAuBkB,KAAvB,EAA8B3B,CAAC,CAACU,KAAhC,EAAuCsB,SAAvC,CAAP;AACD;;AAED,QAAM;AAACE;AAAD,MAAa/B,OAAO,CAACE,OAAR,CAAgBC,GAAhB,CAAoBN,CAAC,CAACO,MAAtB,CAAnB;AACA,QAAM4B,WAAW,GAAGzC,UAAU,CAAC0C,gBAAX,CAA4BpC,CAAC,CAACe,KAA9B,EAAqCW,MAArC,EAA6CC,KAA7C,CAApB;;AACA,MAAIO,QAAQ,IAAI,CAACC,WAAjB,EAA8B;AAC5B,UAAME,OAAO,GAAG7C,GAAG,GAAG8C,OAAN,CAAc,6BAAd,IACZ,IAAIxC,kBAAJ,CAAuB6B,KAAvB,CADY,GAEZ,IAAI9B,YAAJ,CAAiB8B,KAAjB,CAFJ;AAGA,UAAMY,YAAY,GAAG,CAACb,MAAD,CAArB;AACA,WAAOvB,OAAO,CAACqC,eAAR,CAAwBH,OAAxB,EAAiC,CAACrC,CAAD,CAAjC,EAAsCA,CAAC,CAACU,KAAxC,EAA+C6B,YAA/C,CAAP;AACD;;AACDpC,SAAO,CAACsC,WAAR,CAAoBzC,CAAC,CAACO,MAAtB;AACA,SAAOR,YAAY,CAACC,CAAD,EAAI0B,MAAJ,EAAYC,KAAZ,EAAmBxB,OAAnB,CAAnB;AACD;AAED,OAAO,MAAMuC,WAAW,GAAiB;AACvCC,YAAU,EAAElD,KAD2B;AAEvCmD,aAAW,EAAE,OAF0B;AAGvCC,YAAU,EAAE1B;AAH2B,CAAlC","names":["env","Slice","slice_util","util","sliceImplCPU","SliceProgram","SlicePackedProgram","shallowSlice","x","begin","size","backend","xTexData","texData","get","dataId","t","makeTensorInfo","dtype","newTexData","Object","assign","refCount","shape","flatOffset","computeFlatOffset","computeStrides","slice","origDataId","dataRefCount","set","args","inputs","attrs","$begin","$size","parseSliceParams","assertParamsValid","sizeFromShape","shouldExecuteOnCPU","outValues","values","isPacked","isContinous","isSliceContinous","program","getBool","customValues","runWebGLProgram","uploadToGPU","sliceConfig","kernelName","backendName","kernelFunc"],"sources":["/home/nadimakhtar97/smart-attendance-system/tfjs-backend-webgl/src/kernels/Slice.ts"],"sourcesContent":["/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {env, KernelConfig, KernelFunc, Slice, slice_util, SliceAttrs, SliceInputs, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendWebGL} from '../backend_webgl';\nimport {sliceImplCPU} from '../kernel_utils/shared';\nimport {SliceProgram} from '../slice_gpu';\nimport {SlicePackedProgram} from '../slice_packed_gpu';\n\nfunction shallowSlice(\n    x: TensorInfo, begin: number[], size: number[], backend: MathBackendWebGL) {\n  const xTexData = backend.texData.get(x.dataId);\n  const t = backend.makeTensorInfo(size, x.dtype);\n  const newTexData = backend.texData.get(t.dataId);\n  // Copy texture data from the original tensor.\n  Object.assign(newTexData, xTexData);\n  newTexData.refCount = 1;\n  newTexData.shape = size;\n  newTexData.dtype = x.dtype;\n  let flatOffset =\n      slice_util.computeFlatOffset(begin, util.computeStrides(x.shape));\n  if (xTexData.slice) {\n    // We are slicing an already sliced tensor, so we have to accumulate\n    // the offset.\n    flatOffset += xTexData.slice.flatOffset;\n  }\n  newTexData.slice = {\n    flatOffset,\n    // Point to the original dataId, which is used to do ref counting.\n    origDataId: xTexData.slice && xTexData.slice.origDataId || x.dataId\n  };\n\n  // Increase the ref count for that data bucket.\n  const refCount = backend.dataRefCount.get(newTexData.slice.origDataId) || 1;\n  backend.dataRefCount.set(newTexData.slice.origDataId, refCount + 1);\n  return t;\n}\n\nexport function slice(\n    args: {inputs: SliceInputs, backend: MathBackendWebGL, attrs: SliceAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {begin, size} = attrs;\n\n  const [$begin, $size] = slice_util.parseSliceParams(x, begin, size);\n  slice_util.assertParamsValid(x, $begin, $size);\n\n  if (util.sizeFromShape($size) === 0) {\n    return backend.makeTensorInfo($size, x.dtype, []);\n  }\n\n  // Run on cpu if dtype is string. For string, the backend represents it\n  // as Uint8Array[], where each Uint8Array is a character. Given that the\n  // computation is only on the outer array, uploading the whole data onto\n  // gpu is wasteful. Also, currently webgl doesn't have a design to\n  // upload and retrieve Uint8Array[] between cpu and gpu. Therefore, we\n  // just run the kernel on cpu if dtype is string.\n  if (backend.shouldExecuteOnCPU([x]) || x.dtype === 'string') {\n    const xTexData = backend.texData.get(x.dataId);\n    const outValues = sliceImplCPU(\n        xTexData.values as TypedArray, $begin, $size, x.shape, x.dtype);\n    return backend.makeTensorInfo($size, x.dtype, outValues);\n  }\n\n  const {isPacked} = backend.texData.get(x.dataId);\n  const isContinous = slice_util.isSliceContinous(x.shape, $begin, $size);\n  if (isPacked || !isContinous) {\n    const program = env().getBool('WEBGL_PACK_ARRAY_OPERATIONS') ?\n        new SlicePackedProgram($size) :\n        new SliceProgram($size);\n    const customValues = [$begin];\n    return backend.runWebGLProgram(program, [x], x.dtype, customValues);\n  }\n  backend.uploadToGPU(x.dataId);\n  return shallowSlice(x, $begin, $size, backend);\n}\n\nexport const sliceConfig: KernelConfig = {\n  kernelName: Slice,\n  backendName: 'webgl',\n  kernelFunc: slice as {} as KernelFunc\n};\n"]},"metadata":{},"sourceType":"module"}