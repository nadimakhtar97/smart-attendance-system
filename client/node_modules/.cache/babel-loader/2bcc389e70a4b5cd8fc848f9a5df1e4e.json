{"ast":null,"code":"/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { Pow } from '../kernel_names';\nimport * as broadcast_util from '../ops/broadcast_util';\nimport { cast } from '../ops/cast';\nimport { greater } from '../ops/greater';\nimport { log } from '../ops/log';\nimport { mul } from '../ops/mul';\nimport { pow } from '../ops/pow';\nimport { reshape } from '../ops/reshape';\nimport { scalar } from '../ops/scalar';\nimport { sub } from '../ops/sub';\nimport { sum } from '../ops/sum';\nimport { where } from '../ops/where';\nimport { zerosLike } from '../ops/zeros_like';\nexport const powGradConfig = {\n  kernelName: Pow,\n  inputsToSave: ['a', 'b'],\n  outputsToSave: [true],\n  gradFunc: (dy, saved) => {\n    const [a, b, y] = saved;\n    const base = a;\n    const exp = b;\n    const outShape = broadcast_util.assertAndGetBroadcastShape(base.shape, exp.shape);\n\n    const derBase = () => {\n      const expFloat = cast(exp, 'float32');\n      let res = mul(dy, mul(expFloat, pow(base, sub(expFloat, scalar(1)))));\n      const reduceAxes = broadcast_util.getReductionAxes(base.shape, outShape);\n\n      if (reduceAxes.length > 0) {\n        res = sum(res, reduceAxes);\n      }\n\n      return reshape(res, base.shape);\n    };\n\n    const derExp = () => {\n      const condition = greater(base, 0);\n      const logBase = where(condition, log(base), zerosLike(base));\n      let res = mul(dy, mul(y, logBase));\n      const reduceAxes = broadcast_util.getReductionAxes(exp.shape, outShape);\n\n      if (reduceAxes.length > 0) {\n        res = sum(res, reduceAxes);\n      }\n\n      return reshape(res, exp.shape);\n    };\n\n    return {\n      a: derBase,\n      b: derExp\n    };\n  }\n};","map":{"version":3,"mappings":"AAAA;;;;;;;;;;;;;;;;AAgBA,SAAQA,GAAR,QAAkB,iBAAlB;AAEA,OAAO,KAAKC,cAAZ,MAAgC,uBAAhC;AACA,SAAQC,IAAR,QAAmB,aAAnB;AACA,SAAQC,OAAR,QAAsB,gBAAtB;AACA,SAAQC,GAAR,QAAkB,YAAlB;AACA,SAAQC,GAAR,QAAkB,YAAlB;AACA,SAAQC,GAAR,QAAkB,YAAlB;AACA,SAAQC,OAAR,QAAsB,gBAAtB;AACA,SAAQC,MAAR,QAAqB,eAArB;AACA,SAAQC,GAAR,QAAkB,YAAlB;AACA,SAAQC,GAAR,QAAkB,YAAlB;AACA,SAAQC,KAAR,QAAoB,cAApB;AACA,SAAQC,SAAR,QAAwB,mBAAxB;AAGA,OAAO,MAAMC,aAAa,GAAe;AACvCC,YAAU,EAAEd,GAD2B;AAEvCe,cAAY,EAAE,CAAC,GAAD,EAAM,GAAN,CAFyB;AAGvCC,eAAa,EAAE,CAAC,IAAD,CAHwB;AAIvCC,UAAQ,EAAE,CAACC,EAAD,EAAaC,KAAb,KAAgC;AACxC,UAAM,CAACC,CAAD,EAAIC,CAAJ,EAAOC,CAAP,IAAYH,KAAlB;AACA,UAAMI,IAAI,GAAGH,CAAb;AACA,UAAMI,GAAG,GAAGH,CAAZ;AACA,UAAMI,QAAQ,GACVxB,cAAc,CAACyB,0BAAf,CAA0CH,IAAI,CAACI,KAA/C,EAAsDH,GAAG,CAACG,KAA1D,CADJ;;AAGA,UAAMC,OAAO,GAAG,MAAK;AACnB,YAAMC,QAAQ,GAAG3B,IAAI,CAACsB,GAAD,EAAM,SAAN,CAArB;AACA,UAAIM,GAAG,GAAGzB,GAAG,CAACa,EAAD,EAAKb,GAAG,CAACwB,QAAD,EAAWvB,GAAG,CAACiB,IAAD,EAAOd,GAAG,CAACoB,QAAD,EAAWrB,MAAM,CAAC,CAAD,CAAjB,CAAV,CAAd,CAAR,CAAb;AACA,YAAMuB,UAAU,GAAG9B,cAAc,CAAC+B,gBAAf,CAAgCT,IAAI,CAACI,KAArC,EAA4CF,QAA5C,CAAnB;;AACA,UAAIM,UAAU,CAACE,MAAX,GAAoB,CAAxB,EAA2B;AACzBH,WAAG,GAAGpB,GAAG,CAACoB,GAAD,EAAMC,UAAN,CAAT;AACD;;AACD,aAAOxB,OAAO,CAACuB,GAAD,EAAMP,IAAI,CAACI,KAAX,CAAd;AACD,KARD;;AASA,UAAMO,MAAM,GAAG,MAAK;AAClB,YAAMC,SAAS,GAAGhC,OAAO,CAACoB,IAAD,EAAO,CAAP,CAAzB;AACA,YAAMa,OAAO,GAAGzB,KAAK,CAACwB,SAAD,EAAY/B,GAAG,CAACmB,IAAD,CAAf,EAAuBX,SAAS,CAACW,IAAD,CAAhC,CAArB;AACA,UAAIO,GAAG,GAAGzB,GAAG,CAACa,EAAD,EAAKb,GAAG,CAACiB,CAAD,EAAIc,OAAJ,CAAR,CAAb;AACA,YAAML,UAAU,GAAG9B,cAAc,CAAC+B,gBAAf,CAAgCR,GAAG,CAACG,KAApC,EAA2CF,QAA3C,CAAnB;;AACA,UAAIM,UAAU,CAACE,MAAX,GAAoB,CAAxB,EAA2B;AACzBH,WAAG,GAAGpB,GAAG,CAACoB,GAAD,EAAMC,UAAN,CAAT;AACD;;AACD,aAAOxB,OAAO,CAACuB,GAAD,EAAMN,GAAG,CAACG,KAAV,CAAd;AACD,KATD;;AAUA,WAAO;AAACP,OAAC,EAAEQ,OAAJ;AAAaP,OAAC,EAAEa;AAAhB,KAAP;AACD;AA/BsC,CAAlC","names":["Pow","broadcast_util","cast","greater","log","mul","pow","reshape","scalar","sub","sum","where","zerosLike","powGradConfig","kernelName","inputsToSave","outputsToSave","gradFunc","dy","saved","a","b","y","base","exp","outShape","assertAndGetBroadcastShape","shape","derBase","expFloat","res","reduceAxes","getReductionAxes","length","derExp","condition","logBase"],"sources":["/home/nadimakhtar97/smart-attendance-system/tfjs-core/src/gradients/Pow_grad.ts"],"sourcesContent":["/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {Pow} from '../kernel_names';\nimport {GradConfig} from '../kernel_registry';\nimport * as broadcast_util from '../ops/broadcast_util';\nimport {cast} from '../ops/cast';\nimport {greater} from '../ops/greater';\nimport {log} from '../ops/log';\nimport {mul} from '../ops/mul';\nimport {pow} from '../ops/pow';\nimport {reshape} from '../ops/reshape';\nimport {scalar} from '../ops/scalar';\nimport {sub} from '../ops/sub';\nimport {sum} from '../ops/sum';\nimport {where} from '../ops/where';\nimport {zerosLike} from '../ops/zeros_like';\nimport {Tensor} from '../tensor';\n\nexport const powGradConfig: GradConfig = {\n  kernelName: Pow,\n  inputsToSave: ['a', 'b'],\n  outputsToSave: [true],\n  gradFunc: (dy: Tensor, saved: Tensor[]) => {\n    const [a, b, y] = saved;\n    const base = a;\n    const exp = b;\n    const outShape =\n        broadcast_util.assertAndGetBroadcastShape(base.shape, exp.shape);\n\n    const derBase = () => {\n      const expFloat = cast(exp, 'float32');\n      let res = mul(dy, mul(expFloat, pow(base, sub(expFloat, scalar(1)))));\n      const reduceAxes = broadcast_util.getReductionAxes(base.shape, outShape);\n      if (reduceAxes.length > 0) {\n        res = sum(res, reduceAxes);\n      }\n      return reshape(res, base.shape);\n    };\n    const derExp = () => {\n      const condition = greater(base, 0);\n      const logBase = where(condition, log(base), zerosLike(base));\n      let res = mul(dy, mul(y, logBase));\n      const reduceAxes = broadcast_util.getReductionAxes(exp.shape, outShape);\n      if (reduceAxes.length > 0) {\n        res = sum(res, reduceAxes);\n      }\n      return reshape(res, exp.shape);\n    };\n    return {a: derBase, b: derExp};\n  }\n};\n"]},"metadata":{},"sourceType":"module"}