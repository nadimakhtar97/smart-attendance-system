{"ast":null,"code":"/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { Mod } from '../kernel_names';\nimport { assertAndGetBroadcastShape, getReductionAxes } from '../ops/broadcast_util';\nimport { div } from '../ops/div';\nimport { floor } from '../ops/floor';\nimport { mul } from '../ops/mul';\nimport { neg } from '../ops/neg';\nimport { reshape } from '../ops/reshape';\nimport { sum } from '../ops/sum';\nexport const modGradConfig = {\n  kernelName: Mod,\n  inputsToSave: ['a', 'b'],\n  gradFunc: (dy, saved) => {\n    const [a, b] = saved;\n    const outShape = assertAndGetBroadcastShape(a.shape, b.shape);\n\n    const derA = () => {\n      const reduceAxes = getReductionAxes(a.shape, outShape);\n\n      if (reduceAxes.length > 0) {\n        return reshape(sum(dy, reduceAxes), a.shape);\n      }\n\n      return dy;\n    };\n\n    const derB = () => {\n      const res = mul(dy, neg(floor(div(a, b))));\n      const reduceAxes = getReductionAxes(b.shape, outShape);\n\n      if (reduceAxes.length > 0) {\n        return reshape(sum(res, reduceAxes), b.shape);\n      }\n\n      return res;\n    };\n\n    return {\n      a: derA,\n      b: derB\n    };\n  }\n};","map":{"version":3,"mappings":"AAAA;;;;;;;;;;;;;;;;AAiBA,SAAQA,GAAR,QAAkB,iBAAlB;AAEA,SAAQC,0BAAR,EAAoCC,gBAApC,QAA2D,uBAA3D;AACA,SAAQC,GAAR,QAAkB,YAAlB;AACA,SAAQC,KAAR,QAAoB,cAApB;AACA,SAAQC,GAAR,QAAkB,YAAlB;AACA,SAAQC,GAAR,QAAkB,YAAlB;AACA,SAAQC,OAAR,QAAsB,gBAAtB;AACA,SAAQC,GAAR,QAAkB,YAAlB;AAGA,OAAO,MAAMC,aAAa,GAAe;AACvCC,YAAU,EAAEV,GAD2B;AAEvCW,cAAY,EAAE,CAAC,GAAD,EAAM,GAAN,CAFyB;AAGvCC,UAAQ,EAAE,CAACC,EAAD,EAAaC,KAAb,KAAgC;AACxC,UAAM,CAACC,CAAD,EAAIC,CAAJ,IAASF,KAAf;AACA,UAAMG,QAAQ,GAAGhB,0BAA0B,CAACc,CAAC,CAACG,KAAH,EAAUF,CAAC,CAACE,KAAZ,CAA3C;;AAEA,UAAMC,IAAI,GAAG,MAAK;AAChB,YAAMC,UAAU,GAAGlB,gBAAgB,CAACa,CAAC,CAACG,KAAH,EAAUD,QAAV,CAAnC;;AACA,UAAIG,UAAU,CAACC,MAAX,GAAoB,CAAxB,EAA2B;AACzB,eAAOd,OAAO,CAACC,GAAG,CAACK,EAAD,EAAKO,UAAL,CAAJ,EAAsBL,CAAC,CAACG,KAAxB,CAAd;AACD;;AACD,aAAOL,EAAP;AACD,KAND;;AAOA,UAAMS,IAAI,GAAG,MAAK;AAChB,YAAMC,GAAG,GAAGlB,GAAG,CAACQ,EAAD,EAAKP,GAAG,CAACF,KAAK,CAACD,GAAG,CAACY,CAAD,EAAIC,CAAJ,CAAJ,CAAN,CAAR,CAAf;AACA,YAAMI,UAAU,GAAGlB,gBAAgB,CAACc,CAAC,CAACE,KAAH,EAAUD,QAAV,CAAnC;;AACA,UAAIG,UAAU,CAACC,MAAX,GAAoB,CAAxB,EAA2B;AACzB,eAAOd,OAAO,CAACC,GAAG,CAACe,GAAD,EAAMH,UAAN,CAAJ,EAAuBJ,CAAC,CAACE,KAAzB,CAAd;AACD;;AACD,aAAOK,GAAP;AACD,KAPD;;AAQA,WAAO;AAACR,OAAC,EAAEI,IAAJ;AAAUH,OAAC,EAAEM;AAAb,KAAP;AACD;AAvBsC,CAAlC","names":["Mod","assertAndGetBroadcastShape","getReductionAxes","div","floor","mul","neg","reshape","sum","modGradConfig","kernelName","inputsToSave","gradFunc","dy","saved","a","b","outShape","shape","derA","reduceAxes","length","derB","res"],"sources":["/home/nadimakhtar97/smart-attendance-system/tfjs-core/src/gradients/Mod_grad.ts"],"sourcesContent":["/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Mod} from '../kernel_names';\nimport {GradConfig} from '../kernel_registry';\nimport {assertAndGetBroadcastShape, getReductionAxes} from '../ops/broadcast_util';\nimport {div} from '../ops/div';\nimport {floor} from '../ops/floor';\nimport {mul} from '../ops/mul';\nimport {neg} from '../ops/neg';\nimport {reshape} from '../ops/reshape';\nimport {sum} from '../ops/sum';\nimport {Tensor} from '../tensor';\n\nexport const modGradConfig: GradConfig = {\n  kernelName: Mod,\n  inputsToSave: ['a', 'b'],\n  gradFunc: (dy: Tensor, saved: Tensor[]) => {\n    const [a, b] = saved;\n    const outShape = assertAndGetBroadcastShape(a.shape, b.shape);\n\n    const derA = () => {\n      const reduceAxes = getReductionAxes(a.shape, outShape);\n      if (reduceAxes.length > 0) {\n        return reshape(sum(dy, reduceAxes), a.shape);\n      }\n      return dy;\n    };\n    const derB = () => {\n      const res = mul(dy, neg(floor(div(a, b))));\n      const reduceAxes = getReductionAxes(b.shape, outShape);\n      if (reduceAxes.length > 0) {\n        return reshape(sum(res, reduceAxes), b.shape);\n      }\n      return res;\n    };\n    return {a: derA, b: derB};\n  }\n};\n"]},"metadata":{},"sourceType":"module"}